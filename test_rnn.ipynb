{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IQ TEST SEQUENCER BOT - RNN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import random\n",
    "from keras.layers import Bidirectional\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  stem               options            category    id\n",
      "0           7,9,-1,5,?        [4, 2, -1, -3]            sequence     0\n",
      "1        3,2,5/3,3/2,?  [1/4, 7/5, 3/4, 2/5]            sequence     1\n",
      "2           1,2,5,26,?    [34, 841, 677, 37]            sequence     2\n",
      "3            2,12,30,?      [50, 65, 75, 56]            sequence     3\n",
      "4        2,1,2/3,1/2,?  [3/4, 1/4, 2/5, 5/6]            sequence     4\n",
      "...                ...                   ...                 ...   ...\n",
      "1071  20 22 25 30 37 ?                    []  sequence-reasoning  1090\n",
      "1072        0 1 3 10 ?                    []  sequence-reasoning  1091\n",
      "1073       5 15 10 215                    []  sequence-reasoning  1092\n",
      "1074        1 2 5 29 ?    [34, 841, 866, 37]  sequence-reasoning  1093\n",
      "1075         2 12 30 ?      [50, 65, 75, 56]  sequence-reasoning  1094\n",
      "\n",
      "[1076 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "seqdataIn = pd.read_json('data/seq-public.json', orient='records')\n",
    "print(seqdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     answer                                               hint\n",
      "0       [4]      A<sub>n+1</sub>=2<sup>5-n</sup>-A<sub>n</sub>\n",
      "1       [2]  3/1, 4/2, 5/3, 6/4\\n\\nA<sub>n+1</sub>=A<sub>n<...\n",
      "2       [3]        A<sub>n+1</sub>=A<sub>n</sub><sup>2</sup>+1\n",
      "3       [4]                           A<sub>n</sub>=2n\\*(2n-1)\n",
      "4       [3]             4/2, 4/4, 4/6, 4/8\\n\\nA<sub>n</sub>=2n\n",
      "...     ...                                                ...\n",
      "1090     48                A<sub>n+1</sub>-A<sub>n</sub>=P(n);\n",
      "1091    102           A<sub>n\\*2</sub>=A<sub>n\\*2-1</sub>^2+2;\n",
      "1092   -115   A<sub>n</sub>=A<sub>n-2</sub>^2-A<sub>n-1</sub>;\n",
      "1093    [3]  A<sub>n</sub>=A<sub>n-1</sub>^2+A<sub>n-2</sub...\n",
      "1094    [4]                      A<sub>n</sub>=(2\\*n-1)\\*2\\*n;\n",
      "\n",
      "[1076 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "seqDataAns =pd.read_json('data/seq-public.answer.json',orient='index')\n",
    "print(seqDataAns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Preprocess hints for printing - (not given with question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                   A_{n+1}=2^{5-n}-A_{n}\n",
      "1       3/1, 4/2, 5/3, 6/4 |  | A_{n+1}=A_{n}+1 |  | B...\n",
      "2                                     A_{n+1}=A_{n}^{2}+1\n",
      "3                                         A_{n}=2n*(2n-1)\n",
      "4                        4/2, 4/4, 4/6, 4/8 |  | A_{n}=2n\n",
      "                              ...                        \n",
      "1090                                  A_{n+1}-A_{n}=P(n);\n",
      "1091                               A_{n*2}=A_{n*2-1}^2+2;\n",
      "1092                             A_{n}=A_{n-2}^2-A_{n-1};\n",
      "1093                           A_{n}=A_{n-1}^2+A_{n-2}^2;\n",
      "1094                                   A_{n}=(2*n-1)*2*n;\n",
      "Name: hint, Length: 1076, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def hint2txt(h):\n",
    "    return h.replace('<sub>','_{').replace('</sub>','}').replace('<sup>','^{').replace('</sup>','}').replace('\\n',' | ').replace('\\*','*')\n",
    "seqDataAns['hint'] = seqDataAns['hint'].map(lambda x: hint2txt(x))\n",
    "print(seqDataAns['hint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: The sequences are recursive and can involve exponents and the index number. \n",
    "#### The answers also correspond to the index in the answer choices not the literal answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fibonacci LSTM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
      "[2, 3, 5, 8, 13, 21, 34, 55, 89, 144]\n"
     ]
    }
   ],
   "source": [
    "#define fibonacci function\n",
    "def fib(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    elif x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(x-1)+fib(x-2)\n",
    "\n",
    "#returns n fibonacci numbers (starting with the 'start'th number) \n",
    "def fibSeq(n,start=0):\n",
    "    s = []\n",
    "    for i in range(start,start+n):\n",
    "        s.append(fib(i))\n",
    "    return s\n",
    "\n",
    "print(fibSeq(10))\n",
    "print(fibSeq(10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]] => [2]\n",
      "[[1 2]] => [3]\n",
      "[[2 3]] => [5]\n",
      "[[3 5]] => [8]\n",
      "[[5 8]] => [13]\n",
      "[[ 8 13]] => [21]\n",
      "[[13 21]] => [34]\n",
      "[[21 34]] => [55]\n",
      "[[34 55]] => [89]\n",
      "[[55 89]] => [144]\n",
      "[[ 89 144]] => [233]\n",
      "[[144 233]] => [377]\n",
      "[[233 377]] => [610]\n",
      "[[377 610]] => [987]\n",
      "[[610 987]] => [1597]\n",
      "[[ 987 1597]] => [2584]\n",
      "[[1597 2584]] => [4181]\n",
      "[[2584 4181]] => [6765]\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/time-series-forecasting-with-recurrent-neural-networks-74674e289816\n",
    "# https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/\n",
    "\n",
    "# Test data preprocessing for RNN \n",
    "lookback = 2 #for fibonacci specifically only looks back to the previous 2 values\n",
    "testSeq = fibSeq(20)\n",
    "generator = TimeseriesGenerator(testSeq, testSeq, length=lookback, batch_size=1)\n",
    "# print each sample\n",
    "for i in range(len(generator)):\n",
    "\tx, y = generator[i]\n",
    "\tprint('%s => %s' % (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[987, 1597, 2584, 4181, 6765], [4181, 6765, 10946, 17711, 28657], [1, 1, 2, 3, 5], [1597, 2584, 4181, 6765, 10946], [46368, 75025, 121393, 196418, 317811], [2584, 4181, 6765, 10946, 17711], [6765, 10946, 17711, 28657, 46368], [89, 144, 233, 377, 610], [28657, 46368, 75025, 121393, 196418], [377, 610, 987, 1597, 2584]]\n",
      "[[8, 13, 21, 34, 55]]\n"
     ]
    }
   ],
   "source": [
    "# make train and test data sets\n",
    "m = 30\n",
    "seqLen = 5\n",
    "masterSeq = fibSeq(m) #get first 50 fib numbers\n",
    "#make set of specific length \n",
    "def fibSet(x,l):\n",
    "    s = []\n",
    "    for i in range(x):\n",
    "        t = random.randint(0,m-l)\n",
    "        s.append(masterSeq[t:t+l])\n",
    "    return s\n",
    "train_fib = fibSet(10,seqLen)\n",
    "test_fib = fibSet(1,seqLen)\n",
    "print(train_fib)\n",
    "print(test_fib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data for lstm\n",
    "fib_look = 2 #for fibonacci specifically only looks back to the previous 2 values\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "#train\n",
    "for t in train_fib:\n",
    "    train_gen = TimeseriesGenerator(t, t, length=fib_look, batch_size=1)\n",
    "    for i in range(len(train_gen)):\n",
    "        x, y = train_gen[i]\n",
    "        X_train.append(x)\n",
    "        y_train.append(y)\n",
    "\n",
    "X_train = np.squeeze(np.asarray(X_train))\n",
    "y_train = np.squeeze(np.asarray(y_train))\n",
    "#reshape to [# samples, #time steps, #features] -> [10*segments, 2, 1]\n",
    "X_train = X_train.reshape((X_train.shape[0],fib_look,1))\n",
    "\n",
    "#test\n",
    "for t in test_fib:\n",
    "    test_gen = TimeseriesGenerator(t, t, length=fib_look, batch_size=1)\n",
    "    for i in range(len(test_gen)):\n",
    "        x, y = test_gen[i]\n",
    "        X_test.append(x)\n",
    "        y_test.append(y)\n",
    "\n",
    "X_test = np.squeeze(np.asarray(X_test))\n",
    "y_test = np.squeeze(np.asarray(y_test))\n",
    "#reshape to [# samples, #time steps, #features] -> [10*segments, 2, 1]\n",
    "X_test = X_test.reshape((X_test.shape[0],fib_look,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train[[[   987]\n",
      "  [  1597]]\n",
      "\n",
      " [[  1597]\n",
      "  [  2584]]\n",
      "\n",
      " [[  2584]\n",
      "  [  4181]]\n",
      "\n",
      " [[  4181]\n",
      "  [  6765]]\n",
      "\n",
      " [[  6765]\n",
      "  [ 10946]]\n",
      "\n",
      " [[ 10946]\n",
      "  [ 17711]]\n",
      "\n",
      " [[     1]\n",
      "  [     1]]\n",
      "\n",
      " [[     1]\n",
      "  [     2]]\n",
      "\n",
      " [[     2]\n",
      "  [     3]]\n",
      "\n",
      " [[  1597]\n",
      "  [  2584]]\n",
      "\n",
      " [[  2584]\n",
      "  [  4181]]\n",
      "\n",
      " [[  4181]\n",
      "  [  6765]]\n",
      "\n",
      " [[ 46368]\n",
      "  [ 75025]]\n",
      "\n",
      " [[ 75025]\n",
      "  [121393]]\n",
      "\n",
      " [[121393]\n",
      "  [196418]]\n",
      "\n",
      " [[  2584]\n",
      "  [  4181]]\n",
      "\n",
      " [[  4181]\n",
      "  [  6765]]\n",
      "\n",
      " [[  6765]\n",
      "  [ 10946]]\n",
      "\n",
      " [[  6765]\n",
      "  [ 10946]]\n",
      "\n",
      " [[ 10946]\n",
      "  [ 17711]]\n",
      "\n",
      " [[ 17711]\n",
      "  [ 28657]]\n",
      "\n",
      " [[    89]\n",
      "  [   144]]\n",
      "\n",
      " [[   144]\n",
      "  [   233]]\n",
      "\n",
      " [[   233]\n",
      "  [   377]]\n",
      "\n",
      " [[ 28657]\n",
      "  [ 46368]]\n",
      "\n",
      " [[ 46368]\n",
      "  [ 75025]]\n",
      "\n",
      " [[ 75025]\n",
      "  [121393]]\n",
      "\n",
      " [[   377]\n",
      "  [   610]]\n",
      "\n",
      " [[   610]\n",
      "  [   987]]\n",
      "\n",
      " [[   987]\n",
      "  [  1597]]]\n",
      "y train[  2584   4181   6765  10946  17711  28657      2      3      5   4181\n",
      "   6765  10946 121393 196418 317811   6765  10946  17711  17711  28657\n",
      "  46368    233    377    610  75025 121393 196418    987   1597   2584]\n",
      "X test[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "y test[21 34 55]\n"
     ]
    }
   ],
   "source": [
    "print(\"X train\" + str(X_train))\n",
    "print(\"y train\" + str(y_train))\n",
    "print(\"X test\" + str(X_test))\n",
    "print(\"y test\" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Simple LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(m, activation='relu', input_shape=(fib_look, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 5239776768.0000 - mse: 5239776768.0000 - val_loss: 7724752896.0000 - val_mse: 7724752896.0000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5227749376.0000 - mse: 5227749376.0000 - val_loss: 7706902528.0000 - val_mse: 7706902528.0000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5215668736.0000 - mse: 5215668736.0000 - val_loss: 7688973824.0000 - val_mse: 7688973824.0000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5203536384.0000 - mse: 5203536384.0000 - val_loss: 7670966784.0000 - val_mse: 7670966784.0000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5191349760.0000 - mse: 5191349760.0000 - val_loss: 7652878848.0000 - val_mse: 7652878848.0000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5179108352.0000 - mse: 5179108352.0000 - val_loss: 7634708992.0000 - val_mse: 7634708992.0000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5166811648.0000 - mse: 5166811648.0000 - val_loss: 7616455168.0000 - val_mse: 7616455168.0000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5154458624.0000 - mse: 5154458624.0000 - val_loss: 7598118400.0000 - val_mse: 7598118400.0000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5142048768.0000 - mse: 5142048768.0000 - val_loss: 7579695104.0000 - val_mse: 7579695104.0000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5129581568.0000 - mse: 5129581568.0000 - val_loss: 7561187328.0000 - val_mse: 7561187328.0000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5117056512.0000 - mse: 5117056512.0000 - val_loss: 7542593024.0000 - val_mse: 7542593024.0000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5104472576.0000 - mse: 5104472576.0000 - val_loss: 7523908096.0000 - val_mse: 7523908096.0000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5091827712.0000 - mse: 5091827712.0000 - val_loss: 7505135104.0000 - val_mse: 7505135104.0000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5079122432.0000 - mse: 5079122432.0000 - val_loss: 7486270976.0000 - val_mse: 7486270976.0000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5066356736.0000 - mse: 5066356736.0000 - val_loss: 7467315712.0000 - val_mse: 7467315712.0000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5053529600.0000 - mse: 5053529600.0000 - val_loss: 7448268800.0000 - val_mse: 7448268800.0000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5040638464.0000 - mse: 5040638464.0000 - val_loss: 7429127680.0000 - val_mse: 7429127680.0000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5027684864.0000 - mse: 5027684864.0000 - val_loss: 7409891840.0000 - val_mse: 7409891840.0000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5014667776.0000 - mse: 5014667776.0000 - val_loss: 7390562304.0000 - val_mse: 7390562304.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5001585664.0000 - mse: 5001585664.0000 - val_loss: 7371135488.0000 - val_mse: 7371135488.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4988440064.0000 - mse: 4988440064.0000 - val_loss: 7351611904.0000 - val_mse: 7351611904.0000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4975226880.0000 - mse: 4975226880.0000 - val_loss: 7331987968.0000 - val_mse: 7331987968.0000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4961943040.0000 - mse: 4961943040.0000 - val_loss: 7303370240.0000 - val_mse: 7303370240.0000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4945756160.0000 - mse: 4945756160.0000 - val_loss: 7159644672.0000 - val_mse: 7159644672.0000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4845316608.0000 - mse: 4845316608.0000 - val_loss: 7138095616.0000 - val_mse: 7138095616.0000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4830727680.0000 - mse: 4830727680.000 - 0s 16ms/step - loss: 4830727680.0000 - mse: 4830727680.0000 - val_loss: 7116088832.0000 - val_mse: 7116088832.0000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4815834624.0000 - mse: 4815834624.0000 - val_loss: 7093754368.0000 - val_mse: 7093754368.0000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4800720384.0000 - mse: 4800720384.0000 - val_loss: 7071158272.0000 - val_mse: 7071158272.0000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4785427968.0000 - mse: 4785427968.0000 - val_loss: 7048335872.0000 - val_mse: 7048335872.0000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4769982976.0000 - mse: 4769982976.0000 - val_loss: 7025313280.0000 - val_mse: 7025313280.0000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4754403328.0000 - mse: 4754403328.0000 - val_loss: 7002109952.0000 - val_mse: 7002109952.0000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4738699776.0000 - mse: 4738699776.0000 - val_loss: 6978732032.0000 - val_mse: 6978732032.0000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4722878976.0000 - mse: 4722878976.0000 - val_loss: 6955190784.0000 - val_mse: 6955190784.0000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4706947072.0000 - mse: 4706947072.0000 - val_loss: 6931493376.0000 - val_mse: 6931493376.0000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4690909696.0000 - mse: 4690909696.0000 - val_loss: 6907642368.0000 - val_mse: 6907642368.0000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4674769408.0000 - mse: 4674769408.0000 - val_loss: 6883641856.0000 - val_mse: 6883641856.0000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4658526720.0000 - mse: 4658526720.0000 - val_loss: 6859494912.0000 - val_mse: 6859494912.0000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4642185728.0000 - mse: 4642185728.0000 - val_loss: 6835202560.0000 - val_mse: 6835202560.0000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4625745920.0000 - mse: 4625745920.0000 - val_loss: 6810768896.0000 - val_mse: 6810768896.0000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4609209344.0000 - mse: 4609209344.0000 - val_loss: 6786191360.0000 - val_mse: 6786191360.0000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4592576512.0000 - mse: 4592576512.0000 - val_loss: 6761474048.0000 - val_mse: 6761474048.0000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4575848960.0000 - mse: 4575848960.0000 - val_loss: 6736615936.0000 - val_mse: 6736615936.0000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4559026176.0000 - mse: 4559026176.0000 - val_loss: 6711617536.0000 - val_mse: 6711617536.0000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4542108672.0000 - mse: 4542108672.0000 - val_loss: 6686480896.0000 - val_mse: 6686480896.0000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4525098496.0000 - mse: 4525098496.0000 - val_loss: 6661205504.0000 - val_mse: 6661205504.0000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4507992576.0000 - mse: 4507992576.0000 - val_loss: 6635791872.0000 - val_mse: 6635791872.0000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4490793472.0000 - mse: 4490793472.0000 - val_loss: 6610241024.0000 - val_mse: 6610241024.0000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4473501696.0000 - mse: 4473501696.0000 - val_loss: 6584551424.0000 - val_mse: 6584551424.0000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4456116736.0000 - mse: 4456116736.0000 - val_loss: 6558726144.0000 - val_mse: 6558726144.0000\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4438639104.0000 - mse: 4438639104.0000 - val_loss: 6532763648.0000 - val_mse: 6532763648.0000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4421069312.0000 - mse: 4421069312.0000 - val_loss: 6506663936.0000 - val_mse: 6506663936.0000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4403406336.0000 - mse: 4403406336.0000 - val_loss: 6480429568.0000 - val_mse: 6480429568.0000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4385651712.0000 - mse: 4385651712.0000 - val_loss: 6454059008.0000 - val_mse: 6454059008.0000\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4367805440.0000 - mse: 4367805440.0000 - val_loss: 6427552256.0000 - val_mse: 6427552256.0000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4349868032.0000 - mse: 4349868032.0000 - val_loss: 6400912896.0000 - val_mse: 6400912896.0000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4331838976.0000 - mse: 4331838976.0000 - val_loss: 6374138368.0000 - val_mse: 6374138368.0000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4313719296.0000 - mse: 4313719296.0000 - val_loss: 6347229696.0000 - val_mse: 6347229696.0000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4295509504.0000 - mse: 4295509504.0000 - val_loss: 6320188928.0000 - val_mse: 6320188928.0000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4277209088.0000 - mse: 4277209088.0000 - val_loss: 6293016064.0000 - val_mse: 6293016064.0000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4258819840.0000 - mse: 4258819840.0000 - val_loss: 6265710592.0000 - val_mse: 6265710592.0000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4240340224.0000 - mse: 4240340224.0000 - val_loss: 6238273536.0000 - val_mse: 6238273536.0000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4221772032.0000 - mse: 4221772032.0000 - val_loss: 6210705408.0000 - val_mse: 6210705408.0000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4203115776.0000 - mse: 4203115776.0000 - val_loss: 6183007744.0000 - val_mse: 6183007744.0000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4184371968.0000 - mse: 4184371968.0000 - val_loss: 6155180032.0000 - val_mse: 6155180032.0000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4165540608.0000 - mse: 4165540608.0000 - val_loss: 6127218688.0000 - val_mse: 6127218688.0000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4146619648.0000 - mse: 4146619648.0000 - val_loss: 6099116544.0000 - val_mse: 6099116544.0000\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4127562496.0000 - mse: 4127562496.0000 - val_loss: 5580833280.0000 - val_mse: 5580833280.0000\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3776890880.0000 - mse: 3776890880.0000 - val_loss: 5549647872.0000 - val_mse: 5549647872.0000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3755740928.0000 - mse: 3755740928.0000 - val_loss: 5517008384.0000 - val_mse: 5517008384.0000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3733653760.0000 - mse: 3733653760.0000 - val_loss: 5483368448.0000 - val_mse: 5483368448.0000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3710888704.0000 - mse: 3710888704.0000 - val_loss: 5448974848.0000 - val_mse: 5448974848.0000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3687613184.0000 - mse: 3687613184.0000 - val_loss: 5413987840.0000 - val_mse: 5413987840.0000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3663935488.0000 - mse: 3663935488.0000 - val_loss: 5378516480.0000 - val_mse: 5378516480.0000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3639930112.0000 - mse: 3639930112.0000 - val_loss: 5342646272.0000 - val_mse: 5342646272.0000\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3615655168.0000 - mse: 3615655168.0000 - val_loss: 5306441216.0000 - val_mse: 5306441216.0000\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3591153664.0000 - mse: 3591153664.0000 - val_loss: 5269953536.0000 - val_mse: 5269953536.0000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3566459904.0000 - mse: 3566459904.0000 - val_loss: 5233223168.0000 - val_mse: 5233223168.0000\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3541602304.0000 - mse: 3541602304.0000 - val_loss: 5196284928.0000 - val_mse: 5196284928.0000\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3516604416.0000 - mse: 3516604416.0000 - val_loss: 5159164928.0000 - val_mse: 5159164928.0000\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3491483904.0000 - mse: 3491483904.0000 - val_loss: 5121890816.0000 - val_mse: 5121890816.0000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3466257664.0000 - mse: 3466257664.0000 - val_loss: 5084478464.0000 - val_mse: 5084478464.0000\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3440939008.0000 - mse: 3440939008.0000 - val_loss: 5046945280.0000 - val_mse: 5046945280.0000\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3415539712.0000 - mse: 3415539712.0000 - val_loss: 5009292800.0000 - val_mse: 5009292800.0000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3390067456.0000 - mse: 3390067456.0000 - val_loss: 4971515392.0000 - val_mse: 4971515392.0000\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3364364032.0000 - mse: 3364364032.0000 - val_loss: 3910365952.0000 - val_mse: 3910365952.0000\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2646368256.0000 - mse: 2646368256.0000 - val_loss: 3870252800.0000 - val_mse: 3870252800.0000\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2619205888.0000 - mse: 2619205888.0000 - val_loss: 3828283648.0000 - val_mse: 3828283648.0000\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2590805504.0000 - mse: 2590805504.0000 - val_loss: 3785149440.0000 - val_mse: 3785149440.0000\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2561615104.0000 - mse: 2561615104.0000 - val_loss: 3741223680.0000 - val_mse: 3741223680.0000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2531888384.0000 - mse: 2531888384.0000 - val_loss: 3696748800.0000 - val_mse: 3696748800.0000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2501789952.0000 - mse: 2501789952.0000 - val_loss: 3651896320.0000 - val_mse: 3651896320.0000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2471436032.0000 - mse: 2471436032.0000 - val_loss: 3606791168.0000 - val_mse: 3606791168.0000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2440911104.0000 - mse: 2440911104.0000 - val_loss: 3561532160.0000 - val_mse: 3561532160.0000\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2410281728.0000 - mse: 2410281728.0000 - val_loss: 3516195072.0000 - val_mse: 3516195072.0000\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2379599616.0000 - mse: 2379599616.0000 - val_loss: 3470841600.0000 - val_mse: 3470841600.0000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2348906752.0000 - mse: 2348906752.0000 - val_loss: 3425521408.0000 - val_mse: 3425521408.0000\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2318236416.0000 - mse: 2318236416.0000 - val_loss: 3380275968.0000 - val_mse: 3380275968.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2287616256.0000 - mse: 2287616256.0000 - val_loss: 3335139328.0000 - val_mse: 3335139328.0000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2257069824.0000 - mse: 2257069824.0000 - val_loss: 3290139392.0000 - val_mse: 3290139392.0000\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2226616064.0000 - mse: 2226616064.0000 - val_loss: 3245299968.0000 - val_mse: 3245299968.0000\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2196270848.0000 - mse: 2196270848.0000 - val_loss: 3200641280.0000 - val_mse: 3200641280.0000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2166048256.0000 - mse: 2166048256.0000 - val_loss: 3156182016.0000 - val_mse: 3156182016.0000\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2135959936.0000 - mse: 2135959936.0000 - val_loss: 3111934208.0000 - val_mse: 3111934208.0000\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2106015616.0000 - mse: 2106015616.0000 - val_loss: 3067912448.0000 - val_mse: 3067912448.0000\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2076223488.0000 - mse: 2076223488.0000 - val_loss: 3024126976.0000 - val_mse: 3024126976.0000\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2046591360.0000 - mse: 2046591360.0000 - val_loss: 2980586752.0000 - val_mse: 2980586752.0000\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2017125760.0000 - mse: 2017125760.0000 - val_loss: 2937297920.0000 - val_mse: 2937297920.0000\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1987831808.0000 - mse: 1987831808.0000 - val_loss: 2894248192.0000 - val_mse: 2894248192.0000\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1958697600.0000 - mse: 1958697600.0000 - val_loss: 2268942336.0000 - val_mse: 2268942336.0000\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1535574016.0000 - mse: 1535574016.0000 - val_loss: 2225926400.0000 - val_mse: 2225926400.0000\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1506404864.0000 - mse: 1506404864.0000 - val_loss: 2181769984.0000 - val_mse: 2181769984.0000\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1476525952.0000 - mse: 1476525952.0000 - val_loss: 2137039488.0000 - val_mse: 2137039488.0000\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1446252672.0000 - mse: 1446252672.0000 - val_loss: 1425303040.0000 - val_mse: 1425303040.0000\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 964632256.0000 - mse: 964632256.0000 - val_loss: 1383615104.0000 - val_mse: 1383615104.0000\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 936376640.0000 - mse: 936376640.0000 - val_loss: 1094427008.0000 - val_mse: 1094427008.0000\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 740688320.0000 - mse: 740688320.0000 - val_loss: 1053821184.0000 - val_mse: 1053821184.0000\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 713183232.0000 - mse: 713183232.0000 - val_loss: 1013528064.0000 - val_mse: 1013528064.0000\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 685817408.0000 - mse: 685817408.0000 - val_loss: 723446592.0000 - val_mse: 723446592.0000\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 489702272.0000 - mse: 489702272.0000 - val_loss: 686914752.0000 - val_mse: 686914752.0000\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 464874592.0000 - mse: 464874592.0000 - val_loss: 650702144.0000 - val_mse: 650702144.0000\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 440367328.0000 - mse: 440367328.0000 - val_loss: 615154624.0000 - val_mse: 615154624.0000\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 416311040.0000 - mse: 416311040.0000 - val_loss: 580464832.0000 - val_mse: 580464832.0000\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 392834848.0000 - mse: 392834848.0000 - val_loss: 546755840.0000 - val_mse: 546755840.0000\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 370022400.0000 - mse: 370022400.0000 - val_loss: 514111968.0000 - val_mse: 514111968.0000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 347930496.0000 - mse: 347930496.0000 - val_loss: 482590624.0000 - val_mse: 482590624.0000\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 326598240.0000 - mse: 326598240.0000 - val_loss: 452231392.0000 - val_mse: 452231392.0000\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 306052576.0000 - mse: 306052576.0000 - val_loss: 423059616.0000 - val_mse: 423059616.0000\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 286310400.0000 - mse: 286310400.0000 - val_loss: 395089536.0000 - val_mse: 395089536.0000\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 267381504.0000 - mse: 267381504.0000 - val_loss: 368327168.0000 - val_mse: 368327168.0000\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 249269936.0000 - mse: 249269936.0000 - val_loss: 342771936.0000 - val_mse: 342771936.0000\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 231975184.0000 - mse: 231975184.0000 - val_loss: 318416064.0000 - val_mse: 318416064.0000\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 215492288.0000 - mse: 215492288.0000 - val_loss: 295248288.0000 - val_mse: 295248288.0000\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 199813232.0000 - mse: 199813232.0000 - val_loss: 273252448.0000 - val_mse: 273252448.0000\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 184927504.0000 - mse: 184927504.0000 - val_loss: 252409088.0000 - val_mse: 252409088.0000\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 170821520.0000 - mse: 170821520.0000 - val_loss: 232695744.0000 - val_mse: 232695744.0000\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 157480448.0000 - mse: 157480448.0000 - val_loss: 214087232.0000 - val_mse: 214087232.0000\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 144886896.0000 - mse: 144886896.0000 - val_loss: 196555856.0000 - val_mse: 196555856.0000\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 133022472.0000 - mse: 133022472.0000 - val_loss: 180072832.0000 - val_mse: 180072832.0000\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 121867448.0000 - mse: 121867448.0000 - val_loss: 164606112.0000 - val_mse: 164606112.0000\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 111400192.0000 - mse: 111400192.0000 - val_loss: 150123856.0000 - val_mse: 150123856.0000\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 101599144.0000 - mse: 101599144.0000 - val_loss: 136592272.0000 - val_mse: 136592272.0000\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 92441624.0000 - mse: 92441624.0000 - val_loss: 123976408.0000 - val_mse: 123976408.0000\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 83903704.0000 - mse: 83903704.0000 - val_loss: 112240928.0000 - val_mse: 112240928.0000\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 75961592.0000 - mse: 75961592.0000 - val_loss: 101349736.0000 - val_mse: 101349736.0000\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 68590808.0000 - mse: 68590808.0000 - val_loss: 91265880.0000 - val_mse: 91265880.0000\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 61766476.0000 - mse: 61766476.0000 - val_loss: 81952776.0000 - val_mse: 81952776.0000\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 55463676.0000 - mse: 55463676.0000 - val_loss: 73373064.0000 - val_mse: 73373064.0000\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 49657260.0000 - mse: 49657260.0000 - val_loss: 65490172.0000 - val_mse: 65490172.0000\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 44322412.0000 - mse: 44322412.0000 - val_loss: 58266892.0000 - val_mse: 58266892.0000\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 39433944.0000 - mse: 39433944.0000 - val_loss: 51666908.0000 - val_mse: 51666908.0000\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 34967276.0000 - mse: 34967276.0000 - val_loss: 45653940.0000 - val_mse: 45653940.0000\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 30897870.0000 - mse: 30897870.0000 - val_loss: 40192536.0000 - val_mse: 40192536.0000\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27201808.0000 - mse: 27201808.0000 - val_loss: 35247848.0000 - val_mse: 35247848.0000\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23855422.0000 - mse: 23855422.0000 - val_loss: 30785682.0000 - val_mse: 30785682.0000\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20835516.0000 - mse: 20835516.0000 - val_loss: 26772880.0000 - val_mse: 26772880.0000\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18119802.0000 - mse: 18119802.0000 - val_loss: 23177200.0000 - val_mse: 23177200.0000\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 15686328.0000 - mse: 15686328.0000 - val_loss: 19967522.0000 - val_mse: 19967522.0000\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 13514111.0000 - mse: 13514111.0000 - val_loss: 17113658.0000 - val_mse: 17113658.0000\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11582708.0000 - mse: 11582708.0000 - val_loss: 14586885.0000 - val_mse: 14586885.0000\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9872613.0000 - mse: 9872613.0000 - val_loss: 12359633.0000 - val_mse: 12359633.0000\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8365232.0000 - mse: 8365232.0000 - val_loss: 10405614.0000 - val_mse: 10405614.0000\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7042774.5000 - mse: 7042774.5000 - val_loss: 8699826.0000 - val_mse: 8699826.0000\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5888340.0000 - mse: 5888340.0000 - val_loss: 7218709.5000 - val_mse: 7218709.5000\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4885939.5000 - mse: 4885939.5000 - val_loss: 5940092.5000 - val_mse: 5940092.5000\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4020540.7500 - mse: 4020540.7500 - val_loss: 4843081.5000 - val_mse: 4843081.5000\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3278106.0000 - mse: 3278106.0000 - val_loss: 3908344.2500 - val_mse: 3908344.2500\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2645462.2500 - mse: 2645462.2500 - val_loss: 3117682.7500 - val_mse: 3117682.7500\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2110335.7500 - mse: 2110335.7500 - val_loss: 2454438.7500 - val_mse: 2454438.7500\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1661436.6250 - mse: 1661436.6250 - val_loss: 1903179.0000 - val_mse: 1903179.0000\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1288322.2500 - mse: 1288322.2500 - val_loss: 1449724.6250 - val_mse: 1449724.6250\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 981416.5625 - mse: 981416.5625 - val_loss: 1081237.6250 - val_mse: 1081237.6250\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 732006.5000 - mse: 732006.5000 - val_loss: 785972.3125 - val_mse: 785972.3125\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 532137.9375 - mse: 532137.9375 - val_loss: 553312.4375 - val_mse: 553312.4375\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 374656.8438 - mse: 374656.8438 - val_loss: 373809.9688 - val_mse: 373809.9688\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 253147.6406 - mse: 253147.6406 - val_loss: 238927.5156 - val_mse: 238927.5156\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 161838.3281 - mse: 161838.3281 - val_loss: 141149.6406 - val_mse: 141149.6406\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 95638.2734 - mse: 95638.2734 - val_loss: 73829.2891 - val_mse: 73829.2891\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 50054.7969 - mse: 50054.7969 - val_loss: 31142.7109 - val_mse: 31142.7109\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21144.2910 - mse: 21144.2910 - val_loss: 8028.7773 - val_mse: 8028.7773\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5480.4810 - mse: 5480.4810 - val_loss: 127.7603 - val_mse: 127.7603\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 115.1726 - mse: 115.1726 - val_loss: 3713.4021 - val_mse: 3713.4021\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2524.7095 - mse: 2524.7095 - val_loss: 15634.7383 - val_mse: 15634.7383\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10577.4922 - mse: 10577.4922 - val_loss: 33255.1289 - val_mse: 33255.1289\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 22488.5703 - mse: 22488.5703 - val_loss: 54405.8594 - val_mse: 54405.8594\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 36789.8750 - mse: 36789.8750 - val_loss: 77315.9609 - val_mse: 77315.9609\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 52282.2227 - mse: 52282.2227 - val_loss: 100583.1641 - val_mse: 100583.1641\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 68018.8516 - mse: 68018.8516 - val_loss: 123106.5078 - val_mse: 123106.5078\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 83254.9375 - mse: 83254.9375 - val_loss: 144075.7344 - val_mse: 144075.7344\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 97440.6484 - mse: 97440.6484 - val_loss: 162890.9062 - val_mse: 162890.9062\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 110165.0391 - mse: 110165.0391 - val_loss: 179150.1094 - val_mse: 179150.1094\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 121161.6875 - mse: 121161.6875 - val_loss: 192619.4844 - val_mse: 192619.4844\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 130277.1328 - mse: 130277.1328 - val_loss: 203203.6875 - val_mse: 203203.6875\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 137434.5469 - mse: 137434.5469 - val_loss: 210895.7969 - val_mse: 210895.7969\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 142637.1406 - mse: 142637.1406 - val_loss: 215795.6406 - val_mse: 215795.6406\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 145951.0000 - mse: 145951.0000 - val_loss: 218054.1250 - val_mse: 218054.1250\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 147483.4844 - mse: 147483.4844 - val_loss: 217876.2500 - val_mse: 217876.2500\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 147361.2969 - mse: 147361.2969 - val_loss: 215485.5000 - val_mse: 215485.5000\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 145745.6094 - mse: 145745.6094 - val_loss: 211155.2031 - val_mse: 211155.2031\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 142816.0156 - mse: 142816.0156 - val_loss: 205135.9531 - val_mse: 205135.9531\n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 138739.6250 - mse: 138739.6250 - val_loss: 197696.2969 - val_mse: 197696.2969\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 133712.1406 - mse: 133712.1406 - val_loss: 189105.0781 - val_mse: 189105.0781\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 127897.2422 - mse: 127897.2422 - val_loss: 179591.4844 - val_mse: 179591.4844\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 121464.5078 - mse: 121464.5078 - val_loss: 169405.8438 - val_mse: 169405.8438\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 114570.8359 - mse: 114570.8359 - val_loss: 158756.6094 - val_mse: 158756.6094\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107366.4062 - mse: 107366.4062 - val_loss: 147844.2188 - val_mse: 147844.2188\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 99987.8125 - mse: 99987.8125 - val_loss: 136835.7656 - val_mse: 136835.7656\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 92541.8047 - mse: 92541.8047 - val_loss: 125891.4922 - val_mse: 125891.4922\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 85136.8359 - mse: 85136.8359 - val_loss: 115137.7422 - val_mse: 115137.7422\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 77864.3984 - mse: 77864.3984 - val_loss: 104684.1172 - val_mse: 104684.1172\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 70793.5625 - mse: 70793.5625 - val_loss: 94630.5547 - val_mse: 94630.5547\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 63989.2031 - mse: 63989.2031 - val_loss: 85035.2891 - val_mse: 85035.2891\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 57501.7344 - mse: 57501.7344 - val_loss: 75968.3594 - val_mse: 75968.3594\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 51367.4570 - mse: 51367.4570 - val_loss: 67460.0703 - val_mse: 67460.0703\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 45616.9258 - mse: 45616.9258 - val_loss: 59540.3594 - val_mse: 59540.3594\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 40259.1758 - mse: 40259.1758 - val_loss: 52223.4062 - val_mse: 52223.4062\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 35310.8516 - mse: 35310.8516 - val_loss: 45512.5195 - val_mse: 45512.5195\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 30773.5566 - mse: 30773.5566 - val_loss: 39395.4883 - val_mse: 39395.4883\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26637.5176 - mse: 26637.5176 - val_loss: 33860.4648 - val_mse: 33860.4648\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22894.8535 - mse: 22894.8535 - val_loss: 28892.7090 - val_mse: 28892.7090\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19536.3535 - mse: 19536.3535 - val_loss: 24456.6777 - val_mse: 24456.6777\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16537.3359 - mse: 16537.3359 - val_loss: 20530.6758 - val_mse: 20530.6758\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 13882.8350 - mse: 13882.8350 - val_loss: 17079.5996 - val_mse: 17079.5996\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11551.1143 - mse: 11551.1143 - val_loss: 14069.4414 - val_mse: 14069.4414\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9516.0713 - mse: 9516.0713 - val_loss: 11466.3662 - val_mse: 11466.3662\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7757.0122 - mse: 7757.0122 - val_loss: 9233.7969 - val_mse: 9233.7969\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6248.8125 - mse: 6248.8125 - val_loss: 7335.6880 - val_mse: 7335.6880\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4966.2485 - mse: 4966.2485 - val_loss: 5741.1001 - val_mse: 5741.1001\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3889.7737 - mse: 3889.7737 - val_loss: 4414.0679 - val_mse: 4414.0679\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2993.7151 - mse: 2993.7151 - val_loss: 3325.0637 - val_mse: 3325.0637\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2258.7390 - mse: 2258.7390 - val_loss: 2444.1387 - val_mse: 2444.1387\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1664.0312 - mse: 1664.0312 - val_loss: 1742.7465 - val_mse: 1742.7465\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1191.5094 - mse: 1191.5094 - val_loss: 1196.9481 - val_mse: 1196.9481\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 823.8317 - mse: 823.8317 - val_loss: 782.3331 - val_mse: 782.3331\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 544.7167 - mse: 544.7167 - val_loss: 478.3378 - val_mse: 478.3378\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 340.0566 - mse: 340.0566 - val_loss: 265.6021 - val_mse: 265.6021\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 197.5315 - mse: 197.5315 - val_loss: 127.5060 - val_mse: 127.5060\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 105.1761 - mse: 105.1761 - val_loss: 49.0144 - val_mse: 49.0144\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 53.1039 - mse: 53.1039 - val_loss: 17.0606 - val_mse: 17.0606\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 32.4310 - mse: 32.4310 - val_loss: 20.5256 - val_mse: 20.5256\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 35.6348 - mse: 35.6348 - val_loss: 49.8502 - val_mse: 49.8502\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 56.1711 - mse: 56.1711 - val_loss: 96.7503 - val_mse: 96.7503\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 88.6026 - mse: 88.6026 - val_loss: 154.8746 - val_mse: 154.8746\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 128.5695 - mse: 128.5695 - val_loss: 218.5160 - val_mse: 218.5160\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 172.1292 - mse: 172.1292 - val_loss: 283.5230 - val_mse: 283.5230\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 216.6175 - mse: 216.6175 - val_loss: 346.3192 - val_mse: 346.3192\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 259.2870 - mse: 259.2870 - val_loss: 404.3643 - val_mse: 404.3643\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 299.0242 - mse: 299.0242 - val_loss: 456.1217 - val_mse: 456.1217\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 334.2064 - mse: 334.2064 - val_loss: 499.8987 - val_mse: 499.8987\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 363.9291 - mse: 363.9291 - val_loss: 535.3400 - val_mse: 535.3400\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 388.3702 - mse: 388.3702 - val_loss: 562.3071 - val_mse: 562.3071\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 406.5125 - mse: 406.5125 - val_loss: 580.7059 - val_mse: 580.7059\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 418.7753 - mse: 418.7753 - val_loss: 590.5995 - val_mse: 590.5995\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 425.3754 - mse: 425.3754 - val_loss: 592.7911 - val_mse: 592.7911\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 426.8559 - mse: 426.8559 - val_loss: 588.2966 - val_mse: 588.2966\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 423.8230 - mse: 423.8230 - val_loss: 577.2443 - val_mse: 577.2443\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 416.3642 - mse: 416.3642 - val_loss: 561.0081 - val_mse: 561.0081\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 405.0767 - mse: 405.0767 - val_loss: 540.1096 - val_mse: 540.1096\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 390.8017 - mse: 390.8017 - val_loss: 515.2968 - val_mse: 515.2968\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 373.8247 - mse: 373.8247 - val_loss: 487.9030 - val_mse: 487.9030\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 354.9851 - mse: 354.9851 - val_loss: 458.1513 - val_mse: 458.1513\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 334.6374 - mse: 334.6374 - val_loss: 426.7942 - val_mse: 426.7942\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 313.2788 - mse: 313.2788 - val_loss: 395.3127 - val_mse: 395.3127\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 291.5395 - mse: 291.5395 - val_loss: 363.4125 - val_mse: 363.4125\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 269.6120 - mse: 269.6120 - val_loss: 331.6650 - val_mse: 331.6650\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 247.8648 - mse: 247.8648 - val_loss: 300.4649 - val_mse: 300.4649\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 226.6220 - mse: 226.6220 - val_loss: 270.8253 - val_mse: 270.8253\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 206.0203 - mse: 206.0203 - val_loss: 242.2586 - val_mse: 242.2586\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 186.4170 - mse: 186.4170 - val_loss: 215.0845 - val_mse: 215.0845\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 167.8634 - mse: 167.8634 - val_loss: 189.9660 - val_mse: 189.9660\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 150.5494 - mse: 150.5494 - val_loss: 166.8017 - val_mse: 166.8017\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 134.6503 - mse: 134.6503 - val_loss: 145.4906 - val_mse: 145.4906\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 119.8965 - mse: 119.8965 - val_loss: 126.2063 - val_mse: 126.2063\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 106.5170 - mse: 106.5170 - val_loss: 108.7362 - val_mse: 108.7362\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 94.4140 - mse: 94.4140 - val_loss: 93.1789 - val_mse: 93.1789\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 83.5651 - mse: 83.5651 - val_loss: 79.5667 - val_mse: 79.5667\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 74.0849 - mse: 74.0849 - val_loss: 67.4380 - val_mse: 67.4380\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 65.6425 - mse: 65.6425 - val_loss: 57.0826 - val_mse: 57.0826\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 58.3924 - mse: 58.3924 - val_loss: 48.1578 - val_mse: 48.1578\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 52.0645 - mse: 52.0645 - val_loss: 40.5591 - val_mse: 40.5591\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 46.6874 - mse: 46.6874 - val_loss: 34.2833 - val_mse: 34.2833\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 42.1933 - mse: 42.1933 - val_loss: 29.0371 - val_mse: 29.0371\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 38.3658 - mse: 38.3658 - val_loss: 24.8542 - val_mse: 24.8542\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 35.2740 - mse: 35.2740 - val_loss: 21.4264 - val_mse: 21.4264\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 32.7043 - mse: 32.7043 - val_loss: 18.7345 - val_mse: 18.7345\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 30.6401 - mse: 30.6401 - val_loss: 16.4280 - val_mse: 16.4280\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 28.8342 - mse: 28.8342 - val_loss: 13.3486 - val_mse: 13.3486\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.1188 - mse: 27.1188 - val_loss: 12.8666 - val_mse: 12.8666\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.7268 - mse: 27.7268 - val_loss: 10.8815 - val_mse: 10.8815\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.3990 - mse: 25.3990 - val_loss: 12.8157 - val_mse: 12.8157\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.6621 - mse: 25.6621 - val_loss: 13.2882 - val_mse: 13.2882\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.7860 - mse: 25.7860 - val_loss: 13.5416 - val_mse: 13.5416\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.8970 - mse: 25.8970 - val_loss: 13.8117 - val_mse: 13.8117\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.0253 - mse: 26.0253 - val_loss: 14.1267 - val_mse: 14.1267\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.1780 - mse: 26.1780 - val_loss: 14.4877 - val_mse: 14.4877\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.3445 - mse: 26.3445 - val_loss: 14.8585 - val_mse: 14.8585\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.5178 - mse: 26.5178 - val_loss: 15.2150 - val_mse: 15.2150\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.6867 - mse: 26.6867 - val_loss: 15.5417 - val_mse: 15.5417\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.8324 - mse: 26.8324 - val_loss: 15.8844 - val_mse: 15.8844\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.9695 - mse: 26.9695 - val_loss: 16.1299 - val_mse: 16.1299\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.0645 - mse: 27.0645 - val_loss: 16.3713 - val_mse: 16.3713\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.1388 - mse: 27.1388 - val_loss: 16.5173 - val_mse: 16.5173\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.1673 - mse: 27.1673 - val_loss: 16.6083 - val_mse: 16.6083\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.1677 - mse: 27.1677 - val_loss: 16.6896 - val_mse: 16.6896\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.1403 - mse: 27.1403 - val_loss: 16.6850 - val_mse: 16.6850\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.0772 - mse: 27.0772 - val_loss: 16.6622 - val_mse: 16.6622\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.9948 - mse: 26.9948 - val_loss: 16.5920 - val_mse: 16.5920\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.8770 - mse: 26.8770 - val_loss: 16.4766 - val_mse: 16.4766\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.7434 - mse: 26.7434 - val_loss: 16.3282 - val_mse: 16.3282\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.5892 - mse: 26.5892 - val_loss: 16.1723 - val_mse: 16.1723\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.4210 - mse: 26.4210 - val_loss: 15.9915 - val_mse: 15.9915\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.2460 - mse: 26.2460 - val_loss: 15.8248 - val_mse: 15.8248\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.0640 - mse: 26.0640 - val_loss: 15.6156 - val_mse: 15.6156\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.8600 - mse: 25.8600 - val_loss: 15.3995 - val_mse: 15.3995\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 25.6564 - mse: 25.6564 - val_loss: 15.1857 - val_mse: 15.1857\n",
      "Epoch 315/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 25.4515 - mse: 25.4515 - val_loss: 14.9851 - val_mse: 14.9851\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.2415 - mse: 25.2415 - val_loss: 14.7822 - val_mse: 14.7822\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 25.0270 - mse: 25.0270 - val_loss: 14.5770 - val_mse: 14.5770\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.8089 - mse: 24.8089 - val_loss: 14.3726 - val_mse: 14.3726\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.5805 - mse: 24.5805 - val_loss: 14.1923 - val_mse: 14.1923\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.3450 - mse: 24.3450 - val_loss: 14.0067 - val_mse: 14.0067\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.0832 - mse: 24.0832 - val_loss: 13.8490 - val_mse: 13.8490\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.7918 - mse: 23.7918 - val_loss: 13.6998 - val_mse: 13.6998\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.4615 - mse: 23.4615 - val_loss: 13.5649 - val_mse: 13.5649\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.0565 - mse: 23.0565 - val_loss: 13.4311 - val_mse: 13.4311\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 22.5546 - mse: 22.5546 - val_loss: 13.3046 - val_mse: 13.3046\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.9029 - mse: 21.9029 - val_loss: 13.1847 - val_mse: 13.1847\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.0447 - mse: 21.0447 - val_loss: 13.0557 - val_mse: 13.0557\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.8687 - mse: 19.8687 - val_loss: 12.8642 - val_mse: 12.8642\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.2369 - mse: 18.2369 - val_loss: 12.4179 - val_mse: 12.4179\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 15.9269 - mse: 15.9269 - val_loss: 11.1285 - val_mse: 11.1285\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12.6912 - mse: 12.6912 - val_loss: 7.3641 - val_mse: 7.3641\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4299 - mse: 8.4299 - val_loss: 0.4859 - val_mse: 0.4859\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9661 - mse: 3.9661 - val_loss: 97.1590 - val_mse: 97.1590\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3184 - mse: 7.3184 - val_loss: 26.3412 - val_mse: 26.3412\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9450 - mse: 2.9450 - val_loss: 4.3938 - val_mse: 4.3938\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7260 - mse: 2.7260 - val_loss: 0.4145 - val_mse: 0.4145\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3081 - mse: 3.3081 - val_loss: 0.5235 - val_mse: 0.5235\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9357 - mse: 3.9357 - val_loss: 1.1789 - val_mse: 1.1789\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3888 - mse: 4.3888 - val_loss: 1.5612 - val_mse: 1.5612\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5950 - mse: 4.5950 - val_loss: 1.5309 - val_mse: 1.5309\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5518 - mse: 4.5518 - val_loss: 1.1411 - val_mse: 1.1411\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2914 - mse: 4.2914 - val_loss: 0.5701 - val_mse: 0.5701\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8659 - mse: 3.8659 - val_loss: 0.2399 - val_mse: 0.2399\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3544 - mse: 3.3544 - val_loss: 1.0811 - val_mse: 1.0811\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8620 - mse: 2.8620 - val_loss: 4.9275 - val_mse: 4.9275\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5152 - mse: 2.5152 - val_loss: 14.4829 - val_mse: 14.4829\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4856 - mse: 2.4856 - val_loss: 30.1519 - val_mse: 30.1519\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9093 - mse: 2.9093 - val_loss: 40.0400 - val_mse: 40.0400\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3116 - mse: 3.3116 - val_loss: 31.1871 - val_mse: 31.1871\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9294 - mse: 2.9294 - val_loss: 17.3229 - val_mse: 17.3229\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4934 - mse: 2.4934 - val_loss: 8.3327 - val_mse: 8.3327\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3818 - mse: 2.3818 - val_loss: 3.8747 - val_mse: 3.8747\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4605 - mse: 2.4605 - val_loss: 1.9179 - val_mse: 1.9179\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5903 - mse: 2.5903 - val_loss: 1.1433 - val_mse: 1.1433\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6918 - mse: 2.6918 - val_loss: 0.9161 - val_mse: 0.9161\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7279 - mse: 2.7279 - val_loss: 1.0138 - val_mse: 1.0138\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6925 - mse: 2.6925 - val_loss: 1.4619 - val_mse: 1.4619\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5989 - mse: 2.5989 - val_loss: 2.4589 - val_mse: 2.4589\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4768 - mse: 2.4768 - val_loss: 4.3201 - val_mse: 4.3201\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3640 - mse: 2.3640 - val_loss: 7.3424 - val_mse: 7.3424\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2971 - mse: 2.2971 - val_loss: 11.4915 - val_mse: 11.4915\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3012 - mse: 2.3012 - val_loss: 15.9028 - val_mse: 15.9028\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3614 - mse: 2.3614 - val_loss: 18.7712 - val_mse: 18.7712\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4214 - mse: 2.4214 - val_loss: 18.5949 - val_mse: 18.5949\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4114 - mse: 2.4114 - val_loss: 15.7593 - val_mse: 15.7593\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3368 - mse: 2.3368 - val_loss: 11.9977 - val_mse: 11.9977\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2663 - mse: 2.2663 - val_loss: 8.6797 - val_mse: 8.6797\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2301 - mse: 2.2301 - val_loss: 6.2969 - val_mse: 6.2969\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2343 - mse: 2.2343 - val_loss: 4.8023 - val_mse: 4.8023\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2513 - mse: 2.2513 - val_loss: 3.9957 - val_mse: 3.9957\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2687 - mse: 2.2687 - val_loss: 3.7093 - val_mse: 3.7093\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2731 - mse: 2.2731 - val_loss: 3.8492 - val_mse: 3.8492\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2566 - mse: 2.2566 - val_loss: 4.3792 - val_mse: 4.3792\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2280 - mse: 2.2280 - val_loss: 5.3060 - val_mse: 5.3060\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1993 - mse: 2.1993 - val_loss: 6.6016 - val_mse: 6.6016\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1748 - mse: 2.1748 - val_loss: 8.1640 - val_mse: 8.1640\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1640 - mse: 2.1640 - val_loss: 9.7540 - val_mse: 9.7540\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1656 - mse: 2.1656 - val_loss: 11.0263 - val_mse: 11.0263\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1691 - mse: 2.1691 - val_loss: 11.6481 - val_mse: 11.6481\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.1715 - mse: 2.1715 - val_loss: 11.4728 - val_mse: 11.4728\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1612 - mse: 2.1612 - val_loss: 10.6265 - val_mse: 10.6265\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1448 - mse: 2.1448 - val_loss: 9.4162 - val_mse: 9.4162\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1273 - mse: 2.1273 - val_loss: 8.1584 - val_mse: 8.1584\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1156 - mse: 2.1156 - val_loss: 7.0671 - val_mse: 7.0671\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1095 - mse: 2.1095 - val_loss: 6.2461 - val_mse: 6.2461\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1073 - mse: 2.1073 - val_loss: 5.7218 - val_mse: 5.7218\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1057 - mse: 2.1057 - val_loss: 5.4851 - val_mse: 5.4851\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0995 - mse: 2.0995 - val_loss: 5.5034 - val_mse: 5.5034\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0930 - mse: 2.0930 - val_loss: 5.7510 - val_mse: 5.7510\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0833 - mse: 2.0833 - val_loss: 6.1860 - val_mse: 6.1860\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0726 - mse: 2.0726 - val_loss: 6.7556 - val_mse: 6.7556\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0629 - mse: 2.0629 - val_loss: 7.3830 - val_mse: 7.3830\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0551 - mse: 2.0551 - val_loss: 7.9716 - val_mse: 7.9716\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0503 - mse: 2.0503 - val_loss: 8.4181 - val_mse: 8.4181\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0463 - mse: 2.0463 - val_loss: 8.6435 - val_mse: 8.6435\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0414 - mse: 2.0414 - val_loss: 8.6154 - val_mse: 8.6154\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0350 - mse: 2.0350 - val_loss: 8.3587 - val_mse: 8.3587\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0271 - mse: 2.0271 - val_loss: 7.9424 - val_mse: 7.9424\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0187 - mse: 2.0187 - val_loss: 7.4547 - val_mse: 7.4547\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0109 - mse: 2.0109 - val_loss: 6.9764 - val_mse: 6.9764\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0037 - mse: 2.0037 - val_loss: 6.5679 - val_mse: 6.5679\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9974 - mse: 1.9974 - val_loss: 6.2655 - val_mse: 6.2655\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9915 - mse: 1.9915 - val_loss: 6.0845 - val_mse: 6.0845\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9853 - mse: 1.9853 - val_loss: 6.0256 - val_mse: 6.0256\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9785 - mse: 1.9785 - val_loss: 6.0766 - val_mse: 6.0766\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9711 - mse: 1.9711 - val_loss: 6.2176 - val_mse: 6.2176\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9632 - mse: 1.9632 - val_loss: 6.4202 - val_mse: 6.4202\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9554 - mse: 1.9554 - val_loss: 6.6493 - val_mse: 6.6493\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9478 - mse: 1.9478 - val_loss: 6.8675 - val_mse: 6.8675\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9405 - mse: 1.9405 - val_loss: 7.0385 - val_mse: 7.0385\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.9333 - mse: 1.9333 - val_loss: 7.1351 - val_mse: 7.1351\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9241 - mse: 1.9241 - val_loss: 7.1432 - val_mse: 7.1432\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9164 - mse: 1.9164 - val_loss: 7.0645 - val_mse: 7.0645\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9082 - mse: 1.9082 - val_loss: 6.9148 - val_mse: 6.9148\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8997 - mse: 1.8997 - val_loss: 6.7197 - val_mse: 6.7197\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8908 - mse: 1.8908 - val_loss: 6.5076 - val_mse: 6.5076\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.8818 - mse: 1.8818 - val_loss: 6.3059 - val_mse: 6.3059\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8732 - mse: 1.8732 - val_loss: 6.1339 - val_mse: 6.1339\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8642 - mse: 1.8642 - val_loss: 6.0038 - val_mse: 6.0038\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8546 - mse: 1.8546 - val_loss: 5.9222 - val_mse: 5.9222\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8445 - mse: 1.8445 - val_loss: 5.8877 - val_mse: 5.8877\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8340 - mse: 1.8340 - val_loss: 5.8953 - val_mse: 5.8953\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8227 - mse: 1.8227 - val_loss: 5.9330 - val_mse: 5.9330\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8110 - mse: 1.8110 - val_loss: 5.9877 - val_mse: 5.9877\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7987 - mse: 1.7987 - val_loss: 6.0438 - val_mse: 6.0438\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7854 - mse: 1.7854 - val_loss: 6.0880 - val_mse: 6.0880\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7716 - mse: 1.7716 - val_loss: 6.1077 - val_mse: 6.1077\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7569 - mse: 1.7569 - val_loss: 6.0956 - val_mse: 6.0956\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7410 - mse: 1.7410 - val_loss: 6.0484 - val_mse: 6.0484\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7239 - mse: 1.7239 - val_loss: 5.9683 - val_mse: 5.9683\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7053 - mse: 1.7053 - val_loss: 5.8615 - val_mse: 5.8615\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6850 - mse: 1.6850 - val_loss: 5.7361 - val_mse: 5.7361\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6627 - mse: 1.6627 - val_loss: 5.6008 - val_mse: 5.6008\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6383 - mse: 1.6383 - val_loss: 5.4642 - val_mse: 5.4642\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6113 - mse: 1.6113 - val_loss: 5.3318 - val_mse: 5.3318\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5812 - mse: 1.5812 - val_loss: 5.2056 - val_mse: 5.2056\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5476 - mse: 1.5476 - val_loss: 5.0856 - val_mse: 5.0856\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5105 - mse: 1.5105 - val_loss: 4.9682 - val_mse: 4.9682\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4682 - mse: 1.4682 - val_loss: 4.8464 - val_mse: 4.8464\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4208 - mse: 1.4208 - val_loss: 4.7110 - val_mse: 4.7110\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3676 - mse: 1.3676 - val_loss: 4.5508 - val_mse: 4.5508\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3087 - mse: 1.3087 - val_loss: 4.3532 - val_mse: 4.3532\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2445 - mse: 1.2445 - val_loss: 4.1053 - val_mse: 4.1053\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1768 - mse: 1.1768 - val_loss: 3.7964 - val_mse: 3.7964\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1093 - mse: 1.1093 - val_loss: 3.4210 - val_mse: 3.4210\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0485 - mse: 1.0485 - val_loss: 2.9827 - val_mse: 2.9827\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0036 - mse: 1.0036 - val_loss: 2.4969 - val_mse: 2.4969\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9830 - mse: 0.9830 - val_loss: 1.9809 - val_mse: 1.9809\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9823 - mse: 0.9823 - val_loss: 1.4451 - val_mse: 1.4451\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9783 - mse: 0.9783 - val_loss: 0.9273 - val_mse: 0.9273\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9479 - mse: 0.9479 - val_loss: 0.5334 - val_mse: 0.5334\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9045 - mse: 0.9045 - val_loss: 0.3504 - val_mse: 0.3504\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8815 - mse: 0.8815 - val_loss: 0.3555 - val_mse: 0.3555\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8880 - mse: 0.8880 - val_loss: 0.4538 - val_mse: 0.4538\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9044 - mse: 0.9044 - val_loss: 0.5523 - val_mse: 0.5523\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9079 - mse: 0.9079 - val_loss: 0.5955 - val_mse: 0.5955\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8926 - mse: 0.8926 - val_loss: 0.5715 - val_mse: 0.5715\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8750 - mse: 0.8750 - val_loss: 0.5146 - val_mse: 0.5146\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8775 - mse: 0.8775 - val_loss: 0.4796 - val_mse: 0.4796\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8952 - mse: 0.8952 - val_loss: 0.4932 - val_mse: 0.4932\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8952 - mse: 0.8952 - val_loss: 0.5769 - val_mse: 0.5769\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8782 - mse: 0.8782 - val_loss: 0.7293 - val_mse: 0.7293\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8733 - mse: 0.8733 - val_loss: 0.8780 - val_mse: 0.8780\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8834 - mse: 0.8834 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8890 - mse: 0.8890 - val_loss: 0.9043 - val_mse: 0.9043\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8817 - mse: 0.8817 - val_loss: 0.7821 - val_mse: 0.7821\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8728 - mse: 0.8728 - val_loss: 0.6523 - val_mse: 0.6523\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8756 - mse: 0.8756 - val_loss: 0.5872 - val_mse: 0.5872\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8828 - mse: 0.8828 - val_loss: 0.6111 - val_mse: 0.6111\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8797 - mse: 0.8797 - val_loss: 0.7143 - val_mse: 0.7143\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8725 - mse: 0.8725 - val_loss: 0.8469 - val_mse: 0.8469\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8734 - mse: 0.8734 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8781 - mse: 0.8781 - val_loss: 0.9322 - val_mse: 0.9322\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8776 - mse: 0.8776 - val_loss: 0.8484 - val_mse: 0.8484\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8728 - mse: 0.8728 - val_loss: 0.7352 - val_mse: 0.7352\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8716 - mse: 0.8716 - val_loss: 0.6569 - val_mse: 0.6569\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8749 - mse: 0.8749 - val_loss: 0.6489 - val_mse: 0.6489\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8754 - mse: 0.8754 - val_loss: 0.7094 - val_mse: 0.7094\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8721 - mse: 0.8721 - val_loss: 0.8048 - val_mse: 0.8048\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8711 - mse: 0.8711 - val_loss: 0.8807 - val_mse: 0.8807\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8732 - mse: 0.8732 - val_loss: 0.8951 - val_mse: 0.8951\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8737 - mse: 0.8737 - val_loss: 0.8452 - val_mse: 0.8452\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8717 - mse: 0.8717 - val_loss: 0.7638 - val_mse: 0.7638\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8706 - mse: 0.8706 - val_loss: 0.6989 - val_mse: 0.6989\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8718 - mse: 0.8718 - val_loss: 0.6825 - val_mse: 0.6825\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8723 - mse: 0.8723 - val_loss: 0.7185 - val_mse: 0.7185\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8709 - mse: 0.8709 - val_loss: 0.7841 - val_mse: 0.7841\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8702 - mse: 0.8702 - val_loss: 0.8403 - val_mse: 0.8403\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8710 - mse: 0.8710 - val_loss: 0.8548 - val_mse: 0.8548\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8712 - mse: 0.8712 - val_loss: 0.8221 - val_mse: 0.8221\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8703 - mse: 0.8703 - val_loss: 0.7644 - val_mse: 0.7644\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8697 - mse: 0.8697 - val_loss: 0.7161 - val_mse: 0.7161\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8702 - mse: 0.8702 - val_loss: 0.7020 - val_mse: 0.7020\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8704 - mse: 0.8704 - val_loss: 0.7261 - val_mse: 0.7261\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8697 - mse: 0.8697 - val_loss: 0.7712 - val_mse: 0.7712\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8692 - mse: 0.8692 - val_loss: 0.8086 - val_mse: 0.8086\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8694 - mse: 0.8694 - val_loss: 0.8159 - val_mse: 0.8159\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8695 - mse: 0.8695 - val_loss: 0.7894 - val_mse: 0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8690 - mse: 0.8690 - val_loss: 0.7465 - val_mse: 0.7465\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8687 - mse: 0.8687 - val_loss: 0.7121 - val_mse: 0.7121\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8687 - mse: 0.8687 - val_loss: 0.7036 - val_mse: 0.7036\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8687 - mse: 0.8687 - val_loss: 0.7216 - val_mse: 0.7216\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8682 - mse: 0.8682 - val_loss: 0.7519 - val_mse: 0.7519\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8680 - mse: 0.8680 - val_loss: 0.7729 - val_mse: 0.7729\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8680 - mse: 0.8680 - val_loss: 0.7699 - val_mse: 0.7699\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8677 - mse: 0.8677 - val_loss: 0.7437 - val_mse: 0.7437\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8673 - mse: 0.8673 - val_loss: 0.7097 - val_mse: 0.7097\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8670 - mse: 0.8670 - val_loss: 0.6858 - val_mse: 0.6858\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8669 - mse: 0.8669 - val_loss: 0.6822 - val_mse: 0.6822\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8666 - mse: 0.8666 - val_loss: 0.6957 - val_mse: 0.6957\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8662 - mse: 0.8662 - val_loss: 0.7124 - val_mse: 0.7124\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8658 - mse: 0.8658 - val_loss: 0.7169 - val_mse: 0.7169\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8655 - mse: 0.8655 - val_loss: 0.7022 - val_mse: 0.7022\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8644 - mse: 0.8644 - val_loss: 0.6738 - val_mse: 0.6738\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8638 - mse: 0.8638 - val_loss: 0.6455 - val_mse: 0.6455\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8635 - mse: 0.8635 - val_loss: 0.6288 - val_mse: 0.6288\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8631 - mse: 0.8631 - val_loss: 0.6267 - val_mse: 0.6267\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8624 - mse: 0.8624 - val_loss: 0.6320 - val_mse: 0.6320\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8618 - mse: 0.8618 - val_loss: 0.6324 - val_mse: 0.6324\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8613 - mse: 0.8613 - val_loss: 0.6191 - val_mse: 0.6191\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8605 - mse: 0.8605 - val_loss: 0.5928 - val_mse: 0.5928\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8598 - mse: 0.8598 - val_loss: 0.5624 - val_mse: 0.5624\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8590 - mse: 0.8590 - val_loss: 0.5378 - val_mse: 0.5378\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8581 - mse: 0.8581 - val_loss: 0.5232 - val_mse: 0.5232\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8570 - mse: 0.8570 - val_loss: 0.5153 - val_mse: 0.5153\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8560 - mse: 0.8560 - val_loss: 0.5051 - val_mse: 0.5051\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8549 - mse: 0.8549 - val_loss: 0.4855 - val_mse: 0.4855\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8536 - mse: 0.8536 - val_loss: 0.4561 - val_mse: 0.4561\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8520 - mse: 0.8520 - val_loss: 0.4228 - val_mse: 0.4228\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8504 - mse: 0.8504 - val_loss: 0.3934 - val_mse: 0.3934\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8487 - mse: 0.8487 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8467 - mse: 0.8467 - val_loss: 0.3517 - val_mse: 0.3517\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8447 - mse: 0.8447 - val_loss: 0.3316 - val_mse: 0.3316\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8425 - mse: 0.8425 - val_loss: 0.3068 - val_mse: 0.3068\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8401 - mse: 0.8401 - val_loss: 0.2790 - val_mse: 0.2790\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8374 - mse: 0.8374 - val_loss: 0.2535 - val_mse: 0.2535\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8344 - mse: 0.8344 - val_loss: 0.2345 - val_mse: 0.2345\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8312 - mse: 0.8312 - val_loss: 0.2219 - val_mse: 0.2219\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8277 - mse: 0.8277 - val_loss: 0.2139 - val_mse: 0.2139\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8239 - mse: 0.8239 - val_loss: 0.2113 - val_mse: 0.2113\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8198 - mse: 0.8198 - val_loss: 0.2177 - val_mse: 0.2177\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8156 - mse: 0.8156 - val_loss: 0.2371 - val_mse: 0.2371\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8109 - mse: 0.8109 - val_loss: 0.2682 - val_mse: 0.2682\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8062 - mse: 0.8062 - val_loss: 0.3051 - val_mse: 0.3051\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8011 - mse: 0.8011 - val_loss: 0.3468 - val_mse: 0.3468\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7963 - mse: 0.7963 - val_loss: 0.4014 - val_mse: 0.4014\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7914 - mse: 0.7914 - val_loss: 0.4756 - val_mse: 0.4756\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7868 - mse: 0.7868 - val_loss: 0.5601 - val_mse: 0.5601\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7824 - mse: 0.7824 - val_loss: 0.6343 - val_mse: 0.6343\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7783 - mse: 0.7783 - val_loss: 0.6995 - val_mse: 0.6995\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7746 - mse: 0.7746 - val_loss: 0.7809 - val_mse: 0.7809\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7715 - mse: 0.7715 - val_loss: 0.8790 - val_mse: 0.8790\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7689 - mse: 0.7689 - val_loss: 0.9574 - val_mse: 0.9574\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7669 - mse: 0.7669 - val_loss: 1.0117 - val_mse: 1.0117\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7654 - mse: 0.7654 - val_loss: 1.0861 - val_mse: 1.0861\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7643 - mse: 0.7643 - val_loss: 1.1705 - val_mse: 1.1705\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7643 - mse: 0.7643 - val_loss: 1.2168 - val_mse: 1.2168\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7640 - mse: 0.7640 - val_loss: 1.2579 - val_mse: 1.2579\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7639 - mse: 0.7639 - val_loss: 1.3272 - val_mse: 1.3272\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7642 - mse: 0.7642 - val_loss: 1.3663 - val_mse: 1.3663\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7644 - mse: 0.7644 - val_loss: 1.3829 - val_mse: 1.3829\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7647 - mse: 0.7647 - val_loss: 1.4314 - val_mse: 1.4314\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7627 - mse: 0.7627 - val_loss: 1.4578 - val_mse: 1.4578\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7631 - mse: 0.7631 - val_loss: 1.4576 - val_mse: 1.4576\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7635 - mse: 0.7635 - val_loss: 1.4900 - val_mse: 1.4900\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7636 - mse: 0.7636 - val_loss: 1.4983 - val_mse: 1.4983\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7638 - mse: 0.7638 - val_loss: 1.4882 - val_mse: 1.4882\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7638 - mse: 0.7638 - val_loss: 1.5069 - val_mse: 1.5069\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7638 - mse: 0.7638 - val_loss: 1.4993 - val_mse: 1.4993\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7637 - mse: 0.7637 - val_loss: 1.4842 - val_mse: 1.4842\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7637 - mse: 0.7637 - val_loss: 1.4902 - val_mse: 1.4902\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7634 - mse: 0.7634 - val_loss: 1.4720 - val_mse: 1.4720\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7632 - mse: 0.7632 - val_loss: 1.4549 - val_mse: 1.4549\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7628 - mse: 0.7628 - val_loss: 1.4501 - val_mse: 1.4501\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7625 - mse: 0.7625 - val_loss: 1.4282 - val_mse: 1.4282\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7622 - mse: 0.7622 - val_loss: 1.4085 - val_mse: 1.4085\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7620 - mse: 0.7620 - val_loss: 1.3989 - val_mse: 1.3989\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7616 - mse: 0.7616 - val_loss: 1.3762 - val_mse: 1.3762\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7613 - mse: 0.7613 - val_loss: 1.3557 - val_mse: 1.3557\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7611 - mse: 0.7611 - val_loss: 1.3441 - val_mse: 1.3441\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7610 - mse: 0.7610 - val_loss: 1.3245 - val_mse: 1.3245\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7608 - mse: 0.7608 - val_loss: 1.3044 - val_mse: 1.3044\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7607 - mse: 0.7607 - val_loss: 1.2936 - val_mse: 1.2936\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7605 - mse: 0.7605 - val_loss: 1.2777 - val_mse: 1.2777\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7605 - mse: 0.7605 - val_loss: 1.2596 - val_mse: 1.2596\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7605 - mse: 0.7605 - val_loss: 1.2518 - val_mse: 1.2518\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7604 - mse: 0.7604 - val_loss: 1.2414 - val_mse: 1.2414\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7604 - mse: 0.7604 - val_loss: 1.2255 - val_mse: 1.2255\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 1.2202 - val_mse: 1.2202\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 1.2159 - val_mse: 1.2159\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 1.2047 - val_mse: 1.2047\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 1.2008 - val_mse: 1.2008\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7604 - mse: 0.7604 - val_loss: 1.2014 - val_mse: 1.2014\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 1.1954 - val_mse: 1.1954\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 1.1929 - val_mse: 1.1929\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 1.1959 - val_mse: 1.1959\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 1.1957 - val_mse: 1.1957\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 1.1938 - val_mse: 1.1938\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7601 - mse: 0.7601 - val_loss: 1.1989 - val_mse: 1.1989\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7601 - mse: 0.7601 - val_loss: 1.2028 - val_mse: 1.2028\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7601 - mse: 0.7601 - val_loss: 1.2020 - val_mse: 1.2020\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7600 - mse: 0.7600 - val_loss: 1.2079 - val_mse: 1.2079\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7600 - mse: 0.7600 - val_loss: 1.2137 - val_mse: 1.2137\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7600 - mse: 0.7600 - val_loss: 1.2140 - val_mse: 1.2140\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7599 - mse: 0.7599 - val_loss: 1.2197 - val_mse: 1.2197\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7597 - mse: 0.7597 - val_loss: 1.2268 - val_mse: 1.2268\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7597 - mse: 0.7597 - val_loss: 1.2279 - val_mse: 1.2279\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7597 - mse: 0.7597 - val_loss: 1.2332 - val_mse: 1.2332\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7596 - mse: 0.7596 - val_loss: 1.2395 - val_mse: 1.2395\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7596 - mse: 0.7596 - val_loss: 1.2418 - val_mse: 1.2418\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7596 - mse: 0.7596 - val_loss: 1.2455 - val_mse: 1.2455\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7595 - mse: 0.7595 - val_loss: 1.2513 - val_mse: 1.2513\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7595 - mse: 0.7595 - val_loss: 1.2537 - val_mse: 1.2537\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7595 - mse: 0.7595 - val_loss: 1.2564 - val_mse: 1.2564\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7595 - mse: 0.7595 - val_loss: 1.2604 - val_mse: 1.2604\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7594 - mse: 0.7594 - val_loss: 1.2625 - val_mse: 1.2625\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7594 - mse: 0.7594 - val_loss: 1.2648 - val_mse: 1.2648\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 1.2669 - val_mse: 1.2669\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7594 - mse: 0.7594 - val_loss: 1.2693 - val_mse: 1.2693\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 1.2700 - val_mse: 1.2700\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 1.2720 - val_mse: 1.2720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 1.2727 - val_mse: 1.2727\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7593 - mse: 0.7593 - val_loss: 1.2727 - val_mse: 1.2727\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7592 - mse: 0.7592 - val_loss: 1.2743 - val_mse: 1.2743\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 1.2729 - val_mse: 1.2729\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7592 - mse: 0.7592 - val_loss: 1.2743 - val_mse: 1.2743\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 1.2735 - val_mse: 1.2735\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 1.2729 - val_mse: 1.2729\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 1.2735 - val_mse: 1.2735\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7590 - mse: 0.7590 - val_loss: 1.2726 - val_mse: 1.2726\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7590 - mse: 0.7590 - val_loss: 1.2708 - val_mse: 1.2708\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7590 - mse: 0.7590 - val_loss: 1.2714 - val_mse: 1.2714\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 1.2706 - val_mse: 1.2706\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 1.2689 - val_mse: 1.2689\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 1.2697 - val_mse: 1.2697\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 1.2677 - val_mse: 1.2677\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7588 - mse: 0.7588 - val_loss: 1.2665 - val_mse: 1.2665\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7588 - mse: 0.7588 - val_loss: 1.2680 - val_mse: 1.2680\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7587 - mse: 0.7587 - val_loss: 1.2650 - val_mse: 1.2650\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7587 - mse: 0.7587 - val_loss: 1.2645 - val_mse: 1.2645\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7587 - mse: 0.7587 - val_loss: 1.2672 - val_mse: 1.2672\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7586 - mse: 0.7586 - val_loss: 1.2629 - val_mse: 1.2629\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7586 - mse: 0.7586 - val_loss: 1.2622 - val_mse: 1.2622\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7585 - mse: 0.7585 - val_loss: 1.2661 - val_mse: 1.2661\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7586 - mse: 0.7586 - val_loss: 1.2633 - val_mse: 1.2633\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7585 - mse: 0.7585 - val_loss: 1.2602 - val_mse: 1.2602\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7585 - mse: 0.7585 - val_loss: 1.2645 - val_mse: 1.2645\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - mse: 0.7584 - val_loss: 1.2636 - val_mse: 1.2636\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7585 - mse: 0.7585 - val_loss: 1.2607 - val_mse: 1.2607\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - mse: 0.7584 - val_loss: 1.2636 - val_mse: 1.2636\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - mse: 0.7584 - val_loss: 1.2646 - val_mse: 1.2646\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - mse: 0.7584 - val_loss: 1.2608 - val_mse: 1.2608\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - mse: 0.7584 - val_loss: 1.2638 - val_mse: 1.2638\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7583 - mse: 0.7583 - val_loss: 1.2649 - val_mse: 1.2649\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7583 - mse: 0.7583 - val_loss: 1.2627 - val_mse: 1.2627\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7582 - mse: 0.7582 - val_loss: 1.2640 - val_mse: 1.2640\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7582 - mse: 0.7582 - val_loss: 1.2656 - val_mse: 1.2656\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7582 - mse: 0.7582 - val_loss: 1.2641 - val_mse: 1.2641\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7582 - mse: 0.7582 - val_loss: 1.2651 - val_mse: 1.2651\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7581 - mse: 0.7581 - val_loss: 1.2668 - val_mse: 1.2668\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7581 - mse: 0.7581 - val_loss: 1.2662 - val_mse: 1.2662\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7581 - mse: 0.7581 - val_loss: 1.2667 - val_mse: 1.2667\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7581 - mse: 0.7581 - val_loss: 1.2675 - val_mse: 1.2675\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7581 - mse: 0.7581 - val_loss: 1.2681 - val_mse: 1.2681\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 1.2682 - val_mse: 1.2682\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 1.2690 - val_mse: 1.2690\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2685 - val_mse: 1.2685\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 1.2696 - val_mse: 1.2696\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2703 - val_mse: 1.2703\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2698 - val_mse: 1.2698\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2704 - val_mse: 1.2704\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2709 - val_mse: 1.2709\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2707 - val_mse: 1.2707\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2715 - val_mse: 1.2715\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2724 - val_mse: 1.2724\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2713 - val_mse: 1.2713\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2721 - val_mse: 1.2721\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2734 - val_mse: 1.2734\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2724 - val_mse: 1.2724\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2729 - val_mse: 1.2729\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2737 - val_mse: 1.2737\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2728 - val_mse: 1.2728\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2735 - val_mse: 1.2735\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2734 - val_mse: 1.2734\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2740 - val_mse: 1.2740\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2738 - val_mse: 1.2738\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2737 - val_mse: 1.2737\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2748 - val_mse: 1.2748\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2743 - val_mse: 1.2743\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2744 - val_mse: 1.2744\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2749 - val_mse: 1.2749\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2749 - val_mse: 1.2749\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2744 - val_mse: 1.2744\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2761 - val_mse: 1.2761\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2747 - val_mse: 1.2747\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2755 - val_mse: 1.2755\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2767 - val_mse: 1.2767\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2743 - val_mse: 1.2743\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2771 - val_mse: 1.2771\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2764 - val_mse: 1.2764\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2758 - val_mse: 1.2758\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2772 - val_mse: 1.2772\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2768 - val_mse: 1.2768\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2765 - val_mse: 1.2765\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2772 - val_mse: 1.2772\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7570 - mse: 0.7570 - val_loss: 1.2782 - val_mse: 1.2782\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2774 - val_mse: 1.2774\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2776 - val_mse: 1.2776\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2786 - val_mse: 1.2786\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2790 - val_mse: 1.2790\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2789 - val_mse: 1.2789\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2805 - val_mse: 1.2805\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2801 - val_mse: 1.2801\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2795 - val_mse: 1.2795\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2814 - val_mse: 1.2814\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2807 - val_mse: 1.2807\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2801 - val_mse: 1.2801\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2816 - val_mse: 1.2816\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2815 - val_mse: 1.2815\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2813 - val_mse: 1.2813\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2813 - val_mse: 1.2813\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2826 - val_mse: 1.2826\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2832 - val_mse: 1.2832\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2836 - val_mse: 1.2836\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2855 - val_mse: 1.2855\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2843 - val_mse: 1.2843\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 1.2841 - val_mse: 1.2841\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 1.2856 - val_mse: 1.2856\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7580 - mse: 0.7580 - val_loss: 1.2851 - val_mse: 1.2851\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2843 - val_mse: 1.2843\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2866 - val_mse: 1.2866\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2850 - val_mse: 1.2850\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2855 - val_mse: 1.2855\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2878 - val_mse: 1.2878\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 1.2847 - val_mse: 1.2847\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2866 - val_mse: 1.2866\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2876 - val_mse: 1.2876\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7578 - mse: 0.7578 - val_loss: 1.2853 - val_mse: 1.2853\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2878 - val_mse: 1.2878\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2877 - val_mse: 1.2877\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2858 - val_mse: 1.2858\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2882 - val_mse: 1.2882\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2890 - val_mse: 1.2890\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7577 - mse: 0.7577 - val_loss: 1.2857 - val_mse: 1.2857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2890 - val_mse: 1.2890\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2891 - val_mse: 1.2891\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2866 - val_mse: 1.2866\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2905 - val_mse: 1.2905\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7576 - mse: 0.7576 - val_loss: 1.2897 - val_mse: 1.2897\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2861 - val_mse: 1.2861\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2928 - val_mse: 1.2928\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2879 - val_mse: 1.2879\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2895 - val_mse: 1.2895\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2913 - val_mse: 1.2913\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 1.2886 - val_mse: 1.2886\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2907 - val_mse: 1.2907\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2914 - val_mse: 1.2914\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2887 - val_mse: 1.2887\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2927 - val_mse: 1.2927\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7574 - mse: 0.7574 - val_loss: 1.2905 - val_mse: 1.2905\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2904 - val_mse: 1.2904\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2938 - val_mse: 1.2938\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2894 - val_mse: 1.2894\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2931 - val_mse: 1.2931\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 1.2924 - val_mse: 1.2924\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2911 - val_mse: 1.2911\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2928 - val_mse: 1.2928\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2931 - val_mse: 1.2931\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2911 - val_mse: 1.2911\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2948 - val_mse: 1.2948\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 1.2925 - val_mse: 1.2925\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2922 - val_mse: 1.2922\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2951 - val_mse: 1.2951\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2923 - val_mse: 1.2923\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 1.2935 - val_mse: 1.2935\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7570 - mse: 0.7570 - val_loss: 1.2954 - val_mse: 1.2954\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.2928 - val_mse: 1.2928\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.2953 - val_mse: 1.2953\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.2942 - val_mse: 1.2942\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.2942 - val_mse: 1.2942\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2956 - val_mse: 1.2956\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.2944 - val_mse: 1.2944\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2956 - val_mse: 1.2956\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2948 - val_mse: 1.2948\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2956 - val_mse: 1.2956\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2955 - val_mse: 1.2955\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2963 - val_mse: 1.2963\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2951 - val_mse: 1.2951\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2972 - val_mse: 1.2972\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2964 - val_mse: 1.2964\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2963 - val_mse: 1.2963\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2979 - val_mse: 1.2979\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2954 - val_mse: 1.2954\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.2979 - val_mse: 1.2979\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.2972 - val_mse: 1.2972\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.2978 - val_mse: 1.2978\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.3001 - val_mse: 1.3001\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.2976 - val_mse: 1.2976\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.3002 - val_mse: 1.3002\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2991 - val_mse: 1.2991\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2986 - val_mse: 1.2986\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.3008 - val_mse: 1.3008\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 1.2998 - val_mse: 1.2998\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.2993 - val_mse: 1.2993\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.3005 - val_mse: 1.3005\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.3001 - val_mse: 1.3001\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.3006 - val_mse: 1.3006\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.3007 - val_mse: 1.3007\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.3010 - val_mse: 1.3010\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7545 - mse: 0.7545 - val_loss: 1.3005 - val_mse: 1.3005\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.3007 - val_mse: 1.3007\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.3025 - val_mse: 1.3025\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.2996 - val_mse: 1.2996\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.3030 - val_mse: 1.3030\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.3021 - val_mse: 1.3021\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.3011 - val_mse: 1.3011\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3027 - val_mse: 1.3027\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 1.3021 - val_mse: 1.3021\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3024 - val_mse: 1.3024\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3027 - val_mse: 1.3027\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3017 - val_mse: 1.3017\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3035 - val_mse: 1.3035\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3035 - val_mse: 1.3035\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7543 - mse: 0.7543 - val_loss: 1.3026 - val_mse: 1.3026\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3039 - val_mse: 1.3039\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3036 - val_mse: 1.3036\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3029 - val_mse: 1.3029\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3039 - val_mse: 1.3039\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3039 - val_mse: 1.3039\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3035 - val_mse: 1.3035\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7541 - mse: 0.7541 - val_loss: 1.3062 - val_mse: 1.3062\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7542 - mse: 0.7542 - val_loss: 1.3032 - val_mse: 1.3032\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7541 - mse: 0.7541 - val_loss: 1.3043 - val_mse: 1.3043\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7541 - mse: 0.7541 - val_loss: 1.3063 - val_mse: 1.3063\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7541 - mse: 0.7541 - val_loss: 1.3037 - val_mse: 1.3037\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7541 - mse: 0.7541 - val_loss: 1.3050 - val_mse: 1.3050\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3057 - val_mse: 1.3057\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3051 - val_mse: 1.3051\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3068 - val_mse: 1.3068\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3044 - val_mse: 1.3044\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3067 - val_mse: 1.3067\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3063 - val_mse: 1.3063\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3053 - val_mse: 1.3053\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3079 - val_mse: 1.3079\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7539 - mse: 0.7539 - val_loss: 1.3056 - val_mse: 1.3056\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3066 - val_mse: 1.3066\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3077 - val_mse: 1.3077\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3069 - val_mse: 1.3069\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3070 - val_mse: 1.3070\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3074 - val_mse: 1.3074\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7538 - mse: 0.7538 - val_loss: 1.3070 - val_mse: 1.3070\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3080 - val_mse: 1.3080\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3073 - val_mse: 1.3073\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3078 - val_mse: 1.3078\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3079 - val_mse: 1.3079\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3080 - val_mse: 1.3080\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3082 - val_mse: 1.3082\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3097 - val_mse: 1.3097\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.3077 - val_mse: 1.3077\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3091 - val_mse: 1.3091\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3093 - val_mse: 1.3093\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3094 - val_mse: 1.3094\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3080 - val_mse: 1.3080\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3107 - val_mse: 1.3107\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3087 - val_mse: 1.3087\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7535 - mse: 0.7535 - val_loss: 1.3102 - val_mse: 1.3102\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3105 - val_mse: 1.3105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3078 - val_mse: 1.3078\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7535 - mse: 0.7535 - val_loss: 1.3119 - val_mse: 1.3119\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.3091 - val_mse: 1.3091\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7535 - mse: 0.7535 - val_loss: 1.3102 - val_mse: 1.3102\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7535 - mse: 0.7535 - val_loss: 1.3115 - val_mse: 1.3115\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7535 - mse: 0.7535 - val_loss: 1.3091 - val_mse: 1.3091\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3116 - val_mse: 1.3116\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7535 - mse: 0.7535 - val_loss: 1.3106 - val_mse: 1.3106\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3105 - val_mse: 1.3105\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3117 - val_mse: 1.3117\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3111 - val_mse: 1.3111\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3109 - val_mse: 1.3109\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3130 - val_mse: 1.3130\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3095 - val_mse: 1.3095\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3135 - val_mse: 1.3135\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3113 - val_mse: 1.3113\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3118 - val_mse: 1.3118\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3138 - val_mse: 1.3138\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7534 - mse: 0.7534 - val_loss: 1.3113 - val_mse: 1.3113\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3133 - val_mse: 1.3133\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3127 - val_mse: 1.3127\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3120 - val_mse: 1.3120\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3140 - val_mse: 1.3140\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3119 - val_mse: 1.3119\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3138 - val_mse: 1.3138\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3140 - val_mse: 1.3140\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.3117 - val_mse: 1.3117\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7532 - mse: 0.7532 - val_loss: 1.3152 - val_mse: 1.3152\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7532 - mse: 0.7532 - val_loss: 1.3129 - val_mse: 1.3129\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7532 - mse: 0.7532 - val_loss: 1.3134 - val_mse: 1.3134\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7532 - mse: 0.7532 - val_loss: 1.3150 - val_mse: 1.3150\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3119 - val_mse: 1.3119\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3166 - val_mse: 1.3166\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3124 - val_mse: 1.3124\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3153 - val_mse: 1.3153\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3146 - val_mse: 1.3146\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3145 - val_mse: 1.3145\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3151 - val_mse: 1.3151\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3151 - val_mse: 1.3151\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3148 - val_mse: 1.3148\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3154 - val_mse: 1.3154\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3155 - val_mse: 1.3155\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7530 - mse: 0.7530 - val_loss: 1.3144 - val_mse: 1.3144\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.3173 - val_mse: 1.3173\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3132 - val_mse: 1.3132\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3190 - val_mse: 1.3190\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3116 - val_mse: 1.3116\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7530 - mse: 0.7530 - val_loss: 1.3198 - val_mse: 1.3198\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3129 - val_mse: 1.3129\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7530 - mse: 0.7530 - val_loss: 1.3186 - val_mse: 1.3186\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3139 - val_mse: 1.3139\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7530 - mse: 0.7530 - val_loss: 1.3189 - val_mse: 1.3189\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3135 - val_mse: 1.3135\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3201 - val_mse: 1.3201\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3129 - val_mse: 1.3129\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3206 - val_mse: 1.3206\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3131 - val_mse: 1.3131\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.3202 - val_mse: 1.3202\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3148 - val_mse: 1.3148\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3186 - val_mse: 1.3186\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3168 - val_mse: 1.3168\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3163 - val_mse: 1.3163\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3201 - val_mse: 1.3201\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3134 - val_mse: 1.3134\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3231 - val_mse: 1.3231\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3114 - val_mse: 1.3114\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3246 - val_mse: 1.3246\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3123 - val_mse: 1.3123\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3225 - val_mse: 1.3225\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.3156 - val_mse: 1.3156\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3188 - val_mse: 1.3188\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3195 - val_mse: 1.3195\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3165 - val_mse: 1.3165\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3210 - val_mse: 1.3210\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3157 - val_mse: 1.3157\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3221 - val_mse: 1.3221\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3158 - val_mse: 1.3158\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3220 - val_mse: 1.3220\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7527 - mse: 0.7527 - val_loss: 1.3166 - val_mse: 1.3166\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3201 - val_mse: 1.3201\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3203 - val_mse: 1.3203\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3166 - val_mse: 1.3166\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3232 - val_mse: 1.3232\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3161 - val_mse: 1.3161\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3232 - val_mse: 1.3232\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3161 - val_mse: 1.3161\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3241 - val_mse: 1.3241\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3157 - val_mse: 1.3157\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3255 - val_mse: 1.3255\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3143 - val_mse: 1.3143\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.3272 - val_mse: 1.3272\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3119 - val_mse: 1.3119\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3307 - val_mse: 1.3307\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.3087 - val_mse: 1.3087\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.3345 - val_mse: 1.3345\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.3049 - val_mse: 1.3049\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.3390 - val_mse: 1.3390\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.3002 - val_mse: 1.3002\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.3437 - val_mse: 1.3437\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.2952 - val_mse: 1.2952\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.3499 - val_mse: 1.3499\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7522 - mse: 0.7522 - val_loss: 1.2881 - val_mse: 1.2881\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.3588 - val_mse: 1.3588\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.2780 - val_mse: 1.2780\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.3728 - val_mse: 1.3728\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.2606 - val_mse: 1.2606\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.3941 - val_mse: 1.3941\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.2362 - val_mse: 1.2362\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.4252 - val_mse: 1.4252\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.1995 - val_mse: 1.1995\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.4688 - val_mse: 1.4688\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.1519 - val_mse: 1.1519\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.5247 - val_mse: 1.5247\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7529 - mse: 0.7529 - val_loss: 1.0932 - val_mse: 1.0932\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.5844 - val_mse: 1.5844\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 1.0447 - val_mse: 1.0447\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.6112 - val_mse: 1.6112\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7536 - mse: 0.7536 - val_loss: 1.0496 - val_mse: 1.0496\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7537 - mse: 0.7537 - val_loss: 1.5593 - val_mse: 1.5593\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 1.1393 - val_mse: 1.1393\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7528 - mse: 0.7528 - val_loss: 1.4277 - val_mse: 1.4277\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.2848 - val_mse: 1.2848\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7522 - mse: 0.7522 - val_loss: 1.2777 - val_mse: 1.2777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7521 - mse: 0.7521 - val_loss: 1.4166 - val_mse: 1.4166\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.1738 - val_mse: 1.1738\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.4831 - val_mse: 1.4831\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7525 - mse: 0.7525 - val_loss: 1.1508 - val_mse: 1.1508\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 1.4642 - val_mse: 1.4642\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7524 - mse: 0.7524 - val_loss: 1.2061 - val_mse: 1.2061\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.3834 - val_mse: 1.3834\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7521 - mse: 0.7521 - val_loss: 1.3004 - val_mse: 1.3004\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7521 - mse: 0.7521 - val_loss: 1.2891 - val_mse: 1.2891\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7523 - mse: 0.7523 - val_loss: 1.3835 - val_mse: 1.3835\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:8 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x152525280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [21.87735  35.037415 56.21829 ]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make Bidirectional LSTM\n",
    "bimodel = Sequential()\n",
    "bimodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(fib_look, 1)))\n",
    "bimodel.add(Dense(1))\n",
    "bimodel.compile(optimizer='adam', loss='mse',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 6208739840.0000 - mse: 6208739840.0000 - val_loss: 9138359296.0000 - val_mse: 9138359296.0000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6184410624.0000 - mse: 6184410624.0000 - val_loss: 8829029376.0000 - val_mse: 8829029376.0000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5975374336.0000 - mse: 5975374336.0000 - val_loss: 8789493760.0000 - val_mse: 8789493760.0000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5948315648.0000 - mse: 5948315648.0000 - val_loss: 8748741632.0000 - val_mse: 8748741632.0000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5920735232.0000 - mse: 5920735232.0000 - val_loss: 8707279872.0000 - val_mse: 8707279872.0000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5892677632.0000 - mse: 5892677632.0000 - val_loss: 8665041920.0000 - val_mse: 8665041920.0000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5864093696.0000 - mse: 5864093696.0000 - val_loss: 8622306304.0000 - val_mse: 8622306304.0000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5835167744.0000 - mse: 5835167744.0000 - val_loss: 8382445056.0000 - val_mse: 8382445056.0000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5673029632.0000 - mse: 5673029632.0000 - val_loss: 8337016320.0000 - val_mse: 8337016320.0000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5642099200.0000 - mse: 5642099200.0000 - val_loss: 8289906176.0000 - val_mse: 8289906176.0000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5610068992.0000 - mse: 5610068992.0000 - val_loss: 8161866240.0000 - val_mse: 8161866240.0000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5523308544.0000 - mse: 5523308544.0000 - val_loss: 7899721728.0000 - val_mse: 7899721728.0000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5346205184.0000 - mse: 5346205184.0000 - val_loss: 7852406272.0000 - val_mse: 7852406272.0000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5314138624.0000 - mse: 5314138624.0000 - val_loss: 7803637760.0000 - val_mse: 7803637760.0000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5281134080.0000 - mse: 5281134080.0000 - val_loss: 7753680896.0000 - val_mse: 7753680896.0000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5247325696.0000 - mse: 5247325696.0000 - val_loss: 7702669824.0000 - val_mse: 7702669824.0000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5212805120.0000 - mse: 5212805120.0000 - val_loss: 7650691072.0000 - val_mse: 7650691072.0000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5177628672.0000 - mse: 5177628672.0000 - val_loss: 7597796864.0000 - val_mse: 7597796864.0000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5141813760.0000 - mse: 5141813760.0000 - val_loss: 7467196928.0000 - val_mse: 7467196928.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5053601280.0000 - mse: 5053601280.0000 - val_loss: 7414322688.0000 - val_mse: 7414322688.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5017666048.0000 - mse: 5017666048.0000 - val_loss: 7360493056.0000 - val_mse: 7360493056.0000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4981236224.0000 - mse: 4981236224.0000 - val_loss: 7305728000.0000 - val_mse: 7305728000.0000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4944173056.0000 - mse: 4944173056.0000 - val_loss: 7250046976.0000 - val_mse: 7250046976.0000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4906491904.0000 - mse: 4906491904.0000 - val_loss: 7193466880.0000 - val_mse: 7193466880.0000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4868200960.0000 - mse: 4868200960.0000 - val_loss: 7135999488.0000 - val_mse: 7135999488.0000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4829310464.0000 - mse: 4829310464.0000 - val_loss: 7077654016.0000 - val_mse: 7077654016.0000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4789826048.0000 - mse: 4789826048.0000 - val_loss: 7012728320.0000 - val_mse: 7012728320.0000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4745889280.0000 - mse: 4745889280.0000 - val_loss: 6953021952.0000 - val_mse: 6953021952.0000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4705356288.0000 - mse: 4705356288.0000 - val_loss: 6773722624.0000 - val_mse: 6773722624.0000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4584120832.0000 - mse: 4584120832.0000 - val_loss: 6574086656.0000 - val_mse: 6574086656.0000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4457404928.0000 - mse: 4457404928.0000 - val_loss: 6323537408.0000 - val_mse: 6323537408.0000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4279472896.0000 - mse: 4279472896.0000 - val_loss: 6263619584.0000 - val_mse: 6263619584.0000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4238921472.0000 - mse: 4238921472.0000 - val_loss: 6201557504.0000 - val_mse: 6201557504.0000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4196911104.0000 - mse: 4196911104.0000 - val_loss: 6137844224.0000 - val_mse: 6137844224.0000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4153124096.0000 - mse: 4153124096.0000 - val_loss: 5641332736.0000 - val_mse: 5641332736.0000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3817916160.0000 - mse: 3817916160.0000 - val_loss: 5573896192.0000 - val_mse: 5573896192.0000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3772157184.0000 - mse: 3772157184.0000 - val_loss: 5505145344.0000 - val_mse: 5505145344.0000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3725625088.0000 - mse: 3725625088.0000 - val_loss: 5435262976.0000 - val_mse: 5435262976.0000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3678331648.0000 - mse: 3678331648.0000 - val_loss: 5278428672.0000 - val_mse: 5278428672.0000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3572378368.0000 - mse: 3572378368.0000 - val_loss: 5205619712.0000 - val_mse: 5205619712.0000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3522923776.0000 - mse: 3522923776.0000 - val_loss: 5065355776.0000 - val_mse: 5065355776.0000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3427859456.0000 - mse: 3427859456.0000 - val_loss: 4861215232.0000 - val_mse: 4861215232.0000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3289539584.0000 - mse: 3289539584.0000 - val_loss: 4047801600.0000 - val_mse: 4047801600.0000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2739435264.0000 - mse: 2739435264.0000 - val_loss: 3965861888.0000 - val_mse: 3965861888.0000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2683901952.0000 - mse: 2683901952.0000 - val_loss: 3872974080.0000 - val_mse: 3872974080.0000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2621048576.0000 - mse: 2621048576.0000 - val_loss: 3786338048.0000 - val_mse: 3786338048.0000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2562418688.0000 - mse: 2562418688.0000 - val_loss: 3698341632.0000 - val_mse: 3698341632.0000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2502867200.0000 - mse: 2502867200.0000 - val_loss: 3609367552.0000 - val_mse: 3609367552.0000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2442651648.0000 - mse: 2442651648.0000 - val_loss: 3482868992.0000 - val_mse: 3482868992.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2357131520.0000 - mse: 2357131520.0000 - val_loss: 3391771392.0000 - val_mse: 3391771392.0000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2295137792.0000 - mse: 2295137792.0000 - val_loss: 3124691968.0000 - val_mse: 3124691968.0000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2114664576.0000 - mse: 2114664576.0000 - val_loss: 3031890688.0000 - val_mse: 3031890688.0000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2051843712.0000 - mse: 2051843712.0000 - val_loss: 2937431296.0000 - val_mse: 2937431296.0000\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1987917440.0000 - mse: 1987917440.0000 - val_loss: 2842080000.0000 - val_mse: 2842080000.0000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1923362688.0000 - mse: 1923362688.000 - 0s 14ms/step - loss: 1923362688.0000 - mse: 1923362688.0000 - val_loss: 2737893376.0000 - val_mse: 2737893376.0000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1852880256.0000 - mse: 1852880256.0000 - val_loss: 2641994752.0000 - val_mse: 2641994752.0000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1787981184.0000 - mse: 1787981184.0000 - val_loss: 2546272256.0000 - val_mse: 2546272256.0000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1723203456.0000 - mse: 1723203456.0000 - val_loss: 2450935808.0000 - val_mse: 2450935808.0000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1658498432.0000 - mse: 1658498432.0000 - val_loss: 2066508800.0000 - val_mse: 2066508800.0000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1398518912.0000 - mse: 1398518912.0000 - val_loss: 1977394176.0000 - val_mse: 1977394176.0000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1338214272.0000 - mse: 1338214272.000 - 0s 13ms/step - loss: 1338214272.0000 - mse: 1338214272.0000 - val_loss: 1889475584.0000 - val_mse: 1889475584.0000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1278456832.0000 - mse: 1278456832.0000 - val_loss: 1417074816.0000 - val_mse: 1417074816.0000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 959004160.0000 - mse: 959004160.0000 - val_loss: 1060117824.0000 - val_mse: 1060117824.0000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 717527552.0000 - mse: 717527552.0000 - val_loss: 986344704.0000 - val_mse: 986344704.0000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 667514048.0000 - mse: 667514048.0000 - val_loss: 914132480.0000 - val_mse: 914132480.0000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 618644480.0000 - mse: 618644480.0000 - val_loss: 843980352.0000 - val_mse: 843980352.0000\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 571169344.0000 - mse: 571169344.0000 - val_loss: 776209216.0000 - val_mse: 776209216.0000\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 525287776.0000 - mse: 525287776.0000 - val_loss: 629838016.0000 - val_mse: 629838016.0000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 426268064.0000 - mse: 426268064.0000 - val_loss: 569883392.0000 - val_mse: 569883392.0000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 385672320.0000 - mse: 385672320.0000 - val_loss: 513083808.0000 - val_mse: 513083808.0000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 347233184.0000 - mse: 347233184.0000 - val_loss: 459520416.0000 - val_mse: 459520416.0000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 310984320.0000 - mse: 310984320.0000 - val_loss: 409241600.0000 - val_mse: 409241600.0000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 276960672.0000 - mse: 276960672.0000 - val_loss: 362273792.0000 - val_mse: 362273792.0000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 245115824.0000 - mse: 245115824.0000 - val_loss: 101110232.0000 - val_mse: 101110232.0000\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 69044544.0000 - mse: 69044544.0000 - val_loss: 77940072.0000 - val_mse: 77940072.0000\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 52565004.0000 - mse: 52565004.0000 - val_loss: 9921653.0000 - val_mse: 9921653.0000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6715828.0000 - mse: 6715828.0000 - val_loss: 3858883.0000 - val_mse: 3858883.0000\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2611901.5000 - mse: 2611901.5000 - val_loss: 733526.0625 - val_mse: 733526.0625\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 495493.8750 - mse: 495493.8750 - val_loss: 23573994.0000 - val_mse: 23573994.0000\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 14905607.0000 - mse: 14905607.0000 - val_loss: 26383014.0000 - val_mse: 26383014.0000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18102962.0000 - mse: 18102962.0000 - val_loss: 14892657.0000 - val_mse: 14892657.0000\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10077271.0000 - mse: 10077271.0000 - val_loss: 19391774.0000 - val_mse: 19391774.0000\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 13121971.0000 - mse: 13121971.0000 - val_loss: 23350174.0000 - val_mse: 23350174.0000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 15800987.0000 - mse: 15800987.0000 - val_loss: 26540376.0000 - val_mse: 26540376.0000\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17960138.0000 - mse: 17960138.0000 - val_loss: 28840120.0000 - val_mse: 28840120.0000\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19516532.0000 - mse: 19516532.0000 - val_loss: 30212758.0000 - val_mse: 30212758.0000\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20445498.0000 - mse: 20445498.0000 - val_loss: 30688226.0000 - val_mse: 30688226.0000\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 20767368.0000 - mse: 20767368.0000 - val_loss: 30344198.0000 - val_mse: 30344198.0000\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20534590.0000 - mse: 20534590.0000 - val_loss: 29290266.0000 - val_mse: 29290266.0000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19821334.0000 - mse: 19821334.0000 - val_loss: 27654358.0000 - val_mse: 27654358.0000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18714250.0000 - mse: 18714250.0000 - val_loss: 25571858.0000 - val_mse: 25571858.0000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17304996.0000 - mse: 17304996.0000 - val_loss: 23176864.0000 - val_mse: 23176864.0000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 15684247.0000 - mse: 15684247.0000 - val_loss: 20595690.0000 - val_mse: 20595690.0000\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 13937415.0000 - mse: 13937415.0000 - val_loss: 17942136.0000 - val_mse: 17942136.0000\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12141717.0000 - mse: 12141717.0000 - val_loss: 15314655.0000 - val_mse: 15314655.0000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10363621.0000 - mse: 10363621.0000 - val_loss: 12794576.0000 - val_mse: 12794576.0000\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8658204.0000 - mse: 8658204.0000 - val_loss: 10445544.0000 - val_mse: 10445544.0000\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7068524.5000 - mse: 7068524.5000 - val_loss: 8313778.0000 - val_mse: 8313778.0000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5625892.5000 - mse: 5625892.5000 - val_loss: 6429585.5000 - val_mse: 6429585.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4350813.0000 - mse: 4350813.0000 - val_loss: 4808587.5000 - val_mse: 4808587.5000\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3253866.0000 - mse: 3253866.0000 - val_loss: 3453822.0000 - val_mse: 3453822.0000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2337090.0000 - mse: 2337090.0000 - val_loss: 2357781.0000 - val_mse: 2357781.0000\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1595399.0000 - mse: 1595399.0000 - val_loss: 1504675.1250 - val_mse: 1504675.1250\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1018109.5000 - mse: 1018109.5000 - val_loss: 872455.8125 - val_mse: 872455.8125\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 590295.9375 - mse: 590295.9375 - val_loss: 434937.3750 - val_mse: 434937.3750\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 294249.7188 - mse: 294249.7188 - val_loss: 163517.6406 - val_mse: 163517.6406\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 110604.3359 - mse: 110604.3359 - val_loss: 28799.0703 - val_mse: 28799.0703\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19469.9414 - mse: 19469.9414 - val_loss: 1919.5070 - val_mse: 1919.5070\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1311.3724 - mse: 1311.3724 - val_loss: 55582.1875 - val_mse: 55582.1875\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 37656.6172 - mse: 37656.6172 - val_loss: 164883.6406 - val_mse: 164883.6406\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 111651.6250 - mse: 111651.6250 - val_loss: 307815.7500 - val_mse: 307815.7500\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 208403.6719 - mse: 208403.6719 - val_loss: 9217.1943 - val_mse: 9217.1943\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6258.8491 - mse: 6258.8491 - val_loss: 41413.5742 - val_mse: 41413.5742\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 28064.7715 - mse: 28064.7715 - val_loss: 87240.6797 - val_mse: 87240.6797\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 59090.7188 - mse: 59090.7188 - val_loss: 138640.9688 - val_mse: 138640.9688\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 93887.4688 - mse: 93887.4688 - val_loss: 189342.4375 - val_mse: 189342.4375\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 128212.4688 - mse: 128212.4688 - val_loss: 234686.0000 - val_mse: 234686.0000\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 158898.8594 - mse: 158898.8594 - val_loss: 582.7346 - val_mse: 582.7346\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 404.7163 - mse: 404.7163 - val_loss: 1282.8700 - val_mse: 1282.8700\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 879.4697 - mse: 879.4697 - val_loss: 1573.0814 - val_mse: 1573.0814\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1075.7885 - mse: 1075.7885 - val_loss: 1360.5192 - val_mse: 1360.5192\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 930.5610 - mse: 930.5610 - val_loss: 814.1340 - val_mse: 814.1340\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 558.4665 - mse: 558.4665 - val_loss: 255.0033 - val_mse: 255.0033\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 177.0331 - mse: 177.0331 - val_loss: 1.8273 - val_mse: 1.8273\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0931 - mse: 2.0931 - val_loss: 172.8306 - val_mse: 172.8306\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 115.0016 - mse: 115.0016 - val_loss: 540.5476 - val_mse: 540.5476\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 361.8828 - mse: 361.8828 - val_loss: 718.9893 - val_mse: 718.9893\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 482.6201 - mse: 482.6201 - val_loss: 574.9465 - val_mse: 574.9465\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 385.5240 - mse: 385.5240 - val_loss: 266.9940 - val_mse: 266.9940\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 178.2904 - mse: 178.2904 - val_loss: 37.2009 - val_mse: 37.2009\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24.7840 - mse: 24.7840 - val_loss: 20.6944 - val_mse: 20.6944\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 15.3836 - mse: 15.3836 - val_loss: 170.7814 - val_mse: 170.7814\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 118.3859 - mse: 118.3859 - val_loss: 324.7003 - val_mse: 324.7003\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 223.4333 - mse: 223.4333 - val_loss: 350.1732 - val_mse: 350.1732\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 240.7425 - mse: 240.742 - 0s 14ms/step - loss: 240.7425 - mse: 240.7425 - val_loss: 239.3196 - val_mse: 239.3196\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 165.4334 - mse: 165.4334 - val_loss: 87.9074 - val_mse: 87.9074\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 61.6870 - mse: 61.6870 - val_loss: 3.9613 - val_mse: 3.9613\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5503 - mse: 3.5503 - val_loss: 29.9913 - val_mse: 29.9913\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19.8711 - mse: 19.8711 - val_loss: 118.5789 - val_mse: 118.5789\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 78.9498 - mse: 78.9498 - val_loss: 182.2230 - val_mse: 182.2230\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 121.5812 - mse: 121.5812 - val_loss: 168.7486 - val_mse: 168.7486\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 112.4101 - mse: 112.4101 - val_loss: 95.6039 - val_mse: 95.6039\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 63.3501 - mse: 63.3501 - val_loss: 23.8079 - val_mse: 23.8079\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 15.4783 - mse: 15.4783 - val_loss: 1.5972 - val_mse: 1.5972\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2526 - mse: 1.2526 - val_loss: 31.2902 - val_mse: 31.2902\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.9848 - mse: 21.9848 - val_loss: 74.8196 - val_mse: 74.8196\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 52.0082 - mse: 52.0082 - val_loss: 91.3696 - val_mse: 91.3696\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 63.3756 - mse: 63.3756 - val_loss: 68.9760 - val_mse: 68.9760\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 48.0757 - mse: 48.0757 - val_loss: 28.9743 - val_mse: 28.9743\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.5526 - mse: 20.5526 - val_loss: 2.8269 - val_mse: 2.8269\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3450 - mse: 2.3450 - val_loss: 6.1581 - val_mse: 6.1581\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0389 - mse: 4.0389 - val_loss: 28.9492 - val_mse: 28.9492\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.9652 - mse: 18.9652 - val_loss: 47.4482 - val_mse: 47.4482\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 31.2704 - mse: 31.2704 - val_loss: 45.9227 - val_mse: 45.9227\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 30.1918 - mse: 30.1918 - val_loss: 27.3653 - val_mse: 27.3653\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.7967 - mse: 17.7967 - val_loss: 7.6294 - val_mse: 7.6294\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 4.7653 - mse: 4.7653 - val_loss: 0.9404 - val_mse: 0.9404\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6390 - mse: 0.6390 - val_loss: 8.5075 - val_mse: 8.5075\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.0975 - mse: 6.0975 - val_loss: 20.0413 - val_mse: 20.0413\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 14.1315 - mse: 14.1315 - val_loss: 24.1005 - val_mse: 24.1005\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.9669 - mse: 16.9669 - val_loss: 17.8057 - val_mse: 17.8057\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12.5724 - mse: 12.5724 - val_loss: 7.2011 - val_mse: 7.2011\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.1723 - mse: 5.1723 - val_loss: 1.0485 - val_mse: 1.0485\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7621 - mse: 0.7621 - val_loss: 2.9987 - val_mse: 2.9987\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8078 - mse: 1.8078 - val_loss: 9.5032 - val_mse: 9.5032\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.0212 - mse: 6.0212 - val_loss: 13.9220 - val_mse: 13.9220\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.9244 - mse: 8.9244 - val_loss: 12.4066 - val_mse: 12.4066\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.9329 - mse: 7.9329 - val_loss: 6.7274 - val_mse: 6.7274\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2351 - mse: 4.2351 - val_loss: 1.8125 - val_mse: 1.8125\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0983 - mse: 1.0983 - val_loss: 0.9137 - val_mse: 0.9137\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7053 - mse: 0.7053 - val_loss: 3.4851 - val_mse: 3.4851\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6171 - mse: 2.6171 - val_loss: 6.2454 - val_mse: 6.2454\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5450 - mse: 4.5450 - val_loss: 6.4200 - val_mse: 6.4200\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6665 - mse: 4.6665 - val_loss: 4.1417 - val_mse: 4.1417\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0304 - mse: 3.0304 - val_loss: 1.5638 - val_mse: 1.5638\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1361 - mse: 1.1361 - val_loss: 0.8478 - val_mse: 0.8478\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4834 - mse: 0.4834 - val_loss: 2.1987 - val_mse: 2.1987\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2564 - mse: 1.2564 - val_loss: 4.0226 - val_mse: 4.0226\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4048 - mse: 2.4048 - val_loss: 4.5418 - val_mse: 4.5418\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7466 - mse: 2.7466 - val_loss: 3.4408 - val_mse: 3.4408\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0402 - mse: 2.0402 - val_loss: 1.7098 - val_mse: 1.7098\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9767 - mse: 0.9767 - val_loss: 0.7446 - val_mse: 0.7446\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4542 - mse: 0.4542 - val_loss: 1.0017 - val_mse: 1.0017\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7458 - mse: 0.7458 - val_loss: 1.8363 - val_mse: 1.8363\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3765 - mse: 1.3765 - val_loss: 2.2190 - val_mse: 2.2190\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6539 - mse: 1.6539 - val_loss: 1.8431 - val_mse: 1.8431\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3576 - mse: 1.3576 - val_loss: 1.1042 - val_mse: 1.1042\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7903 - mse: 0.7903 - val_loss: 0.7280 - val_mse: 0.7280\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4482 - mse: 0.4482 - val_loss: 0.9925 - val_mse: 0.9925\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5373 - mse: 0.5373 - val_loss: 1.5646 - val_mse: 1.5646\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8600 - mse: 0.8600 - val_loss: 1.9101 - val_mse: 1.9101\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0662 - mse: 1.0662 - val_loss: 1.7225 - val_mse: 1.7225\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9591 - mse: 0.9591 - val_loss: 1.2174 - val_mse: 1.2174\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6568 - mse: 0.6568 - val_loss: 0.7872 - val_mse: 0.7872\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4345 - mse: 0.4345 - val_loss: 0.7304 - val_mse: 0.7304\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4591 - mse: 0.4591 - val_loss: 0.9113 - val_mse: 0.9113\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6369 - mse: 0.6369 - val_loss: 1.0569 - val_mse: 1.0569\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7556 - mse: 0.7556 - val_loss: 0.9884 - val_mse: 0.9884\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6998 - mse: 0.6998 - val_loss: 0.8063 - val_mse: 0.8063\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5456 - mse: 0.5456 - val_loss: 0.6927 - val_mse: 0.6927\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4218 - mse: 0.4218 - val_loss: 0.7722 - val_mse: 0.7722\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4247 - mse: 0.4247 - val_loss: 0.9621 - val_mse: 0.9621\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5151 - mse: 0.5151 - val_loss: 1.0934 - val_mse: 1.0934\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5826 - mse: 0.5826 - val_loss: 1.0616 - val_mse: 1.0616\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5649 - mse: 0.5649 - val_loss: 0.8978 - val_mse: 0.8978\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4752 - mse: 0.4752 - val_loss: 0.7497 - val_mse: 0.7497\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4067 - mse: 0.4067 - val_loss: 0.6996 - val_mse: 0.6996\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4076 - mse: 0.4076 - val_loss: 0.7322 - val_mse: 0.7322\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4559 - mse: 0.4559 - val_loss: 0.7695 - val_mse: 0.7695\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4961 - mse: 0.4961 - val_loss: 0.7574 - val_mse: 0.7574\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4865 - mse: 0.4865 - val_loss: 0.7051 - val_mse: 0.7051\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4360 - mse: 0.4360 - val_loss: 0.6869 - val_mse: 0.6869\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3974 - mse: 0.3974 - val_loss: 0.7231 - val_mse: 0.7231\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3994 - mse: 0.3994 - val_loss: 0.7910 - val_mse: 0.7910\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4261 - mse: 0.4261 - val_loss: 0.8336 - val_mse: 0.8336\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4457 - mse: 0.4457 - val_loss: 0.8202 - val_mse: 0.8202\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4389 - mse: 0.4389 - val_loss: 0.7656 - val_mse: 0.7656\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4138 - mse: 0.4138 - val_loss: 0.7092 - val_mse: 0.7092\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3933 - mse: 0.3933 - val_loss: 0.6858 - val_mse: 0.6858\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3950 - mse: 0.3950 - val_loss: 0.6884 - val_mse: 0.6884\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4106 - mse: 0.4106 - val_loss: 0.6932 - val_mse: 0.6932\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4234 - mse: 0.4234 - val_loss: 0.6895 - val_mse: 0.6895\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4180 - mse: 0.4180 - val_loss: 0.6822 - val_mse: 0.6822\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4002 - mse: 0.4002 - val_loss: 0.6858 - val_mse: 0.6858\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3898 - mse: 0.3898 - val_loss: 0.7073 - val_mse: 0.7073\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3924 - mse: 0.3924 - val_loss: 0.7319 - val_mse: 0.7319\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4011 - mse: 0.4011 - val_loss: 0.7421 - val_mse: 0.7421\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4058 - mse: 0.4058 - val_loss: 0.7319 - val_mse: 0.7319\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4021 - mse: 0.4021 - val_loss: 0.7105 - val_mse: 0.7105\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3946 - mse: 0.3946 - val_loss: 0.6875 - val_mse: 0.6875\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3895 - mse: 0.3895 - val_loss: 0.6760 - val_mse: 0.6760\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3933 - mse: 0.3933 - val_loss: 0.6704 - val_mse: 0.6704\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3967 - mse: 0.3967 - val_loss: 0.6721 - val_mse: 0.6721\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3978 - mse: 0.3978 - val_loss: 0.6732 - val_mse: 0.6732\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3953 - mse: 0.3953 - val_loss: 0.6744 - val_mse: 0.6744\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - mse: 0.3917 - val_loss: 0.6820 - val_mse: 0.6820\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3897 - mse: 0.3897 - val_loss: 0.6942 - val_mse: 0.6942\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3915 - mse: 0.3915 - val_loss: 0.7028 - val_mse: 0.7028\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3938 - mse: 0.3938 - val_loss: 0.7049 - val_mse: 0.7049\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3949 - mse: 0.3949 - val_loss: 0.6988 - val_mse: 0.6988\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3930 - mse: 0.3930 - val_loss: 0.6862 - val_mse: 0.6862\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3902 - mse: 0.3902 - val_loss: 0.6755 - val_mse: 0.6755\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3892 - mse: 0.3892 - val_loss: 0.6681 - val_mse: 0.6681\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3908 - mse: 0.3908 - val_loss: 0.6653 - val_mse: 0.6653\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - mse: 0.3918 - val_loss: 0.6638 - val_mse: 0.6638\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - mse: 0.3917 - val_loss: 0.6652 - val_mse: 0.6652\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3897 - mse: 0.3897 - val_loss: 0.6700 - val_mse: 0.6700\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3903 - mse: 0.3903 - val_loss: 0.6754 - val_mse: 0.6754\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3896 - mse: 0.3896 - val_loss: 0.6821 - val_mse: 0.6821\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3899 - mse: 0.3899 - val_loss: 0.6849 - val_mse: 0.6849\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3898 - mse: 0.3898 - val_loss: 0.6841 - val_mse: 0.6841\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3908 - mse: 0.3908 - val_loss: 0.6784 - val_mse: 0.6784\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3893 - mse: 0.3893 - val_loss: 0.6715 - val_mse: 0.6715\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3884 - mse: 0.3884 - val_loss: 0.6661 - val_mse: 0.6661\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3890 - mse: 0.3890 - val_loss: 0.6625 - val_mse: 0.6625\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3901 - mse: 0.3901 - val_loss: 0.6606 - val_mse: 0.6606\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3907 - mse: 0.3907 - val_loss: 0.6613 - val_mse: 0.6613\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3901 - mse: 0.3901 - val_loss: 0.6624 - val_mse: 0.6624\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3900 - mse: 0.3900 - val_loss: 0.6654 - val_mse: 0.6654\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3899 - mse: 0.3899 - val_loss: 0.6701 - val_mse: 0.6701\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3895 - mse: 0.3895 - val_loss: 0.6728 - val_mse: 0.6728\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3888 - mse: 0.3888 - val_loss: 0.6723 - val_mse: 0.6723\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3890 - mse: 0.3890 - val_loss: 0.6700 - val_mse: 0.6700\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3901 - mse: 0.3901 - val_loss: 0.6652 - val_mse: 0.6652\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3882 - mse: 0.3882 - val_loss: 0.6619 - val_mse: 0.6619\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3883 - mse: 0.388 - 0s 14ms/step - loss: 0.3883 - mse: 0.3883 - val_loss: 0.6580 - val_mse: 0.6580\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3896 - mse: 0.3896 - val_loss: 0.6565 - val_mse: 0.6565\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3885 - mse: 0.3885 - val_loss: 0.6553 - val_mse: 0.6553\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3884 - mse: 0.3884 - val_loss: 0.6574 - val_mse: 0.6574\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3898 - mse: 0.3898 - val_loss: 0.6589 - val_mse: 0.6589\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3884 - mse: 0.3884 - val_loss: 0.6609 - val_mse: 0.6609\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3878 - mse: 0.3878 - val_loss: 0.6634 - val_mse: 0.6634\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3892 - mse: 0.3892 - val_loss: 0.6629 - val_mse: 0.6629\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3895 - mse: 0.3895 - val_loss: 0.6626 - val_mse: 0.6626\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3891 - mse: 0.3891 - val_loss: 0.6592 - val_mse: 0.6592\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3877 - mse: 0.3877 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3891 - mse: 0.3891 - val_loss: 0.6543 - val_mse: 0.6543\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3878 - mse: 0.3878 - val_loss: 0.6532 - val_mse: 0.6532\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3884 - mse: 0.3884 - val_loss: 0.6526 - val_mse: 0.6526\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3895 - mse: 0.3895 - val_loss: 0.6517 - val_mse: 0.6517\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3888 - mse: 0.3888 - val_loss: 0.6535 - val_mse: 0.6535\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3880 - mse: 0.3880 - val_loss: 0.6556 - val_mse: 0.6556\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3883 - mse: 0.3883 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6559 - val_mse: 0.6559\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.6541 - val_mse: 0.6541\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6524 - val_mse: 0.6524\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3889 - mse: 0.3889 - val_loss: 0.6508 - val_mse: 0.6508\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.6491 - val_mse: 0.6491\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6477 - val_mse: 0.6477\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3870 - mse: 0.3870 - val_loss: 0.6472 - val_mse: 0.6472\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3870 - mse: 0.3870 - val_loss: 0.6477 - val_mse: 0.6477\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3874 - mse: 0.3874 - val_loss: 0.6485 - val_mse: 0.6485\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3874 - mse: 0.3874 - val_loss: 0.6483 - val_mse: 0.6483\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3876 - mse: 0.3876 - val_loss: 0.6479 - val_mse: 0.6479\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3887 - mse: 0.3887 - val_loss: 0.6500 - val_mse: 0.6500\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3878 - mse: 0.3878 - val_loss: 0.6493 - val_mse: 0.6493\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3866 - mse: 0.3866 - val_loss: 0.6488 - val_mse: 0.6488\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3877 - mse: 0.3877 - val_loss: 0.6458 - val_mse: 0.6458\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3886 - mse: 0.3886 - val_loss: 0.6457 - val_mse: 0.6457\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3880 - mse: 0.3880 - val_loss: 0.6453 - val_mse: 0.6453\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6448 - val_mse: 0.6448\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6446 - val_mse: 0.6446\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3874 - mse: 0.3874 - val_loss: 0.6441 - val_mse: 0.6441\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3878 - mse: 0.3878 - val_loss: 0.6434 - val_mse: 0.6434\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3883 - mse: 0.3883 - val_loss: 0.6458 - val_mse: 0.6458\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6455 - val_mse: 0.6455\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6450 - val_mse: 0.6450\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3874 - mse: 0.3874 - val_loss: 0.6420 - val_mse: 0.6420\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3883 - mse: 0.3883 - val_loss: 0.6417 - val_mse: 0.6417\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.6413 - val_mse: 0.6413\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3878 - mse: 0.3878 - val_loss: 0.6408 - val_mse: 0.6408\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3882 - mse: 0.3882 - val_loss: 0.6403 - val_mse: 0.6403\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3882 - mse: 0.3882 - val_loss: 0.6426 - val_mse: 0.6426\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6423 - val_mse: 0.6423\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6392 - val_mse: 0.6392\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3880 - mse: 0.3880 - val_loss: 0.6390 - val_mse: 0.6390\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3880 - mse: 0.3880 - val_loss: 0.6386 - val_mse: 0.6386\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3880 - mse: 0.3880 - val_loss: 0.6380 - val_mse: 0.6380\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.6404 - val_mse: 0.6404\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3869 - mse: 0.3869 - val_loss: 0.6400 - val_mse: 0.6400\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3866 - mse: 0.3866 - val_loss: 0.6371 - val_mse: 0.6371\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3877 - mse: 0.3877 - val_loss: 0.6367 - val_mse: 0.6367\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6363 - val_mse: 0.6363\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3873 - mse: 0.3873 - val_loss: 0.6361 - val_mse: 0.6361\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3877 - mse: 0.3877 - val_loss: 0.6381 - val_mse: 0.6381\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.6378 - val_mse: 0.6378\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.6347 - val_mse: 0.6347\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6345 - val_mse: 0.6345\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3876 - mse: 0.3876 - val_loss: 0.6342 - val_mse: 0.6342\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6335 - val_mse: 0.6335\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3875 - mse: 0.3875 - val_loss: 0.6359 - val_mse: 0.6359\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.6355 - val_mse: 0.6355\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3861 - mse: 0.3861 - val_loss: 0.6327 - val_mse: 0.6327\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3872 - mse: 0.3872 - val_loss: 0.6324 - val_mse: 0.6324\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3872 - mse: 0.3872 - val_loss: 0.6319 - val_mse: 0.6319\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3871 - mse: 0.3871 - val_loss: 0.6314 - val_mse: 0.6314\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3871 - mse: 0.3871 - val_loss: 0.6337 - val_mse: 0.6337\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3860 - mse: 0.3860 - val_loss: 0.6334 - val_mse: 0.6334\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3860 - mse: 0.3860 - val_loss: 0.6305 - val_mse: 0.6305\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3870 - mse: 0.3870 - val_loss: 0.6302 - val_mse: 0.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3870 - mse: 0.3870 - val_loss: 0.6299 - val_mse: 0.6299\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3869 - mse: 0.3869 - val_loss: 0.6292 - val_mse: 0.6292\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3868 - mse: 0.3868 - val_loss: 0.6316 - val_mse: 0.6316\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3862 - mse: 0.3862 - val_loss: 0.6313 - val_mse: 0.6313\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3859 - mse: 0.3859 - val_loss: 0.6282 - val_mse: 0.6282\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3868 - mse: 0.3868 - val_loss: 0.6281 - val_mse: 0.6281\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3868 - mse: 0.3868 - val_loss: 0.6278 - val_mse: 0.6278\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3868 - mse: 0.3868 - val_loss: 0.6272 - val_mse: 0.6272\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3867 - mse: 0.3867 - val_loss: 0.6295 - val_mse: 0.6295\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3856 - mse: 0.3856 - val_loss: 0.6291 - val_mse: 0.6291\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3856 - mse: 0.3856 - val_loss: 0.6264 - val_mse: 0.6264\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3867 - mse: 0.3867 - val_loss: 0.6260 - val_mse: 0.6260\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.6257 - val_mse: 0.6257\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.6254 - val_mse: 0.6254\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3866 - mse: 0.3866 - val_loss: 0.6274 - val_mse: 0.6274\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3856 - mse: 0.3856 - val_loss: 0.6271 - val_mse: 0.6271\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3856 - mse: 0.3856 - val_loss: 0.6241 - val_mse: 0.6241\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.6237 - val_mse: 0.6237\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3864 - mse: 0.3864 - val_loss: 0.6236 - val_mse: 0.6236\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3864 - mse: 0.3864 - val_loss: 0.6229 - val_mse: 0.6229\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.6254 - val_mse: 0.6254\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3853 - mse: 0.3853 - val_loss: 0.6238 - val_mse: 0.6238\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3867 - mse: 0.3867 - val_loss: 0.6220 - val_mse: 0.6220\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.6217 - val_mse: 0.6217\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.6240 - val_mse: 0.6240\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3851 - mse: 0.3851 - val_loss: 0.6213 - val_mse: 0.6213\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3862 - mse: 0.3862 - val_loss: 0.6209 - val_mse: 0.6209\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3861 - mse: 0.3861 - val_loss: 0.6217 - val_mse: 0.6217\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3865 - mse: 0.3865 - val_loss: 0.6227 - val_mse: 0.6227\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3852 - mse: 0.3852 - val_loss: 0.6224 - val_mse: 0.6224\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3864 - mse: 0.3864 - val_loss: 0.6193 - val_mse: 0.6193\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3860 - mse: 0.3860 - val_loss: 0.6190 - val_mse: 0.6190\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3859 - mse: 0.3859 - val_loss: 0.6201 - val_mse: 0.6201\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.6210 - val_mse: 0.6210\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3848 - mse: 0.3848 - val_loss: 0.6179 - val_mse: 0.6179\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3859 - mse: 0.3859 - val_loss: 0.6179 - val_mse: 0.6179\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3859 - mse: 0.3859 - val_loss: 0.6173 - val_mse: 0.6173\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3858 - mse: 0.3858 - val_loss: 0.6196 - val_mse: 0.6196\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3862 - mse: 0.3862 - val_loss: 0.6193 - val_mse: 0.6193\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3849 - mse: 0.3849 - val_loss: 0.6189 - val_mse: 0.6189\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3847 - mse: 0.3847 - val_loss: 0.6162 - val_mse: 0.6162\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3854 - mse: 0.3854 - val_loss: 0.6158 - val_mse: 0.6158\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3852 - mse: 0.3852 - val_loss: 0.6155 - val_mse: 0.6155\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3852 - mse: 0.3852 - val_loss: 0.6152 - val_mse: 0.6152\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3857 - mse: 0.3857 - val_loss: 0.6161 - val_mse: 0.6161\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3860 - mse: 0.3860 - val_loss: 0.6170 - val_mse: 0.6170\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3849 - mse: 0.3849 - val_loss: 0.6167 - val_mse: 0.6167\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3849 - mse: 0.3849 - val_loss: 0.6163 - val_mse: 0.6163\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3844 - mse: 0.3844 - val_loss: 0.6135 - val_mse: 0.6135\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3852 - mse: 0.3852 - val_loss: 0.6131 - val_mse: 0.6131\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3845 - mse: 0.3845 - val_loss: 0.6129 - val_mse: 0.6129\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3845 - mse: 0.3845 - val_loss: 0.6124 - val_mse: 0.6124\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3844 - mse: 0.3844 - val_loss: 0.6122 - val_mse: 0.6122\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3851 - mse: 0.3851 - val_loss: 0.6117 - val_mse: 0.6117\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3853 - mse: 0.3853 - val_loss: 0.6139 - val_mse: 0.6139\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3846 - mse: 0.3846 - val_loss: 0.6135 - val_mse: 0.6135\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3846 - mse: 0.3846 - val_loss: 0.6134 - val_mse: 0.6134\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3843 - mse: 0.3843 - val_loss: 0.6105 - val_mse: 0.6105\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3849 - mse: 0.3849 - val_loss: 0.6102 - val_mse: 0.6102\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3841 - mse: 0.3841 - val_loss: 0.6099 - val_mse: 0.6099\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3841 - mse: 0.3841 - val_loss: 0.6096 - val_mse: 0.6096\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3841 - mse: 0.3841 - val_loss: 0.6093 - val_mse: 0.6093\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3844 - mse: 0.3844 - val_loss: 0.6090 - val_mse: 0.6090\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3851 - mse: 0.3851 - val_loss: 0.6112 - val_mse: 0.6112\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3844 - mse: 0.3844 - val_loss: 0.6106 - val_mse: 0.6106\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3843 - mse: 0.3843 - val_loss: 0.6104 - val_mse: 0.6104\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3843 - mse: 0.3843 - val_loss: 0.6076 - val_mse: 0.6076\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3850 - mse: 0.3850 - val_loss: 0.6073 - val_mse: 0.6073\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3846 - mse: 0.3846 - val_loss: 0.6070 - val_mse: 0.6070\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3844 - mse: 0.3844 - val_loss: 0.6066 - val_mse: 0.6066\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3849 - mse: 0.3849 - val_loss: 0.6061 - val_mse: 0.6061\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3848 - mse: 0.3848 - val_loss: 0.6085 - val_mse: 0.6085\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3842 - mse: 0.3842 - val_loss: 0.6082 - val_mse: 0.6082\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3841 - mse: 0.3841 - val_loss: 0.6079 - val_mse: 0.6079\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 0.6050 - val_mse: 0.6050\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3843 - mse: 0.3843 - val_loss: 0.6047 - val_mse: 0.6047\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.6044 - val_mse: 0.6044\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.6040 - val_mse: 0.6040\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.6038 - val_mse: 0.6038\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3842 - mse: 0.3842 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.6055 - val_mse: 0.6055\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.6053 - val_mse: 0.6053\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.6025 - val_mse: 0.6025\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3841 - mse: 0.3841 - val_loss: 0.6021 - val_mse: 0.6021\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.6018 - val_mse: 0.6018\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.6014 - val_mse: 0.6014\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3839 - mse: 0.3839 - val_loss: 0.6009 - val_mse: 0.6009\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3844 - mse: 0.3844 - val_loss: 0.6034 - val_mse: 0.6034\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 0.6030 - val_mse: 0.6030\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 0.6027 - val_mse: 0.6027\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.5999 - val_mse: 0.5999\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3838 - mse: 0.3838 - val_loss: 0.5995 - val_mse: 0.5995\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.5991 - val_mse: 0.5991\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3830 - mse: 0.3830 - val_loss: 0.5989 - val_mse: 0.5989\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.5986 - val_mse: 0.5986\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3840 - mse: 0.3840 - val_loss: 0.6007 - val_mse: 0.6007\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3832 - mse: 0.3832 - val_loss: 0.6004 - val_mse: 0.6004\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.6000 - val_mse: 0.6000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3831 - mse: 0.3831 - val_loss: 0.5973 - val_mse: 0.5973\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3839 - mse: 0.3839 - val_loss: 0.5969 - val_mse: 0.5969\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3833 - mse: 0.3833 - val_loss: 0.5966 - val_mse: 0.5966\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3833 - mse: 0.3833 - val_loss: 0.5964 - val_mse: 0.5964\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3838 - mse: 0.3838 - val_loss: 0.5985 - val_mse: 0.5985\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3828 - mse: 0.3828 - val_loss: 0.5981 - val_mse: 0.5981\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.5953 - val_mse: 0.5953\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 0.5950 - val_mse: 0.5950\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 0.5947 - val_mse: 0.5947\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3837 - mse: 0.3837 - val_loss: 0.5968 - val_mse: 0.5968\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3826 - mse: 0.3826 - val_loss: 0.5965 - val_mse: 0.5965\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3826 - mse: 0.3826 - val_loss: 0.5938 - val_mse: 0.5938\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.5935 - val_mse: 0.5935\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3835 - mse: 0.3835 - val_loss: 0.5931 - val_mse: 0.5931\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3834 - mse: 0.3834 - val_loss: 0.5953 - val_mse: 0.5953\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3824 - mse: 0.3824 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.5921 - val_mse: 0.5921\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3833 - mse: 0.3833 - val_loss: 0.5918 - val_mse: 0.5918\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3829 - mse: 0.3829 - val_loss: 0.5916 - val_mse: 0.5916\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3833 - mse: 0.3833 - val_loss: 0.5910 - val_mse: 0.5910\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3832 - mse: 0.3832 - val_loss: 0.5934 - val_mse: 0.5934\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3825 - mse: 0.3825 - val_loss: 0.5930 - val_mse: 0.5930\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.5899 - val_mse: 0.5899\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3830 - mse: 0.3830 - val_loss: 0.5899 - val_mse: 0.5899\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3831 - mse: 0.3831 - val_loss: 0.5895 - val_mse: 0.5895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3830 - mse: 0.3830 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3830 - mse: 0.3830 - val_loss: 0.5914 - val_mse: 0.5914\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.5911 - val_mse: 0.5911\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3821 - mse: 0.3821 - val_loss: 0.5883 - val_mse: 0.5883\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3830 - mse: 0.3830 - val_loss: 0.5880 - val_mse: 0.5880\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3829 - mse: 0.3829 - val_loss: 0.5876 - val_mse: 0.5876\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3829 - mse: 0.3829 - val_loss: 0.5897 - val_mse: 0.5897\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3818 - mse: 0.3818 - val_loss: 0.5867 - val_mse: 0.5867\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.5864 - val_mse: 0.5864\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.5888 - val_mse: 0.5888\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3816 - mse: 0.3816 - val_loss: 0.5858 - val_mse: 0.5858\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.5858 - val_mse: 0.5858\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.5851 - val_mse: 0.5851\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3826 - mse: 0.3826 - val_loss: 0.5876 - val_mse: 0.5876\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3817 - mse: 0.3817 - val_loss: 0.5872 - val_mse: 0.5872\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3815 - mse: 0.3815 - val_loss: 0.5844 - val_mse: 0.5844\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3822 - mse: 0.3822 - val_loss: 0.5841 - val_mse: 0.5841\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3818 - mse: 0.3818 - val_loss: 0.5837 - val_mse: 0.5837\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3819 - mse: 0.3819 - val_loss: 0.5835 - val_mse: 0.5835\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3824 - mse: 0.3824 - val_loss: 0.5857 - val_mse: 0.5857\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3813 - mse: 0.3813 - val_loss: 0.5853 - val_mse: 0.5853\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3815 - mse: 0.3815 - val_loss: 0.5823 - val_mse: 0.5823\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.5822 - val_mse: 0.5822\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.5816 - val_mse: 0.5816\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3822 - mse: 0.3822 - val_loss: 0.5840 - val_mse: 0.5840\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3811 - mse: 0.3811 - val_loss: 0.5809 - val_mse: 0.5809\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3821 - mse: 0.3821 - val_loss: 0.5809 - val_mse: 0.5809\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3822 - mse: 0.3822 - val_loss: 0.5802 - val_mse: 0.5802\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3821 - mse: 0.3821 - val_loss: 0.5828 - val_mse: 0.5828\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3812 - mse: 0.3812 - val_loss: 0.5824 - val_mse: 0.5824\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3810 - mse: 0.3810 - val_loss: 0.5796 - val_mse: 0.5796\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3819 - mse: 0.3819 - val_loss: 0.5793 - val_mse: 0.5793\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3813 - mse: 0.3813 - val_loss: 0.5790 - val_mse: 0.5790\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3815 - mse: 0.3815 - val_loss: 0.5783 - val_mse: 0.5783\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3819 - mse: 0.3819 - val_loss: 0.5808 - val_mse: 0.5808\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3810 - mse: 0.3810 - val_loss: 0.5804 - val_mse: 0.5804\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3810 - mse: 0.3810 - val_loss: 0.5774 - val_mse: 0.5774\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3818 - mse: 0.3818 - val_loss: 0.5773 - val_mse: 0.5773\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3812 - mse: 0.3812 - val_loss: 0.5770 - val_mse: 0.5770\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3811 - mse: 0.3811 - val_loss: 0.5764 - val_mse: 0.5764\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3812 - mse: 0.3812 - val_loss: 0.5789 - val_mse: 0.5789\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3803 - mse: 0.3803 - val_loss: 0.5785 - val_mse: 0.5785\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3803 - mse: 0.3803 - val_loss: 0.5757 - val_mse: 0.5757\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3812 - mse: 0.3812 - val_loss: 0.5753 - val_mse: 0.5753\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3810 - mse: 0.3810 - val_loss: 0.5750 - val_mse: 0.5750\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3811 - mse: 0.3811 - val_loss: 0.5772 - val_mse: 0.5772\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.5769 - val_mse: 0.5769\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.5741 - val_mse: 0.5741\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3808 - mse: 0.3808 - val_loss: 0.5738 - val_mse: 0.5738\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3806 - mse: 0.3806 - val_loss: 0.5735 - val_mse: 0.5735\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3807 - mse: 0.3807 - val_loss: 0.5757 - val_mse: 0.5757\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3798 - mse: 0.3798 - val_loss: 0.5753 - val_mse: 0.5753\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3796 - mse: 0.3796 - val_loss: 0.5725 - val_mse: 0.5725\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3806 - mse: 0.3806 - val_loss: 0.5722 - val_mse: 0.5722\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3804 - mse: 0.3804 - val_loss: 0.5716 - val_mse: 0.5716\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3805 - mse: 0.3805 - val_loss: 0.5741 - val_mse: 0.5741\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5737 - val_mse: 0.5737\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5708 - val_mse: 0.5708\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.5706 - val_mse: 0.5706\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.5702 - val_mse: 0.5702\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.5697 - val_mse: 0.5697\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3803 - mse: 0.3803 - val_loss: 0.5721 - val_mse: 0.5721\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3799 - mse: 0.3799 - val_loss: 0.5717 - val_mse: 0.5717\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3798 - mse: 0.3798 - val_loss: 0.5687 - val_mse: 0.5687\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.5687 - val_mse: 0.5687\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.5680 - val_mse: 0.5680\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.5704 - val_mse: 0.5704\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3790 - mse: 0.3790 - val_loss: 0.5674 - val_mse: 0.5674\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3801 - mse: 0.3801 - val_loss: 0.5671 - val_mse: 0.5671\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.5667 - val_mse: 0.5667\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.5691 - val_mse: 0.5691\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3791 - mse: 0.3791 - val_loss: 0.5689 - val_mse: 0.5689\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3804 - mse: 0.3804 - val_loss: 0.5659 - val_mse: 0.5659\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.5655 - val_mse: 0.5655\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3799 - mse: 0.3799 - val_loss: 0.5679 - val_mse: 0.5679\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3788 - mse: 0.3788 - val_loss: 0.5649 - val_mse: 0.5649\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3798 - mse: 0.3798 - val_loss: 0.5649 - val_mse: 0.5649\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3797 - mse: 0.3797 - val_loss: 0.5642 - val_mse: 0.5642\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3797 - mse: 0.3797 - val_loss: 0.5665 - val_mse: 0.5665\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3788 - mse: 0.3788 - val_loss: 0.5663 - val_mse: 0.5663\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3788 - mse: 0.3788 - val_loss: 0.5635 - val_mse: 0.5635\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5631 - val_mse: 0.5631\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5628 - val_mse: 0.5628\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5623 - val_mse: 0.5623\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3796 - mse: 0.3796 - val_loss: 0.5648 - val_mse: 0.5648\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3793 - mse: 0.3793 - val_loss: 0.5641 - val_mse: 0.5641\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3792 - mse: 0.3792 - val_loss: 0.5613 - val_mse: 0.5613\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5612 - val_mse: 0.5612\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3792 - mse: 0.3792 - val_loss: 0.5609 - val_mse: 0.5609\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3792 - mse: 0.3792 - val_loss: 0.5603 - val_mse: 0.5603\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3794 - mse: 0.3794 - val_loss: 0.5627 - val_mse: 0.5627\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3785 - mse: 0.3785 - val_loss: 0.5624 - val_mse: 0.5624\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3785 - mse: 0.3785 - val_loss: 0.5596 - val_mse: 0.5596\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3791 - mse: 0.3791 - val_loss: 0.5592 - val_mse: 0.5592\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3789 - mse: 0.3789 - val_loss: 0.5589 - val_mse: 0.5589\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3791 - mse: 0.3791 - val_loss: 0.5611 - val_mse: 0.5611\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3780 - mse: 0.3780 - val_loss: 0.5608 - val_mse: 0.5608\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3780 - mse: 0.3780 - val_loss: 0.5580 - val_mse: 0.5580\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3790 - mse: 0.3790 - val_loss: 0.5577 - val_mse: 0.5577\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3788 - mse: 0.3788 - val_loss: 0.5571 - val_mse: 0.5571\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3789 - mse: 0.3789 - val_loss: 0.5596 - val_mse: 0.5596\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3781 - mse: 0.3781 - val_loss: 0.5591 - val_mse: 0.5591\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3778 - mse: 0.3778 - val_loss: 0.5563 - val_mse: 0.5563\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3786 - mse: 0.3786 - val_loss: 0.5560 - val_mse: 0.5560\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3783 - mse: 0.3783 - val_loss: 0.5557 - val_mse: 0.5557\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3785 - mse: 0.3785 - val_loss: 0.5551 - val_mse: 0.5551\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3788 - mse: 0.3788 - val_loss: 0.5576 - val_mse: 0.5576\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3786 - mse: 0.3786 - val_loss: 0.5571 - val_mse: 0.5571\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3789 - mse: 0.3789 - val_loss: 0.5542 - val_mse: 0.5542\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3786 - mse: 0.3786 - val_loss: 0.5541 - val_mse: 0.5541\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3784 - mse: 0.3784 - val_loss: 0.5538 - val_mse: 0.5538\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3784 - mse: 0.3784 - val_loss: 0.5532 - val_mse: 0.5532\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3786 - mse: 0.3786 - val_loss: 0.5556 - val_mse: 0.5556\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3780 - mse: 0.3780 - val_loss: 0.5553 - val_mse: 0.5553\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3776 - mse: 0.3776 - val_loss: 0.5525 - val_mse: 0.5525\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3783 - mse: 0.3783 - val_loss: 0.5522 - val_mse: 0.5522\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3781 - mse: 0.3781 - val_loss: 0.5516 - val_mse: 0.5516\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3782 - mse: 0.3782 - val_loss: 0.5540 - val_mse: 0.5540\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3773 - mse: 0.3773 - val_loss: 0.5509 - val_mse: 0.5509\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3782 - mse: 0.3782 - val_loss: 0.5518 - val_mse: 0.5518\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3781 - mse: 0.3781 - val_loss: 0.5530 - val_mse: 0.5530\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3773 - mse: 0.3773 - val_loss: 0.5499 - val_mse: 0.5499\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3780 - mse: 0.3780 - val_loss: 0.5499 - val_mse: 0.5499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3781 - mse: 0.3781 - val_loss: 0.5506 - val_mse: 0.5506\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3781 - mse: 0.3781 - val_loss: 0.5517 - val_mse: 0.5517\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3775 - mse: 0.3775 - val_loss: 0.5514 - val_mse: 0.5514\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3771 - mse: 0.3771 - val_loss: 0.5486 - val_mse: 0.5486\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3779 - mse: 0.3779 - val_loss: 0.5482 - val_mse: 0.5482\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3777 - mse: 0.3777 - val_loss: 0.5479 - val_mse: 0.5479\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3777 - mse: 0.3777 - val_loss: 0.5501 - val_mse: 0.5501\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 0.5497 - val_mse: 0.5497\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 0.5469 - val_mse: 0.5469\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3776 - mse: 0.3776 - val_loss: 0.5467 - val_mse: 0.5467\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3776 - mse: 0.3776 - val_loss: 0.5462 - val_mse: 0.5462\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3778 - mse: 0.3778 - val_loss: 0.5484 - val_mse: 0.5484\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3768 - mse: 0.3768 - val_loss: 0.5481 - val_mse: 0.5481\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 0.5453 - val_mse: 0.5453\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3776 - mse: 0.3776 - val_loss: 0.5449 - val_mse: 0.5449\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3774 - mse: 0.3774 - val_loss: 0.5444 - val_mse: 0.5444\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3775 - mse: 0.3775 - val_loss: 0.5468 - val_mse: 0.5468\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3766 - mse: 0.3766 - val_loss: 0.5465 - val_mse: 0.5465\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3766 - mse: 0.3766 - val_loss: 0.5436 - val_mse: 0.5436\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3773 - mse: 0.3773 - val_loss: 0.5434 - val_mse: 0.5434\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3772 - mse: 0.3772 - val_loss: 0.5430 - val_mse: 0.5430\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3772 - mse: 0.3772 - val_loss: 0.5452 - val_mse: 0.5452\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3763 - mse: 0.376 - 0s 13ms/step - loss: 0.3763 - mse: 0.3763 - val_loss: 0.5448 - val_mse: 0.5448\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3762 - mse: 0.3762 - val_loss: 0.5421 - val_mse: 0.5421\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3771 - mse: 0.377 - 0s 13ms/step - loss: 0.3771 - mse: 0.3771 - val_loss: 0.5418 - val_mse: 0.5418\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3771 - mse: 0.3771 - val_loss: 0.5412 - val_mse: 0.5412\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3771 - mse: 0.3771 - val_loss: 0.5436 - val_mse: 0.5436\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3763 - mse: 0.3763 - val_loss: 0.5433 - val_mse: 0.5433\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3761 - mse: 0.3761 - val_loss: 0.5405 - val_mse: 0.5405\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3770 - mse: 0.3770 - val_loss: 0.5401 - val_mse: 0.5401\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3768 - mse: 0.3768 - val_loss: 0.5398 - val_mse: 0.5398\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3768 - mse: 0.3768 - val_loss: 0.5419 - val_mse: 0.5419\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3759 - mse: 0.3759 - val_loss: 0.5417 - val_mse: 0.5417\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3757 - mse: 0.3757 - val_loss: 0.5388 - val_mse: 0.5388\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 0.5385 - val_mse: 0.5385\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3767 - mse: 0.3767 - val_loss: 0.5380 - val_mse: 0.5380\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3766 - mse: 0.3766 - val_loss: 0.5402 - val_mse: 0.5402\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3760 - mse: 0.3760 - val_loss: 0.5400 - val_mse: 0.5400\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3757 - mse: 0.3757 - val_loss: 0.5372 - val_mse: 0.5372\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3765 - mse: 0.3765 - val_loss: 0.5369 - val_mse: 0.5369\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3762 - mse: 0.3762 - val_loss: 0.5366 - val_mse: 0.5366\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3764 - mse: 0.3764 - val_loss: 0.5387 - val_mse: 0.5387\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3756 - mse: 0.3756 - val_loss: 0.5384 - val_mse: 0.5384\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3756 - mse: 0.3756 - val_loss: 0.5355 - val_mse: 0.5355\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3763 - mse: 0.3763 - val_loss: 0.5352 - val_mse: 0.5352\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3763 - mse: 0.3763 - val_loss: 0.5347 - val_mse: 0.5347\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3763 - mse: 0.3763 - val_loss: 0.5371 - val_mse: 0.5371\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3756 - mse: 0.3756 - val_loss: 0.5368 - val_mse: 0.5368\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3753 - mse: 0.3753 - val_loss: 0.5340 - val_mse: 0.5340\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3761 - mse: 0.376 - 0s 13ms/step - loss: 0.3761 - mse: 0.3761 - val_loss: 0.5335 - val_mse: 0.5335\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3760 - mse: 0.3760 - val_loss: 0.5333 - val_mse: 0.5333\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3762 - mse: 0.3762 - val_loss: 0.5354 - val_mse: 0.5354\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3753 - mse: 0.3753 - val_loss: 0.5351 - val_mse: 0.5351\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3753 - mse: 0.3753 - val_loss: 0.5323 - val_mse: 0.5323\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3760 - mse: 0.3760 - val_loss: 0.5321 - val_mse: 0.5321\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3759 - mse: 0.3759 - val_loss: 0.5314 - val_mse: 0.5314\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3759 - mse: 0.3759 - val_loss: 0.5338 - val_mse: 0.5338\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3751 - mse: 0.3751 - val_loss: 0.5334 - val_mse: 0.5334\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3751 - mse: 0.3751 - val_loss: 0.5307 - val_mse: 0.5307\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3757 - mse: 0.3757 - val_loss: 0.5304 - val_mse: 0.5304\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3757 - mse: 0.3757 - val_loss: 0.5300 - val_mse: 0.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3756 - mse: 0.3756 - val_loss: 0.5321 - val_mse: 0.5321\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3749 - mse: 0.3749 - val_loss: 0.5318 - val_mse: 0.5318\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3749 - mse: 0.3749 - val_loss: 0.5290 - val_mse: 0.5290\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3756 - mse: 0.3756 - val_loss: 0.5286 - val_mse: 0.5286\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3755 - mse: 0.3755 - val_loss: 0.5282 - val_mse: 0.5282\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3755 - mse: 0.3755 - val_loss: 0.5305 - val_mse: 0.5305\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3748 - mse: 0.3748 - val_loss: 0.5302 - val_mse: 0.5302\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3747 - mse: 0.3747 - val_loss: 0.5275 - val_mse: 0.5275\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3754 - mse: 0.3754 - val_loss: 0.5271 - val_mse: 0.5271\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3754 - mse: 0.3754 - val_loss: 0.5267 - val_mse: 0.5267\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3753 - mse: 0.3753 - val_loss: 0.5289 - val_mse: 0.5289\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3747 - mse: 0.3747 - val_loss: 0.5286 - val_mse: 0.5286\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3746 - mse: 0.3746 - val_loss: 0.5257 - val_mse: 0.5257\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3752 - mse: 0.3752 - val_loss: 0.5254 - val_mse: 0.5254\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3752 - mse: 0.3752 - val_loss: 0.5248 - val_mse: 0.5248\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3752 - mse: 0.3752 - val_loss: 0.5273 - val_mse: 0.5273\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3749 - mse: 0.3749 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3744 - mse: 0.3744 - val_loss: 0.5241 - val_mse: 0.5241\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3750 - mse: 0.3750 - val_loss: 0.5238 - val_mse: 0.5238\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3750 - mse: 0.3750 - val_loss: 0.5235 - val_mse: 0.5235\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3750 - mse: 0.3750 - val_loss: 0.5256 - val_mse: 0.5256\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3742 - mse: 0.3742 - val_loss: 0.5253 - val_mse: 0.5253\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3742 - mse: 0.374 - 0s 14ms/step - loss: 0.3742 - mse: 0.3742 - val_loss: 0.5222 - val_mse: 0.5222\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3748 - mse: 0.3748 - val_loss: 0.5221 - val_mse: 0.5221\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3748 - mse: 0.3748 - val_loss: 0.5218 - val_mse: 0.5218\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3748 - mse: 0.3748 - val_loss: 0.5239 - val_mse: 0.5239\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3740 - mse: 0.3740 - val_loss: 0.5236 - val_mse: 0.5236\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3738 - mse: 0.3738 - val_loss: 0.5207 - val_mse: 0.5207\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3746 - mse: 0.3746 - val_loss: 0.5205 - val_mse: 0.5205\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3746 - mse: 0.3746 - val_loss: 0.5201 - val_mse: 0.5201\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3746 - mse: 0.3746 - val_loss: 0.5223 - val_mse: 0.5223\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3738 - mse: 0.3738 - val_loss: 0.5220 - val_mse: 0.5220\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3738 - mse: 0.3738 - val_loss: 0.5189 - val_mse: 0.5189\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3744 - mse: 0.3744 - val_loss: 0.5188 - val_mse: 0.5188\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3744 - mse: 0.3744 - val_loss: 0.5182 - val_mse: 0.5182\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3743 - mse: 0.3743 - val_loss: 0.5206 - val_mse: 0.5206\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3734 - mse: 0.3734 - val_loss: 0.5176 - val_mse: 0.5176\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3743 - mse: 0.3743 - val_loss: 0.5172 - val_mse: 0.5172\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3742 - mse: 0.3742 - val_loss: 0.5196 - val_mse: 0.5196\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.5166 - val_mse: 0.5166\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3741 - mse: 0.3741 - val_loss: 0.5163 - val_mse: 0.5163\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3741 - mse: 0.3741 - val_loss: 0.5159 - val_mse: 0.5159\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3741 - mse: 0.3741 - val_loss: 0.5183 - val_mse: 0.5183\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3734 - mse: 0.3734 - val_loss: 0.5165 - val_mse: 0.5165\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3740 - mse: 0.3740 - val_loss: 0.5149 - val_mse: 0.5149\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3740 - mse: 0.3740 - val_loss: 0.5173 - val_mse: 0.5173\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3732 - mse: 0.3732 - val_loss: 0.5143 - val_mse: 0.5143\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3739 - mse: 0.3739 - val_loss: 0.5142 - val_mse: 0.5142\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3739 - mse: 0.3739 - val_loss: 0.5151 - val_mse: 0.5151\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3742 - mse: 0.3742 - val_loss: 0.5160 - val_mse: 0.5160\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3731 - mse: 0.3731 - val_loss: 0.5157 - val_mse: 0.5157\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3729 - mse: 0.3729 - val_loss: 0.5128 - val_mse: 0.5128\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3738 - mse: 0.3738 - val_loss: 0.5125 - val_mse: 0.5125\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.5122 - val_mse: 0.5122\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.5116 - val_mse: 0.5116\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3736 - mse: 0.3736 - val_loss: 0.5138 - val_mse: 0.5138\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3736 - mse: 0.3736 - val_loss: 0.5135 - val_mse: 0.5135\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 0.5109 - val_mse: 0.5109\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3736 - mse: 0.3736 - val_loss: 0.5106 - val_mse: 0.5106\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.5103 - val_mse: 0.5103\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.5096 - val_mse: 0.5096\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3734 - mse: 0.3734 - val_loss: 0.5119 - val_mse: 0.5119\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3734 - mse: 0.3734 - val_loss: 0.5117 - val_mse: 0.5117\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3731 - mse: 0.3731 - val_loss: 0.5090 - val_mse: 0.5090\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 0.5086 - val_mse: 0.5086\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 0.5083 - val_mse: 0.5083\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3733 - mse: 0.3733 - val_loss: 0.5104 - val_mse: 0.5104\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3725 - mse: 0.3725 - val_loss: 0.5101 - val_mse: 0.5101\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3725 - mse: 0.3725 - val_loss: 0.5073 - val_mse: 0.5073\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3732 - mse: 0.3732 - val_loss: 0.5069 - val_mse: 0.5069\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3731 - mse: 0.3731 - val_loss: 0.5064 - val_mse: 0.5064\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3731 - mse: 0.3731 - val_loss: 0.5087 - val_mse: 0.5087\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3727 - mse: 0.3727 - val_loss: 0.5084 - val_mse: 0.5084\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3723 - mse: 0.3723 - val_loss: 0.5057 - val_mse: 0.5057\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3730 - mse: 0.3730 - val_loss: 0.5054 - val_mse: 0.5054\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3729 - mse: 0.3729 - val_loss: 0.5050 - val_mse: 0.5050\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3728 - mse: 0.3728 - val_loss: 0.5071 - val_mse: 0.5071\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3726 - mse: 0.3726 - val_loss: 0.5068 - val_mse: 0.5068\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3726 - mse: 0.3726 - val_loss: 0.5037 - val_mse: 0.5037\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3728 - mse: 0.3728 - val_loss: 0.5037 - val_mse: 0.5037\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3727 - mse: 0.3727 - val_loss: 0.5033 - val_mse: 0.5033\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3726 - mse: 0.3726 - val_loss: 0.5055 - val_mse: 0.5055\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3719 - mse: 0.3719 - val_loss: 0.5051 - val_mse: 0.5051\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3719 - mse: 0.3719 - val_loss: 0.5024 - val_mse: 0.5024\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3725 - mse: 0.3725 - val_loss: 0.5020 - val_mse: 0.5020\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3724 - mse: 0.3724 - val_loss: 0.5014 - val_mse: 0.5014\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3724 - mse: 0.3724 - val_loss: 0.5039 - val_mse: 0.5039\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3717 - mse: 0.3717 - val_loss: 0.5035 - val_mse: 0.5035\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3717 - mse: 0.3717 - val_loss: 0.5007 - val_mse: 0.5007\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3722 - mse: 0.3722 - val_loss: 0.5003 - val_mse: 0.5003\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3722 - mse: 0.3722 - val_loss: 0.5000 - val_mse: 0.5000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3722 - mse: 0.3722 - val_loss: 0.5022 - val_mse: 0.5022\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3715 - mse: 0.3715 - val_loss: 0.5019 - val_mse: 0.5019\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3719 - mse: 0.3719 - val_loss: 0.4988 - val_mse: 0.4988\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3721 - mse: 0.3721 - val_loss: 0.4987 - val_mse: 0.4987\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3720 - mse: 0.3720 - val_loss: 0.4981 - val_mse: 0.4981\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3719 - mse: 0.3719 - val_loss: 0.5005 - val_mse: 0.5005\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3713 - mse: 0.3713 - val_loss: 0.5001 - val_mse: 0.5001\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3723 - mse: 0.3723 - val_loss: 0.4971 - val_mse: 0.4971\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3719 - mse: 0.3719 - val_loss: 0.4995 - val_mse: 0.4995\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - mse: 0.3707 - val_loss: 0.4968 - val_mse: 0.4968\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3719 - mse: 0.3719 - val_loss: 0.4963 - val_mse: 0.4963\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3718 - mse: 0.3718 - val_loss: 0.4985 - val_mse: 0.4985\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.4982 - val_mse: 0.4982\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3706 - mse: 0.3706 - val_loss: 0.4953 - val_mse: 0.4953\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3716 - mse: 0.3716 - val_loss: 0.4950 - val_mse: 0.4950\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3714 - mse: 0.3714 - val_loss: 0.4948 - val_mse: 0.4948\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3716 - mse: 0.3716 - val_loss: 0.4969 - val_mse: 0.4969\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3708 - mse: 0.3708 - val_loss: 0.4965 - val_mse: 0.4965\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3708 - mse: 0.3708 - val_loss: 0.4935 - val_mse: 0.4935\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3714 - mse: 0.3714 - val_loss: 0.4934 - val_mse: 0.4934\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3715 - mse: 0.3715 - val_loss: 0.4930 - val_mse: 0.4930\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3714 - mse: 0.3714 - val_loss: 0.4952 - val_mse: 0.4952\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3711 - mse: 0.3711 - val_loss: 0.4949 - val_mse: 0.4949\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - mse: 0.3707 - val_loss: 0.4918 - val_mse: 0.4918\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3712 - mse: 0.3712 - val_loss: 0.4917 - val_mse: 0.4917\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3713 - mse: 0.3713 - val_loss: 0.4914 - val_mse: 0.4914\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3712 - mse: 0.3712 - val_loss: 0.4935 - val_mse: 0.4935\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3704 - mse: 0.3704 - val_loss: 0.4932 - val_mse: 0.4932\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3704 - mse: 0.3704 - val_loss: 0.4905 - val_mse: 0.4905\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3711 - mse: 0.3711 - val_loss: 0.4900 - val_mse: 0.4900\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3711 - mse: 0.3711 - val_loss: 0.4895 - val_mse: 0.4895\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.4919 - val_mse: 0.4919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - mse: 0.3707 - val_loss: 0.4915 - val_mse: 0.4915\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3703 - mse: 0.3703 - val_loss: 0.4888 - val_mse: 0.4888\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3709 - mse: 0.3709 - val_loss: 0.4884 - val_mse: 0.4884\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3709 - mse: 0.3709 - val_loss: 0.4878 - val_mse: 0.4878\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - mse: 0.3707 - val_loss: 0.4903 - val_mse: 0.4903\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3700 - mse: 0.3700 - val_loss: 0.4899 - val_mse: 0.4899\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3698 - mse: 0.3698 - val_loss: 0.4871 - val_mse: 0.4871\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - mse: 0.3707 - val_loss: 0.4867 - val_mse: 0.4867\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3705 - mse: 0.3705 - val_loss: 0.4865 - val_mse: 0.4865\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - mse: 0.3707 - val_loss: 0.4886 - val_mse: 0.4886\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3697 - mse: 0.3697 - val_loss: 0.4883 - val_mse: 0.4883\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3701 - mse: 0.3701 - val_loss: 0.4852 - val_mse: 0.4852\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3705 - mse: 0.3705 - val_loss: 0.4851 - val_mse: 0.4851\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3705 - mse: 0.3705 - val_loss: 0.4845 - val_mse: 0.4845\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3704 - mse: 0.3704 - val_loss: 0.4869 - val_mse: 0.4869\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3699 - mse: 0.3699 - val_loss: 0.4866 - val_mse: 0.4866\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3695 - mse: 0.3695 - val_loss: 0.4838 - val_mse: 0.4838\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3703 - mse: 0.3703 - val_loss: 0.4834 - val_mse: 0.4834\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3700 - mse: 0.3700 - val_loss: 0.4831 - val_mse: 0.4831\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3702 - mse: 0.3702 - val_loss: 0.4853 - val_mse: 0.4853\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3694 - mse: 0.3694 - val_loss: 0.4849 - val_mse: 0.4849\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3693 - mse: 0.3693 - val_loss: 0.4821 - val_mse: 0.4821\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3701 - mse: 0.3701 - val_loss: 0.4818 - val_mse: 0.4818\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3700 - mse: 0.3700 - val_loss: 0.4839 - val_mse: 0.4839\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 0.4809 - val_mse: 0.4809\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3700 - mse: 0.3700 - val_loss: 0.4806 - val_mse: 0.4806\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3700 - mse: 0.3700 - val_loss: 0.4830 - val_mse: 0.4830\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3691 - mse: 0.3691 - val_loss: 0.4799 - val_mse: 0.4799\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3699 - mse: 0.3699 - val_loss: 0.4795 - val_mse: 0.4795\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3698 - mse: 0.3698 - val_loss: 0.4819 - val_mse: 0.4819\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3688 - mse: 0.3688 - val_loss: 0.4792 - val_mse: 0.4792\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3697 - mse: 0.3697 - val_loss: 0.4786 - val_mse: 0.4786\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3696 - mse: 0.3696 - val_loss: 0.4809 - val_mse: 0.4809\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3686 - mse: 0.3686 - val_loss: 0.4778 - val_mse: 0.4778\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3696 - mse: 0.3696 - val_loss: 0.4776 - val_mse: 0.4776\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3696 - mse: 0.3696 - val_loss: 0.4799 - val_mse: 0.4799\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3685 - mse: 0.3685 - val_loss: 0.4769 - val_mse: 0.4769\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3693 - mse: 0.3693 - val_loss: 0.4766 - val_mse: 0.4766\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3693 - mse: 0.3693 - val_loss: 0.4763 - val_mse: 0.4763\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3694 - mse: 0.3694 - val_loss: 0.4787 - val_mse: 0.4787\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3689 - mse: 0.3689 - val_loss: 0.4782 - val_mse: 0.4782\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3683 - mse: 0.3683 - val_loss: 0.4754 - val_mse: 0.4754\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3692 - mse: 0.3692 - val_loss: 0.4751 - val_mse: 0.4751\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 0.4748 - val_mse: 0.4748\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3692 - mse: 0.3692 - val_loss: 0.4770 - val_mse: 0.4770\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3681 - mse: 0.3681 - val_loss: 0.4767 - val_mse: 0.4767\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3681 - mse: 0.3681 - val_loss: 0.4739 - val_mse: 0.4739\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 0.4735 - val_mse: 0.4735\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 0.4756 - val_mse: 0.4756\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 0.4726 - val_mse: 0.4726\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 0.4722 - val_mse: 0.4722\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3689 - mse: 0.3689 - val_loss: 0.4746 - val_mse: 0.4746\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3681 - mse: 0.3681 - val_loss: 0.4743 - val_mse: 0.4743\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3678 - mse: 0.3678 - val_loss: 0.4714 - val_mse: 0.4714\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3686 - mse: 0.3686 - val_loss: 0.4711 - val_mse: 0.4711\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3686 - mse: 0.3686 - val_loss: 0.4708 - val_mse: 0.4708\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3685 - mse: 0.3685 - val_loss: 0.4703 - val_mse: 0.4703\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3687 - mse: 0.3687 - val_loss: 0.4725 - val_mse: 0.4725\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3687 - mse: 0.3687 - val_loss: 0.4721 - val_mse: 0.4721\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3685 - mse: 0.3685 - val_loss: 0.4693 - val_mse: 0.4693\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3685 - mse: 0.3685 - val_loss: 0.4691 - val_mse: 0.4691\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3683 - mse: 0.3683 - val_loss: 0.4687 - val_mse: 0.4687\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3683 - mse: 0.3683 - val_loss: 0.4683 - val_mse: 0.4683\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3684 - mse: 0.3684 - val_loss: 0.4707 - val_mse: 0.4707\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3680 - mse: 0.3680 - val_loss: 0.4704 - val_mse: 0.4704\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 0.4672 - val_mse: 0.4672\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3683 - mse: 0.3683 - val_loss: 0.4672 - val_mse: 0.4672\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3683 - mse: 0.3683 - val_loss: 0.4666 - val_mse: 0.4666\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3682 - mse: 0.3682 - val_loss: 0.4690 - val_mse: 0.4690\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3673 - mse: 0.3673 - val_loss: 0.4687 - val_mse: 0.4687\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4658 - val_mse: 0.4658\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3680 - mse: 0.3680 - val_loss: 0.4655 - val_mse: 0.4655\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 0.4652 - val_mse: 0.4652\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3681 - mse: 0.3681 - val_loss: 0.4673 - val_mse: 0.4673\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4670 - val_mse: 0.4670\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3679 - mse: 0.3679 - val_loss: 0.4633 - val_mse: 0.4633\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3678 - mse: 0.3678 - val_loss: 0.4657 - val_mse: 0.4657\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3674 - mse: 0.3674 - val_loss: 0.4654 - val_mse: 0.4654\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3669 - mse: 0.3669 - val_loss: 0.4625 - val_mse: 0.4625\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3678 - mse: 0.3678 - val_loss: 0.4621 - val_mse: 0.4621\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3677 - mse: 0.3677 - val_loss: 0.4619 - val_mse: 0.4619\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3677 - mse: 0.3677 - val_loss: 0.4640 - val_mse: 0.4640\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3672 - mse: 0.3672 - val_loss: 0.4635 - val_mse: 0.4635\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4606 - val_mse: 0.4606\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3675 - mse: 0.3675 - val_loss: 0.4605 - val_mse: 0.4605\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3673 - mse: 0.3673 - val_loss: 0.4601 - val_mse: 0.4601\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3674 - mse: 0.3674 - val_loss: 0.4623 - val_mse: 0.4623\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3663 - mse: 0.3663 - val_loss: 0.4607 - val_mse: 0.4607\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3677 - mse: 0.3677 - val_loss: 0.4617 - val_mse: 0.4617\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3663 - mse: 0.3663 - val_loss: 0.4589 - val_mse: 0.4589\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3674 - mse: 0.3674 - val_loss: 0.4586 - val_mse: 0.4586\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3673 - mse: 0.3673 - val_loss: 0.4606 - val_mse: 0.4606\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3661 - mse: 0.3661 - val_loss: 0.4576 - val_mse: 0.4576\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4600 - val_mse: 0.4600\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3661 - mse: 0.3661 - val_loss: 0.4572 - val_mse: 0.4572\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4569 - val_mse: 0.4569\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3671 - mse: 0.3671 - val_loss: 0.4589 - val_mse: 0.4589\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4586 - val_mse: 0.4586\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4558 - val_mse: 0.4558\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3668 - mse: 0.3668 - val_loss: 0.4555 - val_mse: 0.4555\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3667 - mse: 0.3667 - val_loss: 0.4552 - val_mse: 0.4552\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3669 - mse: 0.3669 - val_loss: 0.4573 - val_mse: 0.4573\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3660 - mse: 0.3660 - val_loss: 0.4568 - val_mse: 0.4568\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4539 - val_mse: 0.4539\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3667 - mse: 0.3667 - val_loss: 0.4539 - val_mse: 0.4539\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3667 - mse: 0.3667 - val_loss: 0.4532 - val_mse: 0.4532\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3665 - mse: 0.3665 - val_loss: 0.4557 - val_mse: 0.4557\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3657 - mse: 0.3657 - val_loss: 0.4540 - val_mse: 0.4540\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3669 - mse: 0.3669 - val_loss: 0.4523 - val_mse: 0.4523\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3664 - mse: 0.3664 - val_loss: 0.4547 - val_mse: 0.4547\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.4519 - val_mse: 0.4519\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3664 - mse: 0.3664 - val_loss: 0.4512 - val_mse: 0.4512\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3662 - mse: 0.3662 - val_loss: 0.4536 - val_mse: 0.4536\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.4506 - val_mse: 0.4506\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3662 - mse: 0.3662 - val_loss: 0.4530 - val_mse: 0.4530\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3666 - mse: 0.3666 - val_loss: 0.4527 - val_mse: 0.4527\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3651 - mse: 0.3651 - val_loss: 0.4499 - val_mse: 0.4499\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4493 - val_mse: 0.4493\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3660 - mse: 0.3660 - val_loss: 0.4517 - val_mse: 0.4517\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3649 - mse: 0.3649 - val_loss: 0.4485 - val_mse: 0.4485\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4483 - val_mse: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4506 - val_mse: 0.4506\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.4476 - val_mse: 0.4476\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3658 - mse: 0.3658 - val_loss: 0.4472 - val_mse: 0.4472\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3658 - mse: 0.3658 - val_loss: 0.4497 - val_mse: 0.4497\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3647 - mse: 0.3647 - val_loss: 0.4466 - val_mse: 0.4466\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3656 - mse: 0.3656 - val_loss: 0.4463 - val_mse: 0.4463\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3656 - mse: 0.365 - 0s 14ms/step - loss: 0.3656 - mse: 0.3656 - val_loss: 0.4487 - val_mse: 0.4487\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3646 - mse: 0.3646 - val_loss: 0.4459 - val_mse: 0.4459\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.4453 - val_mse: 0.4453\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3655 - mse: 0.3655 - val_loss: 0.4477 - val_mse: 0.4477\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3645 - mse: 0.3645 - val_loss: 0.4472 - val_mse: 0.4472\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3659 - mse: 0.3659 - val_loss: 0.4442 - val_mse: 0.4442\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.4467 - val_mse: 0.4467\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3643 - mse: 0.3643 - val_loss: 0.4435 - val_mse: 0.4435\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3651 - mse: 0.3651 - val_loss: 0.4435 - val_mse: 0.4435\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3651 - mse: 0.3651 - val_loss: 0.4457 - val_mse: 0.4457\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3642 - mse: 0.3642 - val_loss: 0.4426 - val_mse: 0.4426\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3652 - mse: 0.3652 - val_loss: 0.4450 - val_mse: 0.4450\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3641 - mse: 0.3641 - val_loss: 0.4422 - val_mse: 0.4422\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3650 - mse: 0.3650 - val_loss: 0.4418 - val_mse: 0.4418\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3650 - mse: 0.3650 - val_loss: 0.4440 - val_mse: 0.4440\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3641 - mse: 0.3641 - val_loss: 0.4436 - val_mse: 0.4436\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 0.4409 - val_mse: 0.4409\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.4405 - val_mse: 0.4405\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.4399 - val_mse: 0.4399\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3649 - mse: 0.3649 - val_loss: 0.4424 - val_mse: 0.4424\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 0.4420 - val_mse: 0.4420\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 0.4389 - val_mse: 0.4389\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.4388 - val_mse: 0.4388\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3646 - mse: 0.3646 - val_loss: 0.4397 - val_mse: 0.4397\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3650 - mse: 0.3650 - val_loss: 0.4406 - val_mse: 0.4406\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3636 - mse: 0.3636 - val_loss: 0.4404 - val_mse: 0.4404\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3636 - mse: 0.3636 - val_loss: 0.4375 - val_mse: 0.4375\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3644 - mse: 0.3644 - val_loss: 0.4371 - val_mse: 0.4371\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3643 - mse: 0.3643 - val_loss: 0.4368 - val_mse: 0.4368\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3643 - mse: 0.3643 - val_loss: 0.4390 - val_mse: 0.4390\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3634 - mse: 0.3634 - val_loss: 0.4386 - val_mse: 0.4386\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3634 - mse: 0.3634 - val_loss: 0.4383 - val_mse: 0.4383\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.4356 - val_mse: 0.4356\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3641 - mse: 0.3641 - val_loss: 0.4376 - val_mse: 0.4376\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3646 - mse: 0.3646 - val_loss: 0.4373 - val_mse: 0.4373\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3632 - mse: 0.3632 - val_loss: 0.4370 - val_mse: 0.4370\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3632 - mse: 0.3632 - val_loss: 0.4341 - val_mse: 0.4341\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 0.4338 - val_mse: 0.4338\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 0.4335 - val_mse: 0.4335\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 0.4357 - val_mse: 0.4357\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3630 - mse: 0.3630 - val_loss: 0.4353 - val_mse: 0.4353\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3630 - mse: 0.3630 - val_loss: 0.4322 - val_mse: 0.4322\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 0.4319 - val_mse: 0.4319\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3638 - mse: 0.3638 - val_loss: 0.4316 - val_mse: 0.4316\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3639 - mse: 0.3639 - val_loss: 0.4341 - val_mse: 0.4341\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3628 - mse: 0.3628 - val_loss: 0.4337 - val_mse: 0.4337\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3628 - mse: 0.3628 - val_loss: 0.4308 - val_mse: 0.4308\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3635 - mse: 0.3635 - val_loss: 0.4305 - val_mse: 0.4305\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3634 - mse: 0.3634 - val_loss: 0.4302 - val_mse: 0.4302\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3635 - mse: 0.3635 - val_loss: 0.4323 - val_mse: 0.4323\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3626 - mse: 0.3626 - val_loss: 0.4318 - val_mse: 0.4318\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3627 - mse: 0.3627 - val_loss: 0.4289 - val_mse: 0.4289\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3635 - mse: 0.3635 - val_loss: 0.4288 - val_mse: 0.4288\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3632 - mse: 0.3632 - val_loss: 0.4282 - val_mse: 0.4282\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3633 - mse: 0.3633 - val_loss: 0.4306 - val_mse: 0.4306\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3623 - mse: 0.3623 - val_loss: 0.4303 - val_mse: 0.4303\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3623 - mse: 0.3623 - val_loss: 0.4275 - val_mse: 0.4275\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3631 - mse: 0.3631 - val_loss: 0.4271 - val_mse: 0.4271\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3629 - mse: 0.3629 - val_loss: 0.4269 - val_mse: 0.4269\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3629 - mse: 0.3629 - val_loss: 0.4288 - val_mse: 0.4288\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3624 - mse: 0.3624 - val_loss: 0.4284 - val_mse: 0.4284\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3622 - mse: 0.3622 - val_loss: 0.4259 - val_mse: 0.4259\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3628 - mse: 0.3628 - val_loss: 0.4255 - val_mse: 0.4255\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3628 - mse: 0.3628 - val_loss: 0.4251 - val_mse: 0.4251\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3627 - mse: 0.3627 - val_loss: 0.4271 - val_mse: 0.4271\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3617 - mse: 0.3617 - val_loss: 0.4270 - val_mse: 0.4270\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3617 - mse: 0.3617 - val_loss: 0.4242 - val_mse: 0.4242\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3626 - mse: 0.3626 - val_loss: 0.4238 - val_mse: 0.4238\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3626 - mse: 0.3626 - val_loss: 0.4260 - val_mse: 0.4260\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3617 - mse: 0.3617 - val_loss: 0.4228 - val_mse: 0.4228\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3626 - mse: 0.3626 - val_loss: 0.4252 - val_mse: 0.4252\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3615 - mse: 0.3615 - val_loss: 0.4225 - val_mse: 0.4225\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3624 - mse: 0.3624 - val_loss: 0.4221 - val_mse: 0.4221\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3624 - mse: 0.3624 - val_loss: 0.4243 - val_mse: 0.4243\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3615 - mse: 0.3615 - val_loss: 0.4239 - val_mse: 0.4239\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3614 - mse: 0.3614 - val_loss: 0.4211 - val_mse: 0.4211\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3623 - mse: 0.3623 - val_loss: 0.4208 - val_mse: 0.4208\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3623 - mse: 0.3623 - val_loss: 0.4229 - val_mse: 0.4229\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3613 - mse: 0.3613 - val_loss: 0.4214 - val_mse: 0.4214\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3627 - mse: 0.3627 - val_loss: 0.4211 - val_mse: 0.4211\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3612 - mse: 0.3612 - val_loss: 0.4194 - val_mse: 0.4194\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3620 - mse: 0.3620 - val_loss: 0.4190 - val_mse: 0.4190\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3620 - mse: 0.3620 - val_loss: 0.4200 - val_mse: 0.4200\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3610 - mse: 0.3610 - val_loss: 0.4181 - val_mse: 0.4181\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3621 - mse: 0.3621 - val_loss: 0.4205 - val_mse: 0.4205\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3610 - mse: 0.3610 - val_loss: 0.4177 - val_mse: 0.4177\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3619 - mse: 0.3619 - val_loss: 0.4172 - val_mse: 0.4172\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3620 - mse: 0.3620 - val_loss: 0.4196 - val_mse: 0.4196\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3609 - mse: 0.3609 - val_loss: 0.4193 - val_mse: 0.4193\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3608 - mse: 0.3608 - val_loss: 0.4164 - val_mse: 0.4164\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3616 - mse: 0.3616 - val_loss: 0.4161 - val_mse: 0.4161\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3615 - mse: 0.3615 - val_loss: 0.4158 - val_mse: 0.4158\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3616 - mse: 0.3616 - val_loss: 0.4179 - val_mse: 0.4179\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3606 - mse: 0.3606 - val_loss: 0.4174 - val_mse: 0.4174\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3608 - mse: 0.3608 - val_loss: 0.4172 - val_mse: 0.4172\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3606 - mse: 0.3606 - val_loss: 0.4132 - val_mse: 0.4132\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3610 - mse: 0.3610 - val_loss: 0.4128 - val_mse: 0.4128\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3603 - mse: 0.3603 - val_loss: 0.4125 - val_mse: 0.4125\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3602 - mse: 0.3602 - val_loss: 0.4134 - val_mse: 0.4134\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3613 - mse: 0.3613 - val_loss: 0.4156 - val_mse: 0.4156\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3604 - mse: 0.3604 - val_loss: 0.4151 - val_mse: 0.4151\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "bihistory = bimodel.fit(X_train,y_train,epochs=1000, validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "Prediction: [26.768948 42.210976 62.50232 ]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(bimodel.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked LSTM graph\n",
    "smodel = Sequential()\n",
    "smodel.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(2, 1)))\n",
    "smodel.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "smodel.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "smodel.add(LSTM(25, activation='relu'))\n",
    "smodel.add(Dense(20, activation='relu'))\n",
    "smodel.add(Dense(10, activation='relu'))\n",
    "smodel.add(Dense(1))\n",
    "smodel.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 6648197120.0000 - mse: 6648197120.0000 - val_loss: 9824478208.0000 - val_mse: 9824478208.0000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6648706560.0000 - mse: 6648706560.0000 - val_loss: 9821703168.0000 - val_mse: 9821703168.0000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6646834688.0000 - mse: 6646834688.0000 - val_loss: 9823157248.0000 - val_mse: 9823157248.0000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6647863296.0000 - mse: 6647863296.0000 - val_loss: 9823279104.0000 - val_mse: 9823279104.0000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6647824384.0000 - mse: 6647824384.0000 - val_loss: 9822640128.0000 - val_mse: 9822640128.0000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6647439360.0000 - mse: 6647439360.0000 - val_loss: 9822156800.0000 - val_mse: 9822156800.0000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6647185408.0000 - mse: 6647185408.0000 - val_loss: 9821675520.0000 - val_mse: 9821675520.0000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6647144960.0000 - mse: 6647144960.0000 - val_loss: 9819454464.0000 - val_mse: 9819454464.0000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6645417984.0000 - mse: 6645417984.0000 - val_loss: 9816136704.0000 - val_mse: 9816136704.0000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6643132928.0000 - mse: 6643132928.0000 - val_loss: 9817178112.0000 - val_mse: 9817178112.0000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6643976192.0000 - mse: 6643976192.0000 - val_loss: 9814417408.0000 - val_mse: 9814417408.0000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6641939968.0000 - mse: 6641939968.0000 - val_loss: 9812819968.0000 - val_mse: 9812819968.0000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6640859648.0000 - mse: 6640859648.0000 - val_loss: 9804872704.0000 - val_mse: 9804872704.0000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6635477504.0000 - mse: 6635477504.0000 - val_loss: 9802685440.0000 - val_mse: 9802685440.0000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6633988608.0000 - mse: 6633988608.0000 - val_loss: 9799715840.0000 - val_mse: 9799715840.0000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6631980544.0000 - mse: 6631980544.0000 - val_loss: 9790485504.0000 - val_mse: 9790485504.0000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6625627648.0000 - mse: 6625627648.0000 - val_loss: 9786067968.0000 - val_mse: 9786067968.0000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6622766592.0000 - mse: 6622766592.0000 - val_loss: 9780288512.0000 - val_mse: 9780288512.0000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6618990592.0000 - mse: 6618990592.0000 - val_loss: 9752599552.0000 - val_mse: 9752599552.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6600372736.0000 - mse: 6600372736.0000 - val_loss: 9726632960.0000 - val_mse: 9726632960.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6582567424.0000 - mse: 6582567424.0000 - val_loss: 9716638720.0000 - val_mse: 9716638720.0000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6575701504.0000 - mse: 6575701504.0000 - val_loss: 9667827712.0000 - val_mse: 9667827712.0000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6542367232.0000 - mse: 6542367232.0000 - val_loss: 9646128128.0000 - val_mse: 9646128128.0000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6528413184.0000 - mse: 6528413184.0000 - val_loss: 9627292672.0000 - val_mse: 9627292672.0000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6515382784.0000 - mse: 6515382784.0000 - val_loss: 9604467712.0000 - val_mse: 9604467712.0000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6499878912.0000 - mse: 6499878912.0000 - val_loss: 9481692160.0000 - val_mse: 9481692160.0000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6416710144.0000 - mse: 6416710144.0000 - val_loss: 9245414400.0000 - val_mse: 9245414400.0000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6256871424.0000 - mse: 6256871424.0000 - val_loss: 9198687232.0000 - val_mse: 9198687232.0000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6223103488.0000 - mse: 6223103488.0000 - val_loss: 9014418432.0000 - val_mse: 9014418432.0000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6101089792.0000 - mse: 6101089792.0000 - val_loss: 8927195136.0000 - val_mse: 8927195136.0000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6041553408.0000 - mse: 6041553408.0000 - val_loss: 8552880640.0000 - val_mse: 8552880640.0000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5787424256.0000 - mse: 5787424256.0000 - val_loss: 7158294528.0000 - val_mse: 7158294528.0000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4805118464.0000 - mse: 4805118464.0000 - val_loss: 6881151488.0000 - val_mse: 6881151488.0000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4657050624.0000 - mse: 4657050624.0000 - val_loss: 6152904192.0000 - val_mse: 6152904192.0000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4163966208.0000 - mse: 4163966208.0000 - val_loss: 5599770624.0000 - val_mse: 5599770624.0000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3789611008.0000 - mse: 3789611008.0000 - val_loss: 4866274816.0000 - val_mse: 4866274816.0000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3293645824.0000 - mse: 3293645824.0000 - val_loss: 4034953984.0000 - val_mse: 4034953984.0000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2730743040.0000 - mse: 2730743040.0000 - val_loss: 3428792320.0000 - val_mse: 3428792320.0000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2319976192.0000 - mse: 2319976192.0000 - val_loss: 2053026304.0000 - val_mse: 2053026304.0000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1390030848.0000 - mse: 1390030848.0000 - val_loss: 1282282368.0000 - val_mse: 1282282368.0000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 867604480.0000 - mse: 867604480.0000 - val_loss: 347730176.0000 - val_mse: 347730176.0000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 227466448.0000 - mse: 227466448.0000 - val_loss: 135835024.0000 - val_mse: 135835024.0000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 91616344.0000 - mse: 91616344.0000 - val_loss: 1647774.1250 - val_mse: 1647774.1250\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 617407.8125 - mse: 617407.8125 - val_loss: 118046344.0000 - val_mse: 118046344.0000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81727240.0000 - mse: 81727240.0000 - val_loss: 324694336.0000 - val_mse: 324694336.0000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 219734128.0000 - mse: 219734128.0000 - val_loss: 544693824.0000 - val_mse: 544693824.0000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 368529568.0000 - mse: 368529568.0000 - val_loss: 615200576.0000 - val_mse: 615200576.0000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 416319200.0000 - mse: 416319200.0000 - val_loss: 580429632.0000 - val_mse: 580429632.0000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 392786944.0000 - mse: 392786944.0000 - val_loss: 436974112.0000 - val_mse: 436974112.0000\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 295706272.0000 - mse: 295706272.0000 - val_loss: 281552736.0000 - val_mse: 281552736.0000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 190522560.0000 - mse: 190522560.0000 - val_loss: 129013672.0000 - val_mse: 129013672.0000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 87303128.0000 - mse: 87303128.0000 - val_loss: 39846580.0000 - val_mse: 39846580.0000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 26962614.0000 - mse: 26962614.0000 - val_loss: 2749745.7500 - val_mse: 2749745.7500\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1859650.0000 - mse: 1859650.0000 - val_loss: 6261670.5000 - val_mse: 6261670.5000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4239103.5000 - mse: 4239103.5000 - val_loss: 35786452.0000 - val_mse: 35786452.0000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24222254.0000 - mse: 24222254.0000 - val_loss: 75412744.0000 - val_mse: 75412744.0000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 51040992.0000 - mse: 51040992.0000 - val_loss: 114221992.0000 - val_mse: 114221992.0000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 77306424.0000 - mse: 77306424.0000 - val_loss: 135788768.0000 - val_mse: 135788768.0000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 91905352.0000 - mse: 91905352.0000 - val_loss: 144706992.0000 - val_mse: 144706992.0000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 97939080.0000 - mse: 97939080.0000 - val_loss: 137703216.0000 - val_mse: 137703216.0000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 93197544.0000 - mse: 93197544.0000 - val_loss: 117623256.0000 - val_mse: 117623256.0000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 79607784.0000 - mse: 79607784.0000 - val_loss: 89283192.0000 - val_mse: 89283192.0000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 60427600.0000 - mse: 60427600.0000 - val_loss: 58432300.0000 - val_mse: 58432300.0000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 39547856.0000 - mse: 39547856.0000 - val_loss: 30719914.0000 - val_mse: 30719914.0000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20792022.0000 - mse: 20792022.0000 - val_loss: 19597086.0000 - val_mse: 19597086.0000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13263413.0000 - mse: 13263413.0000 - val_loss: 2952324.2500 - val_mse: 2952324.2500\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1997046.1250 - mse: 1997046.1250 - val_loss: 1985908.6250 - val_mse: 1985908.6250\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1349579.6250 - mse: 1349579.6250 - val_loss: 4738201.0000 - val_mse: 4738201.0000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3206066.0000 - mse: 3206066.0000 - val_loss: 13377333.0000 - val_mse: 13377333.0000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9049931.0000 - mse: 9049931.0000 - val_loss: 22266016.0000 - val_mse: 22266016.0000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 15064585.0000 - mse: 15064585.0000 - val_loss: 21335868.0000 - val_mse: 21335868.0000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 14436453.0000 - mse: 14436453.0000 - val_loss: 19366490.0000 - val_mse: 19366490.0000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13988369.0000 - mse: 13988369.0000 - val_loss: 20890014.0000 - val_mse: 20890014.0000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 14126712.0000 - mse: 14126712.0000 - val_loss: 252129.4531 - val_mse: 252129.4531\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 169848.8125 - mse: 169848.8125 - val_loss: 2974763.2500 - val_mse: 2974763.2500\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2013238.5000 - mse: 2013238.5000 - val_loss: 3302589.0000 - val_mse: 3302589.0000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2235309.2500 - mse: 2235309.2500 - val_loss: 3163763.7500 - val_mse: 3163763.7500\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2141432.2500 - mse: 2141432.2500 - val_loss: 2634298.0000 - val_mse: 2634298.0000\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1783100.6250 - mse: 1783100.6250 - val_loss: 1878975.3750 - val_mse: 1878975.3750\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1271870.8750 - mse: 1271870.8750 - val_loss: 1095976.2500 - val_mse: 1095976.2500\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 741811.2500 - mse: 741811.2500 - val_loss: 461876.3750 - val_mse: 461876.3750\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 312480.3438 - mse: 312480.3438 - val_loss: 89037.6797 - val_mse: 89037.6797\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 60010.5781 - mse: 60010.5781 - val_loss: 7440254.5000 - val_mse: 7440254.5000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5030905.5000 - mse: 5030905.5000 - val_loss: 878.0073 - val_mse: 878.0073\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 310.0033 - mse: 310.0033 - val_loss: 215799.3125 - val_mse: 215799.3125\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 145591.1094 - mse: 145591.1094 - val_loss: 167933.3438 - val_mse: 167933.3438\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 113316.7266 - mse: 113316.7266 - val_loss: 2724746.2500 - val_mse: 2724746.2500\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1863023.6250 - mse: 1863023.6250 - val_loss: 146837.5156 - val_mse: 146837.5156\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 99135.6250 - mse: 99135.6250 - val_loss: 539679.5000 - val_mse: 539679.5000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 364679.7500 - mse: 364679.7500 - val_loss: 997131.2500 - val_mse: 997131.2500\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 673974.2500 - mse: 673974.2500 - val_loss: 8975425.0000 - val_mse: 8975425.0000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6067407.5000 - mse: 6067407.5000 - val_loss: 2322149.7500 - val_mse: 2322149.7500\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1559985.1250 - mse: 1559985.1250 - val_loss: 612652.3125 - val_mse: 612652.3125\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 414323.8750 - mse: 414323.8750 - val_loss: 282845.4688 - val_mse: 282845.4688\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 191436.5625 - mse: 191436.5625 - val_loss: 11647.1611 - val_mse: 11647.1611\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7760.9531 - mse: 7760.9531 - val_loss: 240423.6094 - val_mse: 240423.6094\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 162732.0469 - mse: 162732.0469 - val_loss: 353014.2812 - val_mse: 353014.2812\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 238831.6094 - mse: 238831.6094 - val_loss: 600984.8125 - val_mse: 600984.8125\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 406673.4688 - mse: 406673.4688 - val_loss: 17458.8750 - val_mse: 17458.8750\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11630.9736 - mse: 11630.9736 - val_loss: 1326671.2500 - val_mse: 1326671.2500\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 898418.1875 - mse: 898418.1875 - val_loss: 980316.4375 - val_mse: 980316.4375\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 660546.3125 - mse: 660546.3125 - val_loss: 363619.4062 - val_mse: 363619.4062\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 246538.1875 - mse: 246538.1875 - val_loss: 576009.6875 - val_mse: 576009.6875\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 390946.2500 - mse: 390946.2500 - val_loss: 703681.5625 - val_mse: 703681.5625\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 476656.5938 - mse: 476656.5938 - val_loss: 710735.6875 - val_mse: 710735.6875\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 480954.0938 - mse: 480954.0938 - val_loss: 605455.6250 - val_mse: 605455.6250\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 409478.6562 - mse: 409478.6562 - val_loss: 168596.3125 - val_mse: 168596.3125\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 113889.9922 - mse: 113889.9922 - val_loss: 71315.9609 - val_mse: 71315.9609\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 48088.5977 - mse: 48088.5977 - val_loss: 13410.0439 - val_mse: 13410.0439\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8964.1787 - mse: 8964.1787 - val_loss: 1069.1730 - val_mse: 1069.1730\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 684.7465 - mse: 684.7465 - val_loss: 25869.3887 - val_mse: 25869.3887\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17536.8848 - mse: 17536.8848 - val_loss: 69938.0703 - val_mse: 69938.0703\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 47419.2773 - mse: 47419.2773 - val_loss: 113102.0391 - val_mse: 113102.0391\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 76674.4219 - mse: 76674.4219 - val_loss: 139402.3750 - val_mse: 139402.3750\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 94504.5859 - mse: 94504.5859 - val_loss: 141208.7656 - val_mse: 141208.7656\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 95741.1250 - mse: 95741.1250 - val_loss: 120064.4141 - val_mse: 120064.4141\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 81411.4844 - mse: 81411.4844 - val_loss: 84622.1875 - val_mse: 84622.1875\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 57382.0273 - mse: 57382.0273 - val_loss: 46664.8867 - val_mse: 46664.8867\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 31649.9082 - mse: 31649.9082 - val_loss: 16897.1465 - val_mse: 16897.1465\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11455.5117 - mse: 11455.5117 - val_loss: 1736.0796 - val_mse: 1736.0796\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1147.5527 - mse: 1147.5527 - val_loss: 1988.2959 - val_mse: 1988.2959\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1272.7385 - mse: 1272.7385 - val_loss: 13523.3408 - val_mse: 13523.3408\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9040.7080 - mse: 9040.7080 - val_loss: 29427.2344 - val_mse: 29427.2344\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19774.4160 - mse: 19774.4160 - val_loss: 42691.5586 - val_mse: 42691.5586\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 28733.7559 - mse: 28733.7559 - val_loss: 48510.0352 - val_mse: 48510.0352\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 32665.2285 - mse: 32665.2285 - val_loss: 45443.6758 - val_mse: 45443.6758\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 30604.8301 - mse: 30604.8301 - val_loss: 35314.2305 - val_mse: 35314.2305\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 23777.0957 - mse: 23777.0957 - val_loss: 22015.7969 - val_mse: 22015.7969\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 14797.4688 - mse: 14797.4688 - val_loss: 912469.0625 - val_mse: 912469.0625\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 618634.8750 - mse: 618634.8750 - val_loss: 19580.8496 - val_mse: 19580.8496\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 13148.8125 - mse: 13148.8125 - val_loss: 26890.5859 - val_mse: 26890.5859\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18093.4512 - mse: 18093.4512 - val_loss: 29214.7188 - val_mse: 29214.7188\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19655.1582 - mse: 19655.1582 - val_loss: 26158.5000 - val_mse: 26158.5000\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17583.1113 - mse: 17583.1113 - val_loss: 19256.4141 - val_mse: 19256.4141\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12919.2158 - mse: 12919.2158 - val_loss: 11115.2734 - val_mse: 11115.2734\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7426.9097 - mse: 7426.9097 - val_loss: 4337.5562 - val_mse: 4337.5562\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2859.5842 - mse: 2859.5842 - val_loss: 624.9265 - val_mse: 624.9265\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 368.3615 - mse: 368.3615 - val_loss: 356.5815 - val_mse: 356.5815\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 207.6536 - mse: 207.6536 - val_loss: 2697.3376 - val_mse: 2697.3376\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1809.5903 - mse: 1809.5903 - val_loss: 6095.9038 - val_mse: 6095.9038\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4123.9756 - mse: 4123.9756 - val_loss: 8943.1240 - val_mse: 8943.1240\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6060.1450 - mse: 6060.1450 - val_loss: 10132.9795 - val_mse: 10132.9795\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6870.7280 - mse: 6870.7280 - val_loss: 9362.1885 - val_mse: 9362.1885\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6346.0093 - mse: 6346.0093 - val_loss: 7082.5093 - val_mse: 7082.5093\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4796.6680 - mse: 4796.6680 - val_loss: 2646.0273 - val_mse: 2646.0273\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1777.5068 - mse: 1777.5068 - val_loss: 284.9829 - val_mse: 284.9829\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 160.6553 - mse: 160.6553 - val_loss: 7078.6089 - val_mse: 7078.6089\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4707.4644 - mse: 4707.4644 - val_loss: 2576.3203 - val_mse: 2576.3203\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1679.0165 - mse: 1679.0165 - val_loss: 448.4612 - val_mse: 448.4612\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 256.5955 - mse: 256.5955 - val_loss: 170.1091 - val_mse: 170.1091\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 73.4598 - mse: 73.4598 - val_loss: 74.4155 - val_mse: 74.4155\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.4867 - mse: 12.4867 - val_loss: 82.6018 - val_mse: 82.6018\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.2586 - mse: 18.2586 - val_loss: 91.3289 - val_mse: 91.3289\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24.3983 - mse: 24.3983 - val_loss: 95.5107 - val_mse: 95.5107\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 28.0086 - mse: 28.0086 - val_loss: 93.6705 - val_mse: 93.6705\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27.8141 - mse: 27.8141 - val_loss: 86.1834 - val_mse: 86.1834\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24.1890 - mse: 24.1890 - val_loss: 75.4686 - val_mse: 75.4686\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 18.6230 - mse: 18.6230 - val_loss: 64.3341 - val_mse: 64.3341\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 13.0994 - mse: 13.0994 - val_loss: 556.9133 - val_mse: 556.9133\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 337.9788 - mse: 337.9788 - val_loss: 53.1686 - val_mse: 53.1686\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.2175 - mse: 11.2175 - val_loss: 68.6137 - val_mse: 68.6137\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24.9919 - mse: 24.9919 - val_loss: 88.7073 - val_mse: 88.7073\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 41.7530 - mse: 41.7530 - val_loss: 101.5621 - val_mse: 101.5621\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 53.2074 - mse: 53.2074 - val_loss: 99.9801 - val_mse: 99.9801\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 54.4911 - mse: 54.4911 - val_loss: 84.1012 - val_mse: 84.1012\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 45.9054 - mse: 45.9054 - val_loss: 59.3995 - val_mse: 59.3995\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 31.5709 - mse: 31.5709 - val_loss: 35.3162 - val_mse: 35.3162\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18.8378 - mse: 18.8378 - val_loss: 21.6796 - val_mse: 21.6796\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.6664 - mse: 6.6664 - val_loss: 18.7306 - val_mse: 18.7306\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3825 - mse: 2.3825 - val_loss: 24.4217 - val_mse: 24.4217\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.2332 - mse: 5.2332 - val_loss: 33.8518 - val_mse: 33.8518\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.6247 - mse: 11.6247 - val_loss: 41.2057 - val_mse: 41.2057\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.6058 - mse: 17.6058 - val_loss: 42.8943 - val_mse: 42.8943\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21.0614 - mse: 21.0614 - val_loss: 42.3073 - val_mse: 42.3073\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.3209 - mse: 20.3209 - val_loss: 38.9481 - val_mse: 38.9481\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.1951 - mse: 16.1951 - val_loss: 31.0855 - val_mse: 31.0855\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.7438 - mse: 10.7438 - val_loss: 21.4846 - val_mse: 21.4846\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.3771 - mse: 5.3771 - val_loss: 13.7139 - val_mse: 13.7139\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5278 - mse: 2.5278 - val_loss: 12.9507 - val_mse: 12.9507\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2679 - mse: 2.2679 - val_loss: 16.9181 - val_mse: 16.9181\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0610 - mse: 4.0610 - val_loss: 21.1105 - val_mse: 21.1105\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.7629 - mse: 6.7629 - val_loss: 22.9152 - val_mse: 22.9152\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.5187 - mse: 8.5187 - val_loss: 21.8899 - val_mse: 21.8899\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.8882 - mse: 8.8882 - val_loss: 19.8773 - val_mse: 19.8773\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.9052 - mse: 7.9052 - val_loss: 18.9876 - val_mse: 18.9876\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.6898 - mse: 5.6898 - val_loss: 17.7423 - val_mse: 17.7423\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4787 - mse: 3.4787 - val_loss: 16.2570 - val_mse: 16.2570\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7150 - mse: 1.7150 - val_loss: 15.1926 - val_mse: 15.1926\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8298 - mse: 0.8298 - val_loss: 15.0909 - val_mse: 15.0909\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5965 - mse: 1.5965 - val_loss: 18.1101 - val_mse: 18.1101\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0401 - mse: 2.0401 - val_loss: 21.0495 - val_mse: 21.0495\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.1315 - mse: 3.1315 - val_loss: 21.9252 - val_mse: 21.9252\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7867 - mse: 3.7867 - val_loss: 20.6081 - val_mse: 20.6081\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.5640 - mse: 3.5640 - val_loss: 18.0482 - val_mse: 18.0482\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8672 - mse: 2.8672 - val_loss: 16.0759 - val_mse: 16.0759\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1344 - mse: 2.1344 - val_loss: 15.5514 - val_mse: 15.5514\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2158 - mse: 1.2158 - val_loss: 14.8330 - val_mse: 14.8330\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8596 - mse: 0.8596 - val_loss: 13.6584 - val_mse: 13.6584\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8406 - mse: 0.8406 - val_loss: 12.2064 - val_mse: 12.2064\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0451 - mse: 1.0451 - val_loss: 11.1611 - val_mse: 11.1611\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4493 - mse: 1.4493 - val_loss: 11.0490 - val_mse: 11.0490\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7412 - mse: 1.7412 - val_loss: 11.6970 - val_mse: 11.6970\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7380 - mse: 1.7380 - val_loss: 12.2864 - val_mse: 12.2864\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5821 - mse: 1.5821 - val_loss: 12.1673 - val_mse: 12.1673\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2873 - mse: 1.2873 - val_loss: 11.4085 - val_mse: 11.4085\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9213 - mse: 0.9213 - val_loss: 10.4367 - val_mse: 10.4367\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6785 - mse: 0.6785 - val_loss: 9.9724 - val_mse: 9.9724\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6400 - mse: 0.6400 - val_loss: 10.2965 - val_mse: 10.2965\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7074 - mse: 0.7074 - val_loss: 11.1335 - val_mse: 11.1335\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8412 - mse: 0.8412 - val_loss: 11.8579 - val_mse: 11.8579\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9615 - mse: 0.9615 - val_loss: 11.8493 - val_mse: 11.8493\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0034 - mse: 1.0034 - val_loss: 11.2165 - val_mse: 11.2165\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9575 - mse: 0.9575 - val_loss: 10.3817 - val_mse: 10.3817\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8414 - mse: 0.8414 - val_loss: 9.6277 - val_mse: 9.6277\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6956 - mse: 0.6956 - val_loss: 9.1021 - val_mse: 9.1021\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5944 - mse: 0.5944 - val_loss: 8.8001 - val_mse: 8.8001\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5560 - mse: 0.5560 - val_loss: 8.5815 - val_mse: 8.5815\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5709 - mse: 0.5709 - val_loss: 8.3737 - val_mse: 8.3737\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6159 - mse: 0.6159 - val_loss: 8.1190 - val_mse: 8.1190\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6775 - mse: 0.6775 - val_loss: 7.8613 - val_mse: 7.8613\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6847 - mse: 0.6847 - val_loss: 7.6412 - val_mse: 7.6412\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6718 - mse: 0.6718 - val_loss: 7.5180 - val_mse: 7.5180\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6242 - mse: 0.6242 - val_loss: 7.4703 - val_mse: 7.4703\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5615 - mse: 0.5615 - val_loss: 7.4643 - val_mse: 7.4643\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5181 - mse: 0.5181 - val_loss: 7.4656 - val_mse: 7.4656\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4983 - mse: 0.4983 - val_loss: 7.4719 - val_mse: 7.4719\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4965 - mse: 0.4965 - val_loss: 7.4938 - val_mse: 7.4938\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5140 - mse: 0.5140 - val_loss: 7.5045 - val_mse: 7.5045\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5304 - mse: 0.5304 - val_loss: 7.4713 - val_mse: 7.4713\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5304 - mse: 0.5304 - val_loss: 7.3931 - val_mse: 7.3931\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5217 - mse: 0.5217 - val_loss: 7.2019 - val_mse: 7.2019\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5085 - mse: 0.5085 - val_loss: 6.8833 - val_mse: 6.8833\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4835 - mse: 0.4835 - val_loss: 6.5668 - val_mse: 6.5668\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4579 - mse: 0.4579 - val_loss: 6.3536 - val_mse: 6.3536\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4459 - mse: 0.4459 - val_loss: 6.2217 - val_mse: 6.2217\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4426 - mse: 0.4426 - val_loss: 6.1612 - val_mse: 6.1612\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4488 - mse: 0.4488 - val_loss: 6.0646 - val_mse: 6.0646\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4473 - mse: 0.4473 - val_loss: 5.9064 - val_mse: 5.9064\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4441 - mse: 0.4441 - val_loss: 5.6962 - val_mse: 5.6962\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4391 - mse: 0.4391 - val_loss: 5.5109 - val_mse: 5.5109\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4319 - mse: 0.4319 - val_loss: 5.4300 - val_mse: 5.4300\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4295 - mse: 0.4295 - val_loss: 5.4531 - val_mse: 5.4531\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4213 - mse: 0.4213 - val_loss: 5.4889 - val_mse: 5.4889\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4064 - mse: 0.4064 - val_loss: 5.4863 - val_mse: 5.4863\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4038 - mse: 0.4038 - val_loss: 5.3994 - val_mse: 5.3994\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3998 - mse: 0.3998 - val_loss: 5.2478 - val_mse: 5.2478\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3960 - mse: 0.3960 - val_loss: 5.1262 - val_mse: 5.1262\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3961 - mse: 0.3961 - val_loss: 5.0492 - val_mse: 5.0492\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3933 - mse: 0.3933 - val_loss: 5.0298 - val_mse: 5.0298\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3888 - mse: 0.3888 - val_loss: 5.0094 - val_mse: 5.0094\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3854 - mse: 0.3854 - val_loss: 4.9349 - val_mse: 4.9349\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3812 - mse: 0.3812 - val_loss: 4.8034 - val_mse: 4.8034\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3780 - mse: 0.3780 - val_loss: 4.6278 - val_mse: 4.6278\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3704 - mse: 0.3704 - val_loss: 4.4845 - val_mse: 4.4845\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3673 - mse: 0.3673 - val_loss: 4.3978 - val_mse: 4.3978\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3644 - mse: 0.3644 - val_loss: 4.3413 - val_mse: 4.3413\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3604 - mse: 0.3604 - val_loss: 4.2851 - val_mse: 4.2851\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3599 - mse: 0.3599 - val_loss: 4.1894 - val_mse: 4.1894\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 4.0759 - val_mse: 4.0759\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3507 - mse: 0.3507 - val_loss: 3.9648 - val_mse: 3.9648\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3474 - mse: 0.3474 - val_loss: 3.8950 - val_mse: 3.8950\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3442 - mse: 0.3442 - val_loss: 3.8589 - val_mse: 3.8589\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3417 - mse: 0.3417 - val_loss: 3.8121 - val_mse: 3.8121\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3384 - mse: 0.3384 - val_loss: 3.7487 - val_mse: 3.7487\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3372 - mse: 0.3372 - val_loss: 3.6732 - val_mse: 3.6732\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3356 - mse: 0.3356 - val_loss: 3.6013 - val_mse: 3.6013\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3349 - mse: 0.3349 - val_loss: 3.5478 - val_mse: 3.5478\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3287 - mse: 0.3287 - val_loss: 3.5051 - val_mse: 3.5051\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3253 - mse: 0.3253 - val_loss: 3.4748 - val_mse: 3.4748\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3253 - mse: 0.3253 - val_loss: 3.4233 - val_mse: 3.4233\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3230 - mse: 0.3230 - val_loss: 3.3554 - val_mse: 3.3554\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3213 - mse: 0.3213 - val_loss: 3.2952 - val_mse: 3.2952\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3154 - mse: 0.3154 - val_loss: 3.2397 - val_mse: 3.2397\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3138 - mse: 0.3138 - val_loss: 3.1990 - val_mse: 3.1990\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3113 - mse: 0.3113 - val_loss: 3.1571 - val_mse: 3.1571\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3090 - mse: 0.3090 - val_loss: 3.1084 - val_mse: 3.1084\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3076 - mse: 0.3076 - val_loss: 3.0486 - val_mse: 3.0486\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3050 - mse: 0.3050 - val_loss: 2.9868 - val_mse: 2.9868\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3026 - mse: 0.3026 - val_loss: 2.9347 - val_mse: 2.9347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3014 - mse: 0.3014 - val_loss: 2.8964 - val_mse: 2.8964\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3023 - mse: 0.3023 - val_loss: 2.8577 - val_mse: 2.8577\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2991 - mse: 0.2991 - val_loss: 2.8116 - val_mse: 2.8116\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2965 - mse: 0.2965 - val_loss: 2.7671 - val_mse: 2.7671\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2964 - mse: 0.2964 - val_loss: 2.7084 - val_mse: 2.7084\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2962 - mse: 0.2962 - val_loss: 2.6607 - val_mse: 2.6607\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2922 - mse: 0.2922 - val_loss: 2.6164 - val_mse: 2.6164\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2899 - mse: 0.2899 - val_loss: 2.5879 - val_mse: 2.5879\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2883 - mse: 0.2883 - val_loss: 2.5545 - val_mse: 2.5545\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2888 - mse: 0.2888 - val_loss: 2.5114 - val_mse: 2.5114\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2870 - mse: 0.2870 - val_loss: 2.4652 - val_mse: 2.4652\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2848 - mse: 0.2848 - val_loss: 2.4235 - val_mse: 2.4235\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2831 - mse: 0.2831 - val_loss: 2.3866 - val_mse: 2.3866\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2829 - mse: 0.2829 - val_loss: 2.3538 - val_mse: 2.3538\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2809 - mse: 0.2809 - val_loss: 2.3260 - val_mse: 2.3260\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2800 - mse: 0.2800 - val_loss: 2.2873 - val_mse: 2.2873\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2782 - mse: 0.2782 - val_loss: 2.2514 - val_mse: 2.2514\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2765 - mse: 0.2765 - val_loss: 2.2215 - val_mse: 2.2215\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2760 - mse: 0.2760 - val_loss: 2.1853 - val_mse: 2.1853\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2745 - mse: 0.2745 - val_loss: 2.1582 - val_mse: 2.1582\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2719 - mse: 0.2719 - val_loss: 2.1317 - val_mse: 2.1317\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2707 - mse: 0.2707 - val_loss: 2.0966 - val_mse: 2.0966\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2698 - mse: 0.2698 - val_loss: 2.0711 - val_mse: 2.0711\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2680 - mse: 0.2680 - val_loss: 2.0427 - val_mse: 2.0427\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2671 - mse: 0.2671 - val_loss: 2.0110 - val_mse: 2.0110\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2660 - mse: 0.2660 - val_loss: 1.9834 - val_mse: 1.9834\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2658 - mse: 0.2658 - val_loss: 1.9560 - val_mse: 1.9560\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2645 - mse: 0.2645 - val_loss: 1.9296 - val_mse: 1.9296\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2634 - mse: 0.2634 - val_loss: 1.9050 - val_mse: 1.9050\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2627 - mse: 0.2627 - val_loss: 1.8780 - val_mse: 1.8780\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2616 - mse: 0.2616 - val_loss: 1.8616 - val_mse: 1.8616\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2611 - mse: 0.2611 - val_loss: 1.8383 - val_mse: 1.8383\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2603 - mse: 0.2603 - val_loss: 1.8115 - val_mse: 1.8115\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2592 - mse: 0.2592 - val_loss: 1.7888 - val_mse: 1.7888\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2585 - mse: 0.2585 - val_loss: 1.7663 - val_mse: 1.7663\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2577 - mse: 0.2577 - val_loss: 1.7452 - val_mse: 1.7452\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2567 - mse: 0.2567 - val_loss: 1.7254 - val_mse: 1.7254\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2571 - mse: 0.2571 - val_loss: 1.7067 - val_mse: 1.7067\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2564 - mse: 0.2564 - val_loss: 1.6876 - val_mse: 1.6876\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2554 - mse: 0.2554 - val_loss: 1.6682 - val_mse: 1.6682\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2548 - mse: 0.2548 - val_loss: 1.6530 - val_mse: 1.6530\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2545 - mse: 0.2545 - val_loss: 1.6309 - val_mse: 1.6309\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2529 - mse: 0.2529 - val_loss: 1.6153 - val_mse: 1.6153\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2520 - mse: 0.2520 - val_loss: 1.6005 - val_mse: 1.6005\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2519 - mse: 0.2519 - val_loss: 1.5820 - val_mse: 1.5820\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2518 - mse: 0.2518 - val_loss: 1.5690 - val_mse: 1.5690\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2510 - mse: 0.2510 - val_loss: 1.5475 - val_mse: 1.5475\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2506 - mse: 0.2506 - val_loss: 1.5318 - val_mse: 1.5318\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2494 - mse: 0.2494 - val_loss: 1.5190 - val_mse: 1.5190\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2485 - mse: 0.2485 - val_loss: 1.5071 - val_mse: 1.5071\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 1.4944 - val_mse: 1.4944\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2480 - mse: 0.2480 - val_loss: 1.4796 - val_mse: 1.4796\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2474 - mse: 0.2474 - val_loss: 1.4643 - val_mse: 1.4643\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2469 - mse: 0.2469 - val_loss: 1.4550 - val_mse: 1.4550\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2465 - mse: 0.2465 - val_loss: 1.4396 - val_mse: 1.4396\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2457 - mse: 0.2457 - val_loss: 1.4302 - val_mse: 1.4302\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2455 - mse: 0.2455 - val_loss: 1.4193 - val_mse: 1.4193\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2453 - mse: 0.2453 - val_loss: 1.4063 - val_mse: 1.4063\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2445 - mse: 0.2445 - val_loss: 1.3934 - val_mse: 1.3934\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2440 - mse: 0.2440 - val_loss: 1.3816 - val_mse: 1.3816\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2439 - mse: 0.2439 - val_loss: 1.3720 - val_mse: 1.3720\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2428 - mse: 0.2428 - val_loss: 1.3633 - val_mse: 1.3633\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2423 - mse: 0.2423 - val_loss: 1.3543 - val_mse: 1.3543\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2421 - mse: 0.2421 - val_loss: 1.3431 - val_mse: 1.3431\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2425 - mse: 0.2425 - val_loss: 1.3315 - val_mse: 1.3315\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2421 - mse: 0.2421 - val_loss: 1.3215 - val_mse: 1.3215\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 1.3132 - val_mse: 1.3132\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2406 - mse: 0.2406 - val_loss: 1.3058 - val_mse: 1.3058\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 1.2979 - val_mse: 1.2979\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 1.2883 - val_mse: 1.2883\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2396 - mse: 0.2396 - val_loss: 1.2784 - val_mse: 1.2784\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2393 - mse: 0.2393 - val_loss: 1.2697 - val_mse: 1.2697\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2389 - mse: 0.2389 - val_loss: 1.2625 - val_mse: 1.2625\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2387 - mse: 0.2387 - val_loss: 1.2560 - val_mse: 1.2560\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2382 - mse: 0.2382 - val_loss: 1.2487 - val_mse: 1.2487\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2383 - mse: 0.2383 - val_loss: 1.2403 - val_mse: 1.2403\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2379 - mse: 0.2379 - val_loss: 1.2320 - val_mse: 1.2320\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 1.2250 - val_mse: 1.2250\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2374 - mse: 0.2374 - val_loss: 1.2191 - val_mse: 1.2191\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 1.2133 - val_mse: 1.2133\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2366 - mse: 0.2366 - val_loss: 1.2096 - val_mse: 1.2096\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 1.2020 - val_mse: 1.2020\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 1.1921 - val_mse: 1.1921\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2361 - mse: 0.2361 - val_loss: 1.1863 - val_mse: 1.1863\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2356 - mse: 0.2356 - val_loss: 1.1808 - val_mse: 1.1808\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2354 - mse: 0.2354 - val_loss: 1.1753 - val_mse: 1.1753\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2354 - mse: 0.2354 - val_loss: 1.1724 - val_mse: 1.1724\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2352 - mse: 0.2352 - val_loss: 1.1664 - val_mse: 1.1664\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2352 - mse: 0.2352 - val_loss: 1.1609 - val_mse: 1.1609\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2352 - mse: 0.2352 - val_loss: 1.1558 - val_mse: 1.1558\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2349 - mse: 0.2349 - val_loss: 1.1475 - val_mse: 1.1475\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2344 - mse: 0.2344 - val_loss: 1.1421 - val_mse: 1.1421\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2342 - mse: 0.2342 - val_loss: 1.1396 - val_mse: 1.1396\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2340 - mse: 0.2340 - val_loss: 1.1344 - val_mse: 1.1344\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2343 - mse: 0.2343 - val_loss: 1.1300 - val_mse: 1.1300\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2330 - mse: 0.2330 - val_loss: 1.1260 - val_mse: 1.1260\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2338 - mse: 0.2338 - val_loss: 1.1216 - val_mse: 1.1216\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2335 - mse: 0.2335 - val_loss: 1.1163 - val_mse: 1.1163\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 1.1106 - val_mse: 1.1106\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2331 - mse: 0.2331 - val_loss: 1.1061 - val_mse: 1.1061\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2323 - mse: 0.2323 - val_loss: 1.1030 - val_mse: 1.1030\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2327 - mse: 0.2327 - val_loss: 1.0998 - val_mse: 1.0998\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2328 - mse: 0.2328 - val_loss: 1.0953 - val_mse: 1.0953\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2327 - mse: 0.2327 - val_loss: 1.0868 - val_mse: 1.0868\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2324 - mse: 0.2324 - val_loss: 1.0821 - val_mse: 1.0821\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2315 - mse: 0.2315 - val_loss: 1.0792 - val_mse: 1.0792\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 1.0766 - val_mse: 1.0766\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2323 - mse: 0.2323 - val_loss: 1.0729 - val_mse: 1.0729\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2320 - mse: 0.2320 - val_loss: 1.0684 - val_mse: 1.0684\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2319 - mse: 0.2319 - val_loss: 1.0640 - val_mse: 1.0640\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2312 - mse: 0.2312 - val_loss: 1.0608 - val_mse: 1.0608\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2318 - mse: 0.2318 - val_loss: 1.0582 - val_mse: 1.0582\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2304 - mse: 0.2304 - val_loss: 1.0550 - val_mse: 1.0550\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 1.0509 - val_mse: 1.0509\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 1.0469 - val_mse: 1.0469\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2301 - mse: 0.2301 - val_loss: 1.0439 - val_mse: 1.0439\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2313 - mse: 0.2313 - val_loss: 1.0416 - val_mse: 1.0416\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2312 - mse: 0.2312 - val_loss: 1.0391 - val_mse: 1.0391\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2301 - mse: 0.2301 - val_loss: 1.0357 - val_mse: 1.0357\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2300 - mse: 0.2300 - val_loss: 1.0318 - val_mse: 1.0318\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2304 - mse: 0.2304 - val_loss: 1.0282 - val_mse: 1.0282\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 1.0215 - val_mse: 1.0215\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2294 - mse: 0.2294 - val_loss: 1.0239 - val_mse: 1.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 1.0219 - val_mse: 1.0219\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2305 - mse: 0.2305 - val_loss: 1.0188 - val_mse: 1.0188\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2300 - mse: 0.2300 - val_loss: 1.0153 - val_mse: 1.0153\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2303 - mse: 0.2303 - val_loss: 1.0121 - val_mse: 1.0121\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2303 - mse: 0.2303 - val_loss: 1.0098 - val_mse: 1.0098\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2303 - mse: 0.2303 - val_loss: 1.0083 - val_mse: 1.0083\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2301 - mse: 0.2301 - val_loss: 1.0063 - val_mse: 1.0063\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2295 - mse: 0.2295 - val_loss: 1.0034 - val_mse: 1.0034\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2294 - mse: 0.2294 - val_loss: 1.0000 - val_mse: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2292 - mse: 0.2292 - val_loss: 0.9974 - val_mse: 0.9974\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.9960 - val_mse: 0.9960\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2289 - mse: 0.2289 - val_loss: 0.9945 - val_mse: 0.9945\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2290 - mse: 0.2290 - val_loss: 0.9922 - val_mse: 0.9922\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2297 - mse: 0.2297 - val_loss: 0.9891 - val_mse: 0.9891\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2293 - mse: 0.2293 - val_loss: 0.9867 - val_mse: 0.9867\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2287 - mse: 0.2287 - val_loss: 0.9848 - val_mse: 0.9848\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2294 - mse: 0.2294 - val_loss: 0.9832 - val_mse: 0.9832\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2287 - mse: 0.2287 - val_loss: 0.9813 - val_mse: 0.9813\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.9793 - val_mse: 0.9793\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2286 - mse: 0.2286 - val_loss: 0.9770 - val_mse: 0.9770\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2284 - mse: 0.2284 - val_loss: 0.9748 - val_mse: 0.9748\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2285 - mse: 0.2285 - val_loss: 0.9732 - val_mse: 0.9732\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2290 - mse: 0.2290 - val_loss: 0.9719 - val_mse: 0.9719\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2287 - mse: 0.2287 - val_loss: 0.9700 - val_mse: 0.9700\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.9677 - val_mse: 0.9677\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2284 - mse: 0.2284 - val_loss: 0.9657 - val_mse: 0.9657\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 0.9642 - val_mse: 0.9642\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 0.9630 - val_mse: 0.9630\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.9614 - val_mse: 0.9614\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2281 - mse: 0.2281 - val_loss: 0.9592 - val_mse: 0.9592\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 0.9573 - val_mse: 0.9573\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2281 - mse: 0.2281 - val_loss: 0.9560 - val_mse: 0.9560\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 0.9551 - val_mse: 0.9551\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.9540 - val_mse: 0.9540\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 0.9522 - val_mse: 0.9522\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.9483 - val_mse: 0.9483\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 0.9472 - val_mse: 0.9472\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2290 - mse: 0.2290 - val_loss: 0.9462 - val_mse: 0.9462\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 0.9450 - val_mse: 0.9450\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 0.9433 - val_mse: 0.9433\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.9415 - val_mse: 0.9415\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 0.9401 - val_mse: 0.9401\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 0.9392 - val_mse: 0.9392\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 0.9382 - val_mse: 0.9382\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 0.9372 - val_mse: 0.9372\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 0.9358 - val_mse: 0.9358\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2286 - mse: 0.2286 - val_loss: 0.9345 - val_mse: 0.9345\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2281 - mse: 0.2281 - val_loss: 0.9331 - val_mse: 0.9331\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 0.9319 - val_mse: 0.9319\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.9310 - val_mse: 0.9310\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.9304 - val_mse: 0.9304\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.9292 - val_mse: 0.9292\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.9277 - val_mse: 0.9277\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 0.9262 - val_mse: 0.9262\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 0.9252 - val_mse: 0.9252\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 0.9246 - val_mse: 0.9246\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.9241 - val_mse: 0.9241\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9229 - val_mse: 0.9229\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9217 - val_mse: 0.9217\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9203 - val_mse: 0.9203\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2273 - mse: 0.2273 - val_loss: 0.9194 - val_mse: 0.9194\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.9188 - val_mse: 0.9188\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9182 - val_mse: 0.9182\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.9172 - val_mse: 0.9172\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2271 - mse: 0.2271 - val_loss: 0.9162 - val_mse: 0.9162\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2273 - mse: 0.2273 - val_loss: 0.9151 - val_mse: 0.9151\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9142 - val_mse: 0.9142\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 0.9133 - val_mse: 0.9133\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2278 - mse: 0.2278 - val_loss: 0.9127 - val_mse: 0.9127\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.9081 - val_mse: 0.9081\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.9118 - val_mse: 0.9118\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.9106 - val_mse: 0.9106\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.9091 - val_mse: 0.9091\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2283 - mse: 0.2283 - val_loss: 0.9082 - val_mse: 0.9082\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.9038 - val_mse: 0.9038\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.9038 - val_mse: 0.9038\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.9032 - val_mse: 0.9032\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.9060 - val_mse: 0.9060\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9047 - val_mse: 0.9047\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.9041 - val_mse: 0.9041\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.9038 - val_mse: 0.9038\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8995 - val_mse: 0.8995\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8992 - val_mse: 0.8992\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.9023 - val_mse: 0.9023\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.9009 - val_mse: 0.9009\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.9000 - val_mse: 0.9000\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.8958 - val_mse: 0.8958\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8960 - val_mse: 0.8960\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2285 - mse: 0.2285 - val_loss: 0.8999 - val_mse: 0.8999\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2271 - mse: 0.2271 - val_loss: 0.8986 - val_mse: 0.8986\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.8970 - val_mse: 0.8970\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.8965 - val_mse: 0.8965\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.8928 - val_mse: 0.8928\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8932 - val_mse: 0.8932\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8967 - val_mse: 0.8967\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8950 - val_mse: 0.8950\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8936 - val_mse: 0.8936\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.8936 - val_mse: 0.8936\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8901 - val_mse: 0.8901\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8902 - val_mse: 0.8902\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8933 - val_mse: 0.8933\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.8917 - val_mse: 0.8917\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8910 - val_mse: 0.8910\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8914 - val_mse: 0.8914\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8876 - val_mse: 0.8876\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8871 - val_mse: 0.8871\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8899 - val_mse: 0.8899\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8889 - val_mse: 0.8889\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8848 - val_mse: 0.8848\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8854 - val_mse: 0.8854\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8894 - val_mse: 0.8894\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8881 - val_mse: 0.8881\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8829 - val_mse: 0.8829\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8828 - val_mse: 0.8828\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8834 - val_mse: 0.8834\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8876 - val_mse: 0.8876\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8865 - val_mse: 0.8865\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2289 - mse: 0.2289 - val_loss: 0.8842 - val_mse: 0.8842\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8838 - val_mse: 0.8838\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8844 - val_mse: 0.8844\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8890 - val_mse: 0.8890\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8880 - val_mse: 0.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8866 - val_mse: 0.8866\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.8821 - val_mse: 0.8821\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8830 - val_mse: 0.8830\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8876 - val_mse: 0.8876\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8865 - val_mse: 0.8865\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8849 - val_mse: 0.8849\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8804 - val_mse: 0.8804\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8814 - val_mse: 0.8814\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8818 - val_mse: 0.8818\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8809 - val_mse: 0.8809\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8796 - val_mse: 0.8796\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8793 - val_mse: 0.8793\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8841 - val_mse: 0.8841\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8802 - val_mse: 0.8802\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8795 - val_mse: 0.8795\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8786 - val_mse: 0.8786\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8783 - val_mse: 0.8783\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8785 - val_mse: 0.8785\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8788 - val_mse: 0.8788\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8784 - val_mse: 0.8784\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8818 - val_mse: 0.8818\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8814 - val_mse: 0.8814\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8774 - val_mse: 0.8774\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8775 - val_mse: 0.8775\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8775 - val_mse: 0.8775\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8770 - val_mse: 0.8770\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8804 - val_mse: 0.8804\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2267 - mse: 0.2267 - val_loss: 0.8802 - val_mse: 0.8802\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8763 - val_mse: 0.8763\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8765 - val_mse: 0.8765\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8760 - val_mse: 0.8760\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8795 - val_mse: 0.8795\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8794 - val_mse: 0.8794\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2286 - mse: 0.2286 - val_loss: 0.8753 - val_mse: 0.8753\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8755 - val_mse: 0.8755\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8753 - val_mse: 0.8753\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8746 - val_mse: 0.8746\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8743 - val_mse: 0.8743\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8746 - val_mse: 0.8746\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8789 - val_mse: 0.8789\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8784 - val_mse: 0.8784\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8739 - val_mse: 0.8739\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8740 - val_mse: 0.8740\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8734 - val_mse: 0.8734\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8730 - val_mse: 0.8730\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8730 - val_mse: 0.8730\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8732 - val_mse: 0.8732\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8733 - val_mse: 0.8733\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8728 - val_mse: 0.8728\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8725 - val_mse: 0.8725\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8723 - val_mse: 0.8723\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8760 - val_mse: 0.8760\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8756 - val_mse: 0.8756\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8716 - val_mse: 0.8716\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8719 - val_mse: 0.8719\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8721 - val_mse: 0.8721\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8759 - val_mse: 0.8759\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8749 - val_mse: 0.8749\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8754 - val_mse: 0.8754\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.8765 - val_mse: 0.8765\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8720 - val_mse: 0.8720\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8747 - val_mse: 0.8747\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8694 - val_mse: 0.8694\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2286 - mse: 0.2286 - val_loss: 0.8720 - val_mse: 0.8720\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8761 - val_mse: 0.8761\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8742 - val_mse: 0.8742\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8699 - val_mse: 0.8699\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8717 - val_mse: 0.8717\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8717 - val_mse: 0.8717\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8739 - val_mse: 0.8739\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8712 - val_mse: 0.8712\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8715 - val_mse: 0.8715\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8740 - val_mse: 0.8740\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8708 - val_mse: 0.8708\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8711 - val_mse: 0.8711\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8731 - val_mse: 0.8731\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8698 - val_mse: 0.8698\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8698 - val_mse: 0.8698\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8687 - val_mse: 0.8687\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8730 - val_mse: 0.8730\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8733 - val_mse: 0.8733\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8728 - val_mse: 0.8728\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2276 - mse: 0.2276 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8687 - val_mse: 0.8687\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8686 - val_mse: 0.8686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8687 - val_mse: 0.8687\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8681 - val_mse: 0.8681\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8685 - val_mse: 0.8685\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8679 - val_mse: 0.8679\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8729 - val_mse: 0.8729\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8723 - val_mse: 0.8723\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8677 - val_mse: 0.8677\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8685 - val_mse: 0.8685\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8677 - val_mse: 0.8677\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8678 - val_mse: 0.8678\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8676 - val_mse: 0.8676\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8685 - val_mse: 0.8685\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8679 - val_mse: 0.8679\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8679 - val_mse: 0.8679\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8681 - val_mse: 0.8681\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8681 - val_mse: 0.8681\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8723 - val_mse: 0.8723\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8677 - val_mse: 0.8677\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8685 - val_mse: 0.8685\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8676 - val_mse: 0.8676\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8673 - val_mse: 0.8673\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8676 - val_mse: 0.8676\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8687 - val_mse: 0.8687\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8679 - val_mse: 0.8679\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.8678 - val_mse: 0.8678\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2277 - mse: 0.2277 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2278 - mse: 0.2278 - val_loss: 0.8687 - val_mse: 0.8687\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2280 - mse: 0.2280 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8684 - val_mse: 0.8684\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8678 - val_mse: 0.8678\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8674 - val_mse: 0.8674\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8696 - val_mse: 0.8696\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8676 - val_mse: 0.8676\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8676 - val_mse: 0.8676\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8718 - val_mse: 0.8718\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8735 - val_mse: 0.8735\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8677 - val_mse: 0.8677\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8737 - val_mse: 0.8737\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8688 - val_mse: 0.8688\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8697 - val_mse: 0.8697\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8678 - val_mse: 0.8678\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8682 - val_mse: 0.8682\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8693 - val_mse: 0.8693\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8681 - val_mse: 0.8681\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.8694 - val_mse: 0.8694\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8689 - val_mse: 0.8689\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8732 - val_mse: 0.8732\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8685 - val_mse: 0.8685\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8726 - val_mse: 0.8726\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8727 - val_mse: 0.8727\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8678 - val_mse: 0.8678\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8732 - val_mse: 0.8732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8703 - val_mse: 0.8703\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8718 - val_mse: 0.8718\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8680 - val_mse: 0.8680\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8743 - val_mse: 0.8743\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8747 - val_mse: 0.8747\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8729 - val_mse: 0.8729\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8717 - val_mse: 0.8717\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8686 - val_mse: 0.8686\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.8748 - val_mse: 0.8748\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8703 - val_mse: 0.8703\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8675 - val_mse: 0.8675\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8711 - val_mse: 0.8711\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.8697 - val_mse: 0.8697\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.8719 - val_mse: 0.8719\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8683 - val_mse: 0.8683\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2241 - mse: 0.2241 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8747 - val_mse: 0.8747\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2244 - mse: 0.2244 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8741 - val_mse: 0.8741\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8729 - val_mse: 0.8729\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8735 - val_mse: 0.8735\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.8699 - val_mse: 0.8699\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8739 - val_mse: 0.8739\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2244 - mse: 0.2244 - val_loss: 0.8693 - val_mse: 0.8693\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.8693 - val_mse: 0.8693\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8703 - val_mse: 0.8703\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.8696 - val_mse: 0.8696\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.8690 - val_mse: 0.8690\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2244 - mse: 0.2244 - val_loss: 0.8694 - val_mse: 0.8694\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2244 - mse: 0.2244 - val_loss: 0.8702 - val_mse: 0.8702\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2239 - mse: 0.2239 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8699 - val_mse: 0.8699\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8702 - val_mse: 0.8702\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8696 - val_mse: 0.8696\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8694 - val_mse: 0.8694\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 0.8702 - val_mse: 0.8702\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8696 - val_mse: 0.8696\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8743 - val_mse: 0.8743\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8697 - val_mse: 0.8697\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8734 - val_mse: 0.8734\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8707 - val_mse: 0.8707\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8698 - val_mse: 0.8698\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.8733 - val_mse: 0.8733\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8701 - val_mse: 0.8701\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8708 - val_mse: 0.8708\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8698 - val_mse: 0.8698\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8701 - val_mse: 0.8701\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.8706 - val_mse: 0.8706\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.8699 - val_mse: 0.8699\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2271 - mse: 0.2271 - val_loss: 0.8705 - val_mse: 0.8705\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2271 - mse: 0.2271 - val_loss: 0.8702 - val_mse: 0.8702\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.8741 - val_mse: 0.8741\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2255 - mse: 0.2255 - val_loss: 0.8709 - val_mse: 0.8709\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8703 - val_mse: 0.8703\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8740 - val_mse: 0.8740\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2278 - mse: 0.2278 - val_loss: 0.8712 - val_mse: 0.8712\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8710 - val_mse: 0.8710\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8696 - val_mse: 0.8696\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8712 - val_mse: 0.8712\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8712 - val_mse: 0.8712\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8697 - val_mse: 0.8697\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8693 - val_mse: 0.8693\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.8707 - val_mse: 0.8707\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8709 - val_mse: 0.8709\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8695 - val_mse: 0.8695\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8702 - val_mse: 0.8702\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.8705 - val_mse: 0.8705\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8742 - val_mse: 0.8742\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2273 - mse: 0.2273 - val_loss: 0.8699 - val_mse: 0.8699\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8741 - val_mse: 0.8741\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2273 - mse: 0.2273 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.8703 - val_mse: 0.8703\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8697 - val_mse: 0.8697\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2245 - mse: 0.2245 - val_loss: 0.8699 - val_mse: 0.8699\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8706 - val_mse: 0.8706\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8708 - val_mse: 0.8708\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.8702 - val_mse: 0.8702\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8696 - val_mse: 0.8696\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.8746 - val_mse: 0.8746\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8714 - val_mse: 0.8714\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8708 - val_mse: 0.8708\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.8700 - val_mse: 0.8700\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2271 - mse: 0.2271 - val_loss: 0.8701 - val_mse: 0.8701\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8710 - val_mse: 0.8710\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.8756 - val_mse: 0.8756\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8709 - val_mse: 0.8709\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.8703 - val_mse: 0.8703\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8711 - val_mse: 0.8711\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8715 - val_mse: 0.8715\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.8710 - val_mse: 0.8710\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8706 - val_mse: 0.8706\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2241 - mse: 0.2241 - val_loss: 0.8709 - val_mse: 0.8709\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2240 - mse: 0.2240 - val_loss: 0.8714 - val_mse: 0.8714\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2241 - mse: 0.2241 - val_loss: 0.8755 - val_mse: 0.8755\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8714 - val_mse: 0.8714\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.8714 - val_mse: 0.8714\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8711 - val_mse: 0.8711\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8754 - val_mse: 0.8754\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.8760 - val_mse: 0.8760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8720 - val_mse: 0.8720\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2263 - mse: 0.2263 - val_loss: 0.8711 - val_mse: 0.8711\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8708 - val_mse: 0.8708\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8762 - val_mse: 0.8762\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2244 - mse: 0.2244 - val_loss: 0.8728 - val_mse: 0.8728\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2239 - mse: 0.2239 - val_loss: 0.8716 - val_mse: 0.8716\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8707 - val_mse: 0.8707\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2256 - mse: 0.2256 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 0.8731 - val_mse: 0.8731\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2236 - mse: 0.2236 - val_loss: 0.8761 - val_mse: 0.8761\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8715 - val_mse: 0.8715\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8723 - val_mse: 0.8723\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2242 - mse: 0.2242 - val_loss: 0.8727 - val_mse: 0.8727\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2234 - mse: 0.2234 - val_loss: 0.8763 - val_mse: 0.8763\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8723 - val_mse: 0.8723\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.8727 - val_mse: 0.8727\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2233 - mse: 0.2233 - val_loss: 0.8724 - val_mse: 0.8724\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.8720 - val_mse: 0.8720\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 0.8726 - val_mse: 0.8726\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.8730 - val_mse: 0.8730\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.8725 - val_mse: 0.8725\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2232 - mse: 0.2232 - val_loss: 0.8720 - val_mse: 0.8720\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2250 - mse: 0.2250 - val_loss: 0.8726 - val_mse: 0.8726\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 0.8776 - val_mse: 0.8776\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.8732 - val_mse: 0.8732\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8720 - val_mse: 0.8720\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8763 - val_mse: 0.8763\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2241 - mse: 0.2241 - val_loss: 0.8780 - val_mse: 0.8780\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2226 - mse: 0.2226 - val_loss: 0.8721 - val_mse: 0.8721\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2252 - mse: 0.2252 - val_loss: 0.8783 - val_mse: 0.8783\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2261 - mse: 0.2261 - val_loss: 0.8742 - val_mse: 0.8742\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2224 - mse: 0.2224 - val_loss: 0.8723 - val_mse: 0.8723\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2226 - mse: 0.2226 - val_loss: 0.8721 - val_mse: 0.8721\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2240 - mse: 0.2240 - val_loss: 0.8783 - val_mse: 0.8783\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.8790 - val_mse: 0.8790\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.8730 - val_mse: 0.8730\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2213 - mse: 0.2213 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 0.8739 - val_mse: 0.8739\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2213 - mse: 0.2213 - val_loss: 0.8747 - val_mse: 0.8747\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2223 - mse: 0.2223 - val_loss: 0.8776 - val_mse: 0.8776\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2221 - mse: 0.2221 - val_loss: 0.8729 - val_mse: 0.8729\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 0.8740 - val_mse: 0.8740\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2228 - mse: 0.2228 - val_loss: 0.8744 - val_mse: 0.8744\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2230 - mse: 0.2230 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2231 - mse: 0.2231 - val_loss: 0.8735 - val_mse: 0.8735\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2216 - mse: 0.2216 - val_loss: 0.8743 - val_mse: 0.8743\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 0.8745 - val_mse: 0.8745\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2202 - mse: 0.2202 - val_loss: 0.8737 - val_mse: 0.8737\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 0.8779 - val_mse: 0.8779\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 0.8788 - val_mse: 0.8788\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2236 - mse: 0.2236 - val_loss: 0.8750 - val_mse: 0.8750\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2228 - mse: 0.2228 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2225 - mse: 0.2225 - val_loss: 0.8775 - val_mse: 0.8775\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2212 - mse: 0.2212 - val_loss: 0.8794 - val_mse: 0.8794\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2208 - mse: 0.2208 - val_loss: 0.8760 - val_mse: 0.8760\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2205 - mse: 0.2205 - val_loss: 0.8736 - val_mse: 0.8736\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2199 - mse: 0.2199 - val_loss: 0.8729 - val_mse: 0.8729\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2227 - mse: 0.2227 - val_loss: 0.8797 - val_mse: 0.8797\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2232 - mse: 0.2232 - val_loss: 0.8764 - val_mse: 0.8764\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 0.8739 - val_mse: 0.8739\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2201 - mse: 0.2201 - val_loss: 0.8731 - val_mse: 0.8731\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8754 - val_mse: 0.8754\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2222 - mse: 0.2222 - val_loss: 0.8807 - val_mse: 0.8807\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2225 - mse: 0.2225 - val_loss: 0.8787 - val_mse: 0.8787\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.8752 - val_mse: 0.8752\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2189 - mse: 0.2189 - val_loss: 0.8801 - val_mse: 0.8801\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2223 - mse: 0.2223 - val_loss: 0.8795 - val_mse: 0.8795\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2224 - mse: 0.2224 - val_loss: 0.8752 - val_mse: 0.8752\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8750 - val_mse: 0.8750\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2184 - mse: 0.2184 - val_loss: 0.8792 - val_mse: 0.8792\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2193 - mse: 0.2193 - val_loss: 0.8802 - val_mse: 0.8802\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2196 - mse: 0.2196 - val_loss: 0.8762 - val_mse: 0.8762\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2206 - mse: 0.2206 - val_loss: 0.8749 - val_mse: 0.8749\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2212 - mse: 0.2212 - val_loss: 0.8788 - val_mse: 0.8788\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 0.8811 - val_mse: 0.8811\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8767 - val_mse: 0.8767\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.8748 - val_mse: 0.8748\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8753 - val_mse: 0.8753\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2186 - mse: 0.2186 - val_loss: 0.8813 - val_mse: 0.8813\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.8811 - val_mse: 0.8811\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2209 - mse: 0.2209 - val_loss: 0.8798 - val_mse: 0.8798\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2208 - mse: 0.2208 - val_loss: 0.8758 - val_mse: 0.8758\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 0.8769 - val_mse: 0.8769\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2206 - mse: 0.2206 - val_loss: 0.8811 - val_mse: 0.8811\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.8762 - val_mse: 0.8762\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2205 - mse: 0.2205 - val_loss: 0.8761 - val_mse: 0.8761\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 0.8810 - val_mse: 0.8810\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2206 - mse: 0.2206 - val_loss: 0.8813 - val_mse: 0.8813\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.8808 - val_mse: 0.8808\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.8805 - val_mse: 0.8805\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8768 - val_mse: 0.8768\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8812 - val_mse: 0.8812\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2186 - mse: 0.2186 - val_loss: 0.8807 - val_mse: 0.8807\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 0.8807 - val_mse: 0.8807\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2203 - mse: 0.2203 - val_loss: 0.8814 - val_mse: 0.8814\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2207 - mse: 0.2207 - val_loss: 0.8813 - val_mse: 0.8813\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2204 - mse: 0.2204 - val_loss: 0.8807 - val_mse: 0.8807\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2203 - mse: 0.2203 - val_loss: 0.8769 - val_mse: 0.8769\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2208 - mse: 0.2208 - val_loss: 0.8773 - val_mse: 0.8773\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2209 - mse: 0.2209 - val_loss: 0.8810 - val_mse: 0.8810\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.8811 - val_mse: 0.8811\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2189 - mse: 0.2189 - val_loss: 0.8819 - val_mse: 0.8819\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.8774 - val_mse: 0.8774\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "shistory = smodel.fit(X_train,y_train,epochs=1000,validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14bd8ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [16.949469 29.559275 51.425472]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(smodel.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14bb0d4f0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOT MSE from the 3 graphs\n",
    "pyplot.plot(history.history['mse'],label='simple')\n",
    "pyplot.plot(bihistory.history['mse'],label='bi')\n",
    "pyplot.plot(shistory.history['mse'],label='stack')\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x153eac820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [24.752184 40.32032  63.249104]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - RELU Activation\n",
    "model = Sequential()\n",
    "model.add(LSTM(m, activation='relu', input_shape=(fib_look, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x151cacca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [13.237977 16.261187 19.617468]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - Sigmoid Activation\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(m, activation='sigmoid', input_shape=(fib_look, 1)))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history2 = model2.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model2.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x152730ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [24.58591  39.834045 61.070248]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - Linear Activation\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(m, activation='linear', input_shape=(fib_look, 1)))\n",
    "model3.add(Dense(1))\n",
    "model3.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history3 = model3.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model3.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1535c8d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [20.892284 26.976177 30.669159]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - TANH Activation\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(m, activation='tanh', input_shape=(fib_look, 1)))\n",
    "model4.add(Dense(1))\n",
    "model4.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history4 = model4.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model4.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x153ae0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [21.79715  36.129433 59.31515 ]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - Softplus Activation\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(m, activation='softplus', input_shape=(fib_look, 1)))\n",
    "model5.add(Dense(1))\n",
    "model5.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history5 = model5.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model5.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x152d6bc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [nan nan nan]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - exponential Activation\n",
    "model6 = Sequential()\n",
    "model6.add(LSTM(m, activation='exponential', input_shape=(fib_look, 1)))\n",
    "model6.add(Dense(1))\n",
    "model6.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history6 = model6.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model6.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]\n",
      "  [13]]\n",
      "\n",
      " [[13]\n",
      "  [21]]\n",
      "\n",
      " [[21]\n",
      "  [34]]]\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x150882550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: [23.138958 38.27629  61.144516]\n",
      "Actual: [21 34 55]\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM - ELU Activation\n",
    "model7 = Sequential()\n",
    "model7.add(LSTM(m, activation='elu', input_shape=(fib_look, 1)))\n",
    "model7.add(Dense(1))\n",
    "model7.compile(optimizer='adam', loss='mse',metrics=['mse'])\n",
    "history7 = model7.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=0)\n",
    "\n",
    "#try on prediction\n",
    "print(X_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(model7.predict(X_test))))\n",
    "print(\"Actual: \" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15307f070>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare all of them together\n",
    "#PLOT MSE from the 7 graphs\n",
    "pyplot.plot(history.history['mse'],label='relu')\n",
    "pyplot.plot(history2.history['mse'],label='sigmoid')\n",
    "pyplot.plot(history3.history['mse'],label='linear')\n",
    "pyplot.plot(history4.history['mse'],label='tanh')\n",
    "pyplot.plot(history5.history['mse'],label='softplus')\n",
    "pyplot.plot(history6.history['mse'],label='exponential')\n",
    "pyplot.plot(history7.history['mse'],label='elu')\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x153fea8e0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print original and best\n",
    "pyplot.plot(history.history['mse'],label='relu')\n",
    "pyplot.plot(history5.history['mse'],label='softplus')\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn from one example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot needs to be able to approximate a recursive function that changes from sequence to sequence. Therefore, we need to come up with a network capable of learning and validating itself from one example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive (Fibonacci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 987]\n",
      "  [1597]]\n",
      "\n",
      " [[1597]\n",
      "  [2584]]]\n",
      "[[2584]\n",
      " [4181]]\n",
      "6765\n"
     ]
    }
   ],
   "source": [
    "#length of input sequence is 4 numbers, guess the 5th\n",
    "print(X_train[:2])\n",
    "print(X_train[2])\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4181]\n",
      "  [6765]]]\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14cc5d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: 10920.7295\n",
      "Actual: 10946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x154726550>]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple LSTM - softplus Activation\n",
    "fib_model = Sequential()\n",
    "fib_model.add(LSTM(50, activation='softplus', input_shape=(fib_look, 1)))\n",
    "fib_model.add(Dense(1))\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "fib_model.compile(optimizer=adam, loss='mse',metrics=['mse'])\n",
    "fib_history = fib_model.fit([X_train[:2]], [y_train[:2]], epochs=500, validation_split=0.0, verbose=0)\n",
    "\n",
    "#predict on unseen\n",
    "xt = np.expand_dims(X_train[3],0)\n",
    "print(xt)\n",
    "print(\"Prediction: \" + str(np.squeeze(fib_model.predict(xt))))\n",
    "print(\"Actual: \" + str(y_train[3]))\n",
    "\n",
    "#plot error\n",
    "pyplot.plot(fib_history.history['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset (input => index of number, output => value)\n",
    "# function: A_n = (2n-1)*2n\n",
    "ind_train = [[[1]],[[2]],[[3]]]     \n",
    "ans_train = [[[2]],[[12]],[[30]]]\n",
    "ind_test = [[[4]]]\n",
    "ans_test = [[[56]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4]]]\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1509fc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: 53.35866\n",
      "Actual: [[[56]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14cace4c0>]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple LSTM - softplus Activation\n",
    "index_model = Sequential()\n",
    "index_model.add(LSTM(50, activation='softplus', input_shape=(1, 1)))\n",
    "index_model.add(Dense(1))\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "index_model.compile(optimizer=adam, loss='mae',metrics=['mae'])\n",
    "index_history = index_model.fit(ind_train, ans_train, epochs=500, validation_split=0.0, verbose=0)\n",
    "\n",
    "#predict on unseen\n",
    "print(ind_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(index_model.predict(ind_test))))\n",
    "print(\"Actual: \" + str(ans_test))\n",
    "\n",
    "#plot error\n",
    "pyplot.plot(index_history.history['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive and index hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2, 1)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "#remember format of fibonacci data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset (input => [value (n), index of number], output => value (n+1))\n",
    "# function: A_{n+1} = 2^{5-n} - A_n\n",
    "n_train = [[[7],[1]],[[9],[2]],[[-1],[3]]]     \n",
    "nplus_train = [[[9]],[[-1]],[[5]]]\n",
    "n_test = [[[5],[4]]]\n",
    "nplus_test = [[[-3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5], [4]]]\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x157486940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction: -1.8089914\n",
      "Actual: [[[-3]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15500d8b0>]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAp80lEQVR4nO3dd3hUVf4/8PfJpNIFgoB0RVzFRaTYEFGxIbrrrn5X3fXnWlbXdde6dl11sevaFcWu2CsSeiChKiShBEgIJISSRnqbTJ/z+2PuTKZmJslM5s6d9+t5eMjcuTNzJjfznnM/99xzhZQSRESkXgnRbgAREXWMQU1EpHIMaiIilWNQExGpHIOaiEjlEiPxpIMHD5ZjxoyJxFMTEWlSXl5erZQy3d99EQnqMWPGIDc3NxJPTUSkSUKIg4HuY+mDiEjlGNRERCoXUulDCHEAQAsAGwCrlHJqJBtFRETtOlOjPldKWRuxlhARkV8sfRARqVyoQS0BrBRC5AkhbvG3ghDiFiFErhAit6amJnwtJCKKc6EG9Qwp5akALgFwuxBipvcKUsoFUsqpUsqp6el+hwISEVEXhBTUUspy5f9qAD8CmB6Jxry+eh/W7mVvnIjIXdCgFkL0FkL0df4M4EIAuyLRmHfXlmAdg5qIyEMooz6OBvCjEMK5/hdSyuWRaExasg4Giy0ST01EFLOCBrWUcj+AST3QFqQm6WBkUBMReVDV8Lw0BjURkQ9VBXVqkg4GM4OaiMidqoI6LYk1aiIib6oK6tRkHQwWe7SbQUSkKqoK6rSkBJjYoyYi8qCqoE5O1MFkZY+aiMidqoJaJwC7lNFuBhGRqqgqqBOEgMFsQ97BBkgGNhERALUFdYJAdYsJf5y/CSt2V0W7OUREqqCqoNY5TlMHAGwpbYhiS4iI1ENVQZ3g1primtboNYSISEXUFdRuPerKRkMUW0JEpB6qDeoKBjUREQCVBbUuoT2o9WYbJ2giIoLKgtrZo+6drAMANLZZotkcIiJVUFVQO404qhcAoKHNHOWWEBFFn6qC2mxzlDqGDUgFwKAmIgJUFtR25WTEwX1SAABNLH0QEakrqJ2njaf3dQR1A4OaiEhtQe3439mjZumDiEhlQe2cOa93sg4piQloZFATEakrqJ09aiGA/mlJaDZYo9sgIiIVUFdQK/8LIdAnJRGtZgY1EZGqgtpZ+hAAeqckQm9iUBMRqSqonaWPBGeP2sigJiJSVVA7e9QJCY4edSt71ERE6gpq18FECPRJ0UHPGjURkcqCWvlfCGeNmrPnERGpKqhdBxOdNWqWPoiI1BXUzlPIE5Qetdlqh8Vmj3KriIiiS1VBbVcyOUEI9E5JBAAO0SOiuBdyUAshdEKIbUKIjEg1RqJ9HHWfFMfFA1j+IKJ415ke9Z0ACiPVEMD9FHL3HjUPKBJRfAspqIUQIwBcCuD9SDbG7jbXhyuoOUSPiOJcqD3qVwHcDyDgkT0hxC1CiFwhRG5NTU0Xm9Ne+khLcpQ+eIFbIop3QYNaCDEXQLWUMq+j9aSUC6SUU6WUU9PT07vUmHm/n4j/mzoCsyYMQSqDmogIAJAYwjpnAbhcCDEHQCqAfkKIhVLKv4S7McP6p+GFKycBaO9RG8wcnkdE8S1oj1pK+ZCUcoSUcgyAqwGsiURIe3MFNXvURBTnVDWO2l1qsqNpDGoiinehlD5cpJTZALIj0hIvroOJZgY1EcU39faoWfogIgKg4qBO0iUgSScY1EQU91Qb1ICjV83heUQU71Qd1GkMaiIilQd1sg4GHkwkojin6qBOTdSxRk1EcU/dQZ2sg8HCMxOJKL6pOqjTkhI4jpqI4p7Kg5qlDyIidQd1MoOaiEjVQZ2axFEfRESqDuq0JB1MVgY1EcU31Qc1e9REFO/UHdRKjVo6r3pLRBSHVB3UqUk62CVw0uMrsGFfbbSbQ0QUFaoPagBoM9vw8qqiKLeGiCg6VB3UzosHAECCEFFsCRFR9Kg7qJPbm1fWYIhiS4iIokfdQe3Wo65tNfGgIhHFJVUHdapbUFvtEi0maxRbQ0QUHTET1ADQoDdHqSVERNGj6qBO8w7qNkuUWkJEFD3qDupk9qiJiFQd1N5D8hraGNREFH9UHdS9lB71zOPTAQD17FETURxSdVAPH5CGr245HfP/fCp0CQKNrFETURxKjHYDgjl93CAAwIC0JNSz9EFEcUjVPWp3zUYLvth8CFVNxmg3hYioR8VMUFtsjrMSF6zbH+WWEBH1rJgJaqdWE+vURBRfYiaoP7tpOgCgopGlDyKKL0GDWgiRKoTYIoTYIYTYLYR4sica5u3s8ek4d0I6NhTXorRWH40mEBFFRSg9ahOA86SUkwCcAuBiIcTpEW1VALWtjlEfv39rYzRenogoKoIOz5OOuUVblZtJyr+ozDdqsdkBAE0G1qmJKH6EVKMWQuiEENsBVANYJaXc7GedW4QQuUKI3JqamjA308Fm53zURBR/QgpqKaVNSnkKgBEApgshJvpZZ4GUcqqUcmp6enqYm+nAoCaieNSpUR9SykYAWQAujkhrgrjujNHReFkioqgKZdRHuhBigPJzGoALAOyJcLv8uuGssbjj/PEA2LsmovgRylwfwwB8IoTQwRHs30gpMyLbrMD6pyUBAFqMFgzolRytZhAR9ZhQRn3kA5jcA20JiTOomwwMaiKKDzFzZqJTv1THd0uzgRe6JaL4EHNB7d6jJiKKBzEX1P2UoG42MqiJKD7EXFA7e9R1rSZsO9QQ5dYQEUWe6q/w4s3Zo35s0W4AQOY9M3HckL7RbBIRUUTFXI+6d7IOuoT2q5M38DqKRKRxMRfUQgjXyA8AEB2sS0SkBTEX1EB7nZqIKB7EfFALwT41EWlbTAZ1P4+gjmJDiIh6QMwHNRGR1sVmUKe2B3UCu9REpHExGdQeNeootoOIqCfEZFD3S4u583SIiLosJoPavUfNywcQkdbFfFDzSi9EpHUxGdTuBxOlZFATkbbFZFC796jZoSYirYvJoO7H0gcRxZGYDGqPg4ksfRCRxsVkUPd1mz2PHWoi0rqYDOokXXuzbexRE5HGxWRQu7MzqIlI42I+qFmjJiKti/mgttmj3QIiosiK+aBm6YOItC7mg5qlDyLSupgPapY+iEjrYjao773geAAsfRCR9sVsUM/57TAADGoi0r6YDWrnJbgY1ESkdUGDWggxUgiRJYQoEELsFkLc2RMNC0bnDGrWqIlI40K5ppUVwL1Syq1CiL4A8oQQq6SUBRFuW4ec17TlKeREpHVBe9RSykop5Vbl5xYAhQCOiXTDgklIcCQ1h+cRkdZ1qkYthBgDYDKAzX7uu0UIkSuEyK2pqQlT8wJzlj6+yS2L+GsREUVTyEEthOgD4HsAd0kpm73vl1IukFJOlVJOTU9PD2cb/VI61Mg72BDx1yIiiqaQgloIkQRHSH8upfwhsk0KjXAWqQG0ma1RbAkRUWSFMupDAPgAQKGU8uXINyk0bjkNvckWvYYQEUVYKD3qswBcB+A8IcR25d+cCLcrqMF9UnDZpOEA2KMmIm0LOjxPSrkBgAi2XjRcevIwLN5RgVYTg5qItCtmz0wEgN4pOgBAm5mlDyLSrpgO6l7Jjh0CPXvURKRhMR3U7FETUTyI7aBWetTzMgrwh7c3Rrk1RESREcpcH6rVO8XR/MomIyqbjLDY7EjSxfR3DxGRj5hOtV7JOo/bh+vbotQSIqLIiemgTklMgC6hfeRgi5EHFYlIe2I6qIUQsNnbZ8/T88QXItKgmA5qb208lZyINEhTQc0eNRFpUcwH9R3nj3f9bOB4aiLSoJgPand6BjURaZCmgrqNp5ITkQbFfFC7T+vHHjURaVHMB7U7Aw8mEpEGaSqo2aMmIi3SVFDzSi9EpEUxH9RnHjvI9TOvnUhEWhTzQX3auEEoeupinDFuEHvURKRJMR/UAJCSqMOAXklobLNEuylERGGniaAGgIG9k1GnN0e7GUREYaeZoB7UJwUNbWaP2fSIiLRAM0F9zIBUSAlsP9wY7aYQEYWVZoJ65vHpAICCiqYot4SIKLw0E9T905IA8KQXItIezQR1WpIOQgB6TsxERBqjmaAWQqB3ciJaGdREpDGaCWoA6J2i4+W4iEhztBXUyYlo5dmJRKQxmgrqo3ono7bFFO1mEBGFlaaCevTAXthcWo9F28uj3RQiorDRVFCPHNgLAHDnV9tR3WyMcmuIiMIjaFALIT4UQlQLIXb1RIO6o29qouvn55btiWJLiIjCJ5Qe9ccALo5wO8Ji/NF9XT/rEkQHaxIRxY6gQS2lXAegvgfa0m3nHJ+Od/4yBQCDmoi0I2w1aiHELUKIXCFEbk1NTbiettMunjgUowf1gsHC8dREpA1hC2op5QIp5VQp5dT09PRwPW2XpCXpYOCcH0SkEZoa9eGUmqRDWYMBS/Iro90UIqJu02RQpyXpUFDZjNu/2IoWo+PyXM1GC/LLGqPbMCKiLghleN6XAH4BMEEIUSaEuCnyzeqetGSd62fnlclv/CgHl7+5kVeAIaKYkxhsBSnlNT3RkHBKS3ILamXuj9yDDQAAs9XuEeRERGqnydJHqltQe8+mZ+RoECKKMZoM6rTk9rflPT+1yWrv6eYQEXWLNoPavUdt9g5q9qiJKLZoMqhTEtuD2rtHbbSwR01EsUWTQW11G9nhXepgj5qIYo0mg7qutf3iASavg4esURNRrNFkUNtke4/619J6VLe0z03NUR9EFGs0GdQPz/kN7po9HgCwJL8S17632XVfV2vU132wGZ9vPui6faTZiOLqlu41lIgoBJoM6sF9UnDn+eNdt4urW10/2+ydD2opJdbvq8UjP7ZfO+Hf3+7A7JfXoclg6V5jiYiC0GRQA4AQ7fNRD+qd7Pr57wu3etSwQ2G2+Yb7+n21AIDGNnMXW0hdJaXEO2tLsL+mNfjK3WCy2vDfxQUobzRE9HWIgtFsULvznt3j018O+l0vEKM5cC+cByd7Xk2rCc8t24ObP8mN6Ov8uLUcH24sxXvr9kf0dYiCiYugtnr1iKtbOtejbjEFLm+YOwjqikYDTn9mNfYeYS07nA7XO3q4jREsO72dXYwVu6sAAL00NDeMlBKvr96HLaUxcdGmHmOy2pC1pzrazQgoLoK62eh50kuryQopQ5tFr7i6FTOez/JYVuMW9B2Ny96wrxZVzUb8b2VRJ1pLwVQ1OUbxROpia1JKvLC8CFlFjisVaekkqcP1Bry8ai9u/SyyeyOx5q2sEtzwcQ42KCVNtYmLoPa2eEcFXsncB8AxXK+jqU93HG70uP3r/jpMezrTddvUwYe4d4pjcsLO9uADydpTjY3FtXE/xFCvnG0aqbKT9zEJLR0wbrM4fncNbdp5T+HgPG5VWNkMAPhyyyHsr2nF7oom2FUwNXLQaU61auGvB3Hn+eMx7alMnDJqAD676TS/69m8et7bDjV63A4UFl/nHMID3+8EEJ4emdFiww0f57hu//CPM3HqqKO6/byx5uZPcpBZ6NhF7ajs1B3el3HT0gFjvduUCnd/vR3zfj8RfVLiNgZcnBfDbjPbUK8346Efdrru++iv03DuCUOi1TQAcdqjBhyTNbWZrWgxWV0jOPzx/ja1ewV3oKD+7+KC9nWUHvCRZiNu/iQHn2w6EPDDf7i+DR9uKPUpzbR4lW/21+gDtlnLnCEN+B+NEw5t3kGtkR71UxkF+OP8X1y3f9xWjl3lTVFskXo49zBaTRZXr9rJ/YS5aInbr1KjxR7SBXC9w2DxjgqP24Fq1O498apmI+paTfh88yFkFlYjs7Aan/5yAKvvneXzuCcXFyCz8AimjD4Kk0YOcGuv5+skRKpAG2OklB5DMcPBe8bFhhjvUde1mnDjxznYUeYbyrwItOOg/xHluEeryeqzvb07SdEQtz1qwHF6eTDeG2lPlecIjkA9aveOeJvZhilPZWJov1TXspIAPWJn5niPFPEOan2YPmB3fbUNT2UUBF8xyowWGzbvr/NZ/v760rCHzaYSz9dpjPF67je5ZX5DGgBaTNEPoWgyW+0487k12HLAkQUtRqtPqZJBHWV3fLnN9XOgUSDBDlgdrm/DXz/agnq957ewvwMQ9frgBxWdfcNg07Pqw/AB05us+Gl7Bd7fUNrt54q099btx58W/Oqz/OmlhVhZUBW211mSX4n/LNrtsaxeb8bdX2/36Wl31gvL9+BP7/4SfMUwstrsHZ7g5bz4c7zy7hBl5Ffi39/u8FjWYgx9lFikxHVQu3MGYUWjAWMeXIKMfEeJw3sMtrc31hQju6gGC7xOivC3N17ZFLzW5ayBO7/F6/VmbCquhdGrxNIWhqA29MDokU3Ftahu7n6Nr6ORF+H4DN351Ta8s7YE6/fV+L3/x23l+NVPj74z3s4uweYeHL8spcRZz6/p8Iv4kR93YWeA3nY8CGVv6cONpfjz+5uDrhdJDGrFT9vLUVDRjN0VjgMJ3+WVwWC2YU2Ig+DfWVuCgopm2O0SZqsdiQm+v9ojQQLLaLHhSLOj9+PsUf/t01xc+/5mZBd5tqPV1P2QDWWYn8lqQ0WjAct3VXW6VyGlxLXvb8bcNzZ0tYkuKUmB/1T13ezpAsCi7RV4btkev1+w3rKKqjHmwSVdPrW8o+Gg4WS02F1/Tx257M0N2FSszvHDkdZoCO34w6aSOizfFb49t87SdFCPS+8d8roP/bATc15f7+pBJ+kSMG9JgU9NuiMlNa24dWEejn90md8PfFWQoL7ktfXYqRyFbzFaUFDRjDzl6ulvZZV4rOvdw+6KP87fFHSd+77Nx5nPrcHfF+ZhZcGRTj2/s2wUjnHk3iMx3HW3Ru2+1/TllsMB12s2OL4QvslxrJOr1DW/yTmMF1fsCfn1emq4n3f5rCPXRrnHGElf5xzCB8pehfu2ztpTjQ87Ufb7+8I8196HwWzDbQvzcLi+LbyNDUDTQf3DbWfi6mkjO/UY94MrX2w+1KnHFlY2Y1UHYbar3HPYT3F1q2uX3mKzo7S2/QBji9GKy94M3BPt7hhiu1369LZ2VzShQW/Giyv2uGruy3ZVuu7v7Ik24ToI89KKIny08UDA+9vMNhyub4OlgzLVrvKmgD1ZfYh7J1XNRtz+xVbUtTp+N87fx/3f5+OtrBI8vaQALUYLft5RASkliqpacP2HW3yCOZyjSKpbjCjy05mo15tx3v+yO/Vcka7DRmuY2wPf78S8jAKc82IWjntkmWsyrxs+zsFWr/Migsk7WA+7XWLt3hos21WFJ37eHfxBYaDpoB7QKxmTRw3o1GPu/y4fADoM3EDezm7v9XbUA3Sa/fJa3P31dgDASY+v8LjPZLV3uIsc7CCn3S47/OB5h2ib2YpLX9+AyfNW4a2sEjyV4Qgdi639OXQJAqW1eteB0g83lGLMg0sCtrM5TAeq3swq7vD+soY2nP1CFp5ZWuj3/pdWFGHuGxvwxpp9ONJsxNvZxR6/m1DbuXRnJZbkV7pGCNS2egbue+tLce5L2bjjy23Ye6QVN3+ag7V7a7C7otnjd+T+t2Gx2bsckNlF1Zj+9Gpc9Oo6j+V2u8T3eWWd/qK88JV1wVfqoqw9jrZu7MESi5QSr2budd0+WOfo/b68ai+Wu3VAOuOJxQV4aWWR6wQZ9z3b55btwSWvre9GiwPTdFADQHKi71tcfe85yLxnZhRa4ytf2ZXy7iEH6zF7X2LM25nPrcHcNzZgd0WTT49OSokXV3ruqnsfUGo1WXHbwq0ey7aU1uPcl7JxxnOrYbTY8PIqx4egwk+ttrLJgPP/t7bDNgLA88v34PYvtvosr201YenOypBCzHnyz9oi3wOBRVUtrqDfeqgR//pyG15YXoQStylSQz1F3HubNBksPlOtOsP7olfXtU8e1Wbx2Bv507u/4qmMArSarBj/yDKfA9GhkFLirx+1n6nqvjcxf20Jng7wpdWRfdWtYTtd+kCtHq9l7sNtC/PQYrQgR/ly6+xkUPV6M/LLGrvUhmaDFa8qU0W4y8ivxN8X+v7NhWrhrwddnyn3v4nKJkNYRmP5o/mgTktqP6fnjHGDkHnPOTg2vQ+OG9K308/1wh9/G86mAQASE4TfMAo2wsBss8NoseFgne947EN1bahqNmJ3RTMufX0DTvnvKmwqae/J7K/VY+GvnmUd76FvQgAbvHo/OQcc9fIjzSac8NhyVw3UvWTjVOpnnLiUEs8t24NlOysx5sEl2Ly/DvOzS7Akv9InLG/8OAf/+HxrwPHmHq+lvH6izvPAgMFswz3fbHfdXre3xhUUTYb2D1SoBzu9jzE0tVlwXghfRvVtZo/hmwaLDe9vKEVVkyPIOzvtLgC85bWX4dwzO9JsxIsruj4JWIXSpvyyRizdWYkDfrZtIOf/LxvzMgpQ02LCrJey8UrmXizbVYVnlha69jYDlaeqm414ZdVen1FWV72zCZe/udHvXtvzy/dgwqPLArYnUqWWZqMVGfmOHnlyYgLW76vBeS9lo7LRiKN6JUXkNTUf1CcN7+f6/4u/nYbjhvTp8nP9Xyfr3aGwSel3mFyw0obJYsd/Fu3COS9mo8lgwX3f7kB+WSMO17dh5otZPuvf+lkeAEdYdvUASFmD/8f5q7l6z1hosdmxv1aPd9aW4LbPHb2Zr3PbD9w1GyyQUuL99ftxpNnoOqgaSm+3TglB4TWf3rp9Na5RPN5+3V+HWz/LDToSx533UK5QRww06s04+wXfbTL75fZSw47DjmDcVd7kcUWiQD771TPcncHxn0W7/K3u12+G9fNZ1qB3bIfL39yIf3y+FbNeysai7eVBn+uHrWUoqdHjgw2l+MWrk+F+gDZQSfCGj3Pw2up9+MBr+gTnF3V5g+9e2/zsEpisdvz72x2w2SWqmowejw128D4UQ/ulYuIxvr+ntXvb996e+Hk39tfqseVAPQb0SvZZNxw0H9QjB/bC8388Ge9eNyUspxo/c8XJ6O01P/GKuzouoyy94+yA99W0mDyu6RiqX/bX4ZvcMgDAT9vK8W1eGW5buNVvIACOuqXBbMP8tSUeu8y3n3us3/VX7Pat0QeqeepNNo+ekL8vgyvf+QU/bfP8wLvP89xqsuJIswlPLSnEH+dvco2Nrupg7Ll376XoSAsa28yobjHi018OdHjw88UVRVix+4gr4AIZcVQaFt1+lt/7vCfoCiTYTHV2KfG7txzBOPeNDZj98tqgtWt/26LJYHGNTAnm4xumIeNfM3zCulZv8uk43PnVdjTozcguqobeZEVFowHzMgpcJwDZ7RL3fNN+kkhHJ9h8vOmAz4yUQPvIoGeX7cE7ax2loBeWt5fnDtW34eONpWjQ+345fpdXhqeXFOL0Z1cjWwlQKSWu+2BLR7+CkBzdPxU/3z4Dl00a7vf+ykajx14fe9Td8KdpozDiqF7deo4v/uaYXe/a00bhwpOGetw3YWhfnD1+cMDHnjjc88Nw/RmjPW5v9/OH2xlZyhjrjkY96M02V33W3bHpXd/DcHr4x504+YmVqGs1QUqJsQ8t9amR7jjciDfWeO6uu5dfNu+vc42HLnPrPfmrXztt+8+FPstOf3Y1Plhfiv8s2o2vOhhq5zTP7fR5f8czpITHnCvuQh12+OHGjoeA+TsRavwjy/C3T/P81ox/2lbu0TNN1jnaPfm/K0OeqGrWhCHQ+Sm73fBRDuZl+Na3J89bhb9+lIMvtxzC93ll+GBDKT7aeAB2u3SVS5yeXNzxlAS/e2ujK8yllHgrq9hjjvfnl+9Bi9HicXA+50A9nlhcgMnzVuGhH/I9SloA8I2yd7ZxXy2klD5zyIfimumjcM8Fx3sss9ntSEgQeOOayX4fs9+rNMQedQRk/GsG7nC7CG5Hzjy2PYgTlJ759WeMdvWmbzvH0TOdPmYgFvqZMnXdfee6fp5z8rCQ23jVlBEet+f/+VSfdbKVg2jBgiOz0LeXPLR/qp81O89gsWHq05kevfXOeGJxAUpC2OUPxmixu8bMeu+CB5P36GzcNGOsxzLv2RIDeeaKk/HNrWe4bi+86TRk/GtGp17fW2bhEYx7eCn++cVWfL75IA7Xt+HnHRW4S6lHO11+ynClrXCNuw/Vm9eeirtnH+9xcP3LLYGHpda2ml3HJl5cUYTpz6wOGIrXTPcsFfZ1m051U0kdTFYbPt98yG9N/eQnVnrcdt9D+3LLYfyw1XPvzNmm9zeU4tR5q/yejNQ3JRGXB+gZA8AxA1Lx93M89zCtbqOeVt97TsDHOvVLY4867CYe0981zvrWmeOw5A7HB2vc4N5489rJAUsasyakAwCumjoSE4Y6Dko6v0mPH9oH/dJ8JyUcNagXnr5iIr77+xmwuvWSjhmQFrB9P91+Fl68apLHskvcQn762IFB3yMAjBwY+DXSkjzLOEk63/LQzV7htf+ZOSh9dg52P3mRx3IpPWt3ndWdx7qzevVC199/Lm6aMRbHDEjDvy88PsCjgD4piXhs7okey0IN6j+cegymjx2Im2eMxac3TseM8YMx8Zj+HuvcPTvwa3ckI78Sj/y4C2e/kOUxP83gPsn46pbT8fQVE7v0vABw3JA+uHP2eNdFLrz19Vr+7roSj2mBazsoczz7h/aD7+l9UzyGsu043IgJjy7Hoz+119QvmTgUWx453+9z/bDNf5180sgBPuUGf6WmvEdnY+eTF+H1aybjvosm+H0uIYTP3/9fzxzj+vnY9D5Yc+85ruNe/kRqjvSQgloIcbEQokgIUSyEeDAiLYmS4QPSsPa+Wbjvogk4aXh/HHjuUqz59yzM/e1wTBjaF78/ZThuOGuMx2MumzQcOx6/0OODeOLwfvj0xul49NITXWMsAWD2b9onHP/zaaMxdcxAjBroKMNcPW0kNjzg6GkP65+KTQ+e5/E64wMc+Lxm+kj0SUn06MG5W3bn2Vh5d/uXzKLb/ffs5v3uJPR36wE8eulvkP/4RdjycPuHZUjfFDzqFV4JCQJCiIAfbgD44PqprvfpvRfwzl9OxTXTR/k85nO3E4y8AzNUk0b091k2cmAvPDb3RGx88Dz88zz/e1D3XTTB7zGMP011fJFn/3tWwNd8eM4JSFW+8B6deyJmHp/uuu+u2Y7XG9g7GXfO9n3tl//P84v41nPGYdqY0C4Icc30UTh93CCkJOpwntvE9ud7TXKf88hsLL/rbLzyp0neT+Hib1u+85cp2PnkRRg7uP0MXymBgkr/B2g7svGB8zz+1vzNP1JS04r0Pimdet4JR/dxBfOQvv4fu+/pSzDI7XlvP/c4LLhuis96M8ene/wNHHjuUlzt9Xc6Lr0PlnRwzMkQhukM/Ak6H7UQQgfgLQAXACgDkCOE+FlKqf65MUM0elDgU81fvdp/baq/n10c5wfUOc/HcUP64P3rp/msN3JgL5Q8M8cV6JsfPh9JugQM7J2M/101CQ/9sBNmm911sG3rYxcgv6zRdQbds3/4rau38tFfp2FlwRGs21uD8kYDPrlxuusAUemzc2CX8PjiAICVd89Esi4BY5QP4M//PAu/GdYPSUqtM83tIN9p4wa53m+TwYJVd3vuZTxzxcl4+MedOLpfCr6+5QzMeikbADB2cG8suv0s1LaaMP7ovrh62kh8lXMYl00ajosnDsPFE4dh7m+HobbVhCcXF3gMX7tk4lDceNYY7Klsxrd5ZThhaF/Xqfwr756JWz/Lc+1Wv3TVJNdsZ/dfPAHHD+mLmz/t+HqAc387zHUQcd1956JWb/K4Ws7yu85GYWUzLj15uKuHNWZwb3x643SkJCbglcy9uGLyMdhfq8fAXsm48ayxfl8HAG6deSzeXFOM/yhfPLuevAgbi2sxpG8KCitb8IdTR7gOxO2ZdzGSdQn4Nu+waygk4PiSWL+vBo8ps/qNHtQL150+2uN1Lz15mGtemvl/mYKNxbWoaDJgQFoy0vumIL1vCk4Y2g93f+05M5xTn+T2KNj62AXILDyCC088GgBw5ZQRAYf8fXTDNNyglLsy7zkHb2cVo05vxo1ee2HJiQm454IJ2FRS63EAd8kdMzCkbyqmPZ2JVqPVIyjX338uzn4hCycN7+cxemfm8el46JITsHRnJW6aMRa7lTl6Nj14HmxS4oaPcrCppA5/Pm0UqpqMrr9rdxeeNBR7n7oEta0mJOoEhvT1LAGm+Dle4e7Hf5yJJF0CdAkCNS0m2KTEfd/uwN9mjuvwcV0mpezwH4AzAKxwu/0QgIc6esyUKVNkPLNYbfJfX2yVu8obu/T4isY2uW5vdace02Qwy+yiwI8Z/UCGHP1Ahlyz50hIz/dt7mF58yc5ss1klVJKebBWL3eXN/ldN2NHhTxUp5dSSrnvSLOsajL4rFPVZJBL8yuk3W73uc9ut8stpXXy8UW75OgHMmR9q8lnnYteWSu/yz3s9/UXbS+X760rcT1XTmmdXLm7So5+IEO+lbXP72O2lNbJg7V6v/f1tJ1ljfLDDftdt+12u9xd3iQ/3lgqZ72YJU0Wm7TZ7PKqdzbJZ5YUBHyejB0V8sHvd3T4WoWVTXJnWef/Lgsrm2RBRZMc/UCGvHL+RvneuhL5dlaxlFLK1zL3yv8u3u132+443CB/Kan1WLZ4R7kc/UCGfD1zr2vZ11sOyT2VzVJKKdcUHvG4T0opMwuqZG2LUZY3tPm8TpPB7PE302ayytwDdZ1+j045pXWyvKGty4/vKgC5MkCmChmkBieEuBLAxVLKm5Xb1wE4TUr5T6/1bgFwCwCMGjVqysGDnR/ET5Hz47YyDOiVjHMnRPfab8GYrXa/oy+6Qm+ydlieoc5rNVmRrEsI2zaidkKIPCnlVH/3he2vWEq5AMACAJg6dWr0L9tLHq6YPCL4SioQzgBgSIcfL4QbHaF8KsoBuI+zGaEsIyKiHhBKUOcAGC+EGCuESAZwNYCfI9ssIiJyCrofI6W0CiH+CWAFAB2AD6WUPTMJKxERhVajllIuBbA0wm0hIiI/eOiWiEjlGNRERCrHoCYiUjkGNRGRygU9M7FLTypEDYCunpo4GEDPXQFTHfie4wPfs/Z15/2OllKm+7sjIkHdHUKI3ECnUWoV33N84HvWvki9X5Y+iIhUjkFNRKRyagzqBdFuQBTwPccHvmfti8j7VV2NmoiIPKmxR01ERG4Y1EREKqeaoNbqBXSFECOFEFlCiAIhxG4hxJ3K8oFCiFVCiH3K/0cpy4UQ4nXl95AvhDi141dQLyGETgixTQiRodweK4TYrLy3r5VpcyGESFFuFyv3j4lqw7tICDFACPGdEGKPEKJQCHGG1rezEOJu5e96lxDiSyFEqta2sxDiQyFEtRBil9uyTm9XIcT1yvr7hBDXd6YNqghqtwvoXgLgRADXCCG6dhlq9bECuFdKeSKA0wHcrry3BwGsllKOB7BauQ04fgfjlX+3AJjf800OmzsBFLrdfh7AK1LK4wA0ALhJWX4TgAZl+SvKerHoNQDLpZQnAJgEx3vX7HYWQhwD4A4AU6WUE+GYBvlqaG87fwzgYq9lndquQoiBAB4HcBqA6QAed4Z7SAJdTLEn/6ELF9CN1X8AFsFxRfciAMOUZcMAFCk/vwvgGrf1XevF0j84rgS0GsB5ADIACDjO2Er03uZwzHV+hvJzorKeiPZ76OT77Q+g1LvdWt7OAI4BcBjAQGW7ZQC4SIvbGcAYALu6ul0BXAPgXbflHusF+6eKHjXaN7hTmbJMU5RdvckANgM4WkpZqdxVBeBo5Wet/C5eBXA/ALtyexCARimlVbnt/r5c71m5v0lZP5aMBVAD4COl3PO+EKI3NLydpZTlAF4CcAhAJRzbLQ/a3s5Ond2u3dreaglqzRNC9AHwPYC7pJTN7vdJx1esZsZJCiHmAqiWUuZFuy09KBHAqQDmSyknA9CjfXcYgCa381EAfgfHl9RwAL3hWyLQvJ7YrmoJak1fQFcIkQRHSH8upfxBWXxECDFMuX8YgGpluRZ+F2cBuFwIcQDAV3CUP14DMEAI4byqkPv7cr1n5f7+AOp6ssFhUAagTEq5Wbn9HRzBreXtPBtAqZSyRkppAfADHNtey9vZqbPbtVvbWy1BrdkL6AohBIAPABRKKV92u+tnAM4jv9fDUbt2Lv9/ytHj0wE0ue1ixQQp5UNSyhFSyjFwbMs1Uso/A8gCcKWymvd7dv4urlTWj6mep5SyCsBhIcQEZdH5AAqg4e0MR8njdCFEL+Xv3PmeNbud3XR2u64AcKEQ4ihlT+RCZVlool2kdyuuzwGwF0AJgEei3Z4wvq8ZcOwW5QPYrvybA0dtbjWAfQAyAQxU1hdwjIApAbATjiPqUX8f3Xj/swBkKD+PA7AFQDGAbwGkKMtTldvFyv3jot3uLr7XUwDkKtv6JwBHaX07A3gSwB4AuwB8BiBFa9sZwJdw1OAtcOw53dSV7QrgRuW9FwO4oTNt4CnkREQqp5bSBxERBcCgJiJSOQY1EZHKMaiJiFSOQU1EpHIMaiIilWNQExGp3P8H+QoufimISEIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stacked LSTM - softplus Activation\n",
    "hybrid_model = Sequential()\n",
    "hybrid_model.add(LSTM(30, activation='softplus', input_shape=(2, 1)))\n",
    "hybrid_model.add(Dense(1))\n",
    "adam = keras.optimizers.Adam(lr=0.1)\n",
    "hybrid_model.compile(optimizer=adam, loss='mae',metrics=['mae'])\n",
    "hybrid_history = hybrid_model.fit(n_train, nplus_train, epochs=1000, validation_split=0.0, verbose=0)\n",
    "\n",
    "#predict on unseen\n",
    "print(n_test)\n",
    "print(\"Prediction: \" + str(np.squeeze(hybrid_model.predict(n_test))))\n",
    "print(\"Actual: \" + str(nplus_test))\n",
    "\n",
    "#plot error\n",
    "pyplot.plot(hybrid_history.history['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Needs to have better accuracy (-1.8 is too close to -1 (a possible answer choice) rather than -3 (the actual answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
